{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2245,
     "status": "ok",
     "timestamp": 1582075163579,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "rbobl8w9CnxH",
    "outputId": "e3d66007-8e50-4145-9413-b9c9258d76af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn import datasets\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Activation, Dense,Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scipy.sparse import issparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebmuoJf9ZuHY"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8DsEVv3p4Y9"
   },
   "outputs": [],
   "source": [
    "#Implementacao do contrutor de modelos\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications import ResNet50,VGG16,VGG19,InceptionV3\n",
    "\n",
    "from keras import metrics\n",
    "\n",
    "def create_model_vgg16(units=(64,32),num_classe=9,optimizer='rmsprop',final_act='sigmoid'):\n",
    "  vgg = VGG16(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "  x = vgg.output\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(units[0], activation='relu')(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "  x = Dense(units[1], activation='relu')(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "  out = Dense(num_classe, activation=final_act)(x)\n",
    "  model = Model(inputs=vgg.input, outputs=out)\n",
    "  for layer in model.layers[:-7]:\n",
    "      layer.trainable = False\n",
    "\n",
    "  # Check the trainable status of the individual layers\n",
    "  #for layer in model.layers:\n",
    "  #    print(layer, layer.trainable)\n",
    "\n",
    "  #model.summary()\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwocCMKincqG"
   },
   "outputs": [],
   "source": [
    "#ler o csv e carregar num objeto dataframe do pandas\n",
    "path_name=\"drive/My Drive/\"\n",
    "images_dir=path_name+\"condor/images/\"\n",
    "os.path.exists(images_dir)\n",
    "\n",
    "data_frame=pd.read_csv(path_name+'dataset/condor_data.csv', index_col=[0])\n",
    "data_frame[\"labels\"] = data_frame[\"labels\"].apply(lambda x: list(set(eval(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2112,
     "status": "ok",
     "timestamp": 1582075163585,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "3GHJRCiY3Y8_",
    "outputId": "24458711-02fa-4ea5-b2dd-9adaaa24dbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         adptador     bandeja     bateria  ...      coldre    pendrive       spark\n",
      "count  244.000000  244.000000  244.000000  ...  244.000000  244.000000  244.000000\n",
      "mean     0.196721    0.258197    0.172131  ...    0.049180    0.135246    0.073770\n",
      "std      0.398337    0.438542    0.378270  ...    0.216689    0.342689    0.261934\n",
      "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
      "50%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
      "75%      0.000000    1.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
      "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
      "\n",
      "[8 rows x 9 columns]\n",
      "244\n",
      "['adptador' 'bandeja' 'bateria' 'cabo' 'carregador' 'cartucho' 'coldre'\n",
      " 'pendrive' 'spark'] {0: 5.083333333333333, 1: 3.873015873015873, 2: 5.809523809523809, 3: 11.090909090909092, 4: 6.256410256410256, 5: 8.413793103448276, 6: 20.333333333333332, 7: 7.393939393939394, 8: 13.555555555555555}\n"
     ]
    }
   ],
   "source": [
    "#Binarizar os labels do y [[0 0 1 0]] por exemplo\n",
    "from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "X,y=data_frame.filename, data_frame.labels\n",
    "mbl=MultiLabelBinarizer()\n",
    "y=mbl.fit_transform(data_frame.labels)\n",
    "columns= mbl.classes_\n",
    "\n",
    "for id,column in enumerate(columns):\n",
    "  data_frame[column]=y[:,id]\n",
    "\n",
    "#data_frame=data_frame.query('arma==1 or bandeja==1 or fonte==1 or tomada==1 and municao==0')\n",
    "print(data_frame.describe())\n",
    "\n",
    "total=len(data_frame.index)\n",
    "print(total)\n",
    "def analizar_pesos(data_frame,columns):\n",
    "  class_weights={}\n",
    "  #print(data_frame.query('{}==1'.format('arma')))\n",
    "  #definindo os pesos de cada classe\n",
    "  for id,column in enumerate(columns):\n",
    "    count=len(data_frame.query('{}==1'.format(column)))\n",
    "    try:\n",
    "      class_weights[id]=total/count\n",
    "    except:\n",
    "      class_weights[id]=0\n",
    "\n",
    "  return class_weights\n",
    "\n",
    "class_weights=analizar_pesos(data_frame,columns)\n",
    "print(columns,class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60346,
     "status": "ok",
     "timestamp": 1582075221837,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "c21mSAeidkMQ",
    "outputId": "e71890b4-0f6e-4783-c034-1913f2a4b352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 validated image filenames.\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (460, 128, 128, 3) (460, 9)\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen =  ImageDataGenerator(\n",
    "  rescale=1. / 255,\n",
    "  zoom_range = 0.05, # Aleatory zoom\n",
    "  rotation_range= 10,\n",
    "  width_shift_range=0.1,  # horizontal shift\n",
    "  height_shift_range=0.1,  # vertical shift\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,)\n",
    "\n",
    "path=\"drive/My Drive/\"\n",
    "img_iter = datagen.flow_from_dataframe(\n",
    "    data_frame,\n",
    "    shuffle=True,\n",
    "    directory=path,\n",
    "    x_col='filename',\n",
    "    y_col=columns ,\n",
    "    class_mode='other',# quando existe colunas binarizadas usar o other categorical quando possui uma lista de labels numa coluna label\n",
    "    target_size=(128, 128),\n",
    "    batch_size=24,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "X_train,y_train=img_iter.next()\n",
    "for i in range(1,20):\n",
    "  X_data,y_data=img_iter.next()\n",
    "  X_train=np.concatenate((X_train, X_data))\n",
    "  y_train=np.concatenate((y_train, y_data))\n",
    "\n",
    "print(type(X_train),type(y_train),X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145398,
     "status": "ok",
     "timestamp": 1582076306911,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "NtEKxmsgXLef",
    "outputId": "48ea0e17-7ddf-4a9c-b306-73dd14fb5ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] optimizer=rmsprop, units=(64, 32) ...............................\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 7s 23ms/step - loss: 0.5238 - acc: 0.7578 - f1_m: 0.2031 - precision_m: 0.1922 - recall_m: 0.2590\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3740 - acc: 0.8413 - f1_m: 0.2902 - precision_m: 0.4065 - recall_m: 0.2483\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.8638 - f1_m: 0.3549 - precision_m: 0.5040 - recall_m: 0.2932\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2776 - acc: 0.8863 - f1_m: 0.4788 - precision_m: 0.6185 - recall_m: 0.4144\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2465 - acc: 0.8994 - f1_m: 0.5275 - precision_m: 0.7197 - recall_m: 0.4253\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2285 - acc: 0.9049 - f1_m: 0.5527 - precision_m: 0.6821 - recall_m: 0.4853\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2119 - acc: 0.9143 - f1_m: 0.6022 - precision_m: 0.7272 - recall_m: 0.5613\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1896 - acc: 0.9245 - f1_m: 0.6454 - precision_m: 0.8002 - recall_m: 0.5525\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1924 - acc: 0.9259 - f1_m: 0.6853 - precision_m: 0.7873 - recall_m: 0.6285\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1696 - acc: 0.9292 - f1_m: 0.6774 - precision_m: 0.8043 - recall_m: 0.6077\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1455 - acc: 0.9463 - f1_m: 0.7342 - precision_m: 0.8580 - recall_m: 0.6517\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1547 - acc: 0.9375 - f1_m: 0.7288 - precision_m: 0.8297 - recall_m: 0.6595\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1378 - acc: 0.9415 - f1_m: 0.7643 - precision_m: 0.8602 - recall_m: 0.7113\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1255 - acc: 0.9506 - f1_m: 0.7982 - precision_m: 0.8817 - recall_m: 0.7409\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1252 - acc: 0.9503 - f1_m: 0.7903 - precision_m: 0.8805 - recall_m: 0.7280\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1226 - acc: 0.9473 - f1_m: 0.7754 - precision_m: 0.8765 - recall_m: 0.7107\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1154 - acc: 0.9517 - f1_m: 0.7977 - precision_m: 0.8795 - recall_m: 0.7422\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9528 - f1_m: 0.8071 - precision_m: 0.8915 - recall_m: 0.7502\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1093 - acc: 0.9524 - f1_m: 0.7517 - precision_m: 0.8240 - recall_m: 0.6957\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0946 - acc: 0.9622 - f1_m: 0.8401 - precision_m: 0.8967 - recall_m: 0.7995\n",
      "154/154 [==============================] - 0s 3ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(64, 32), score=(train=0.971, test=0.918), total=  25.8s\n",
      "[CV] optimizer=rmsprop, units=(64, 32) ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.5230 - acc: 0.7615 - f1_m: 0.2474 - precision_m: 0.2469 - recall_m: 0.2810\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3555 - acc: 0.8545 - f1_m: 0.3908 - precision_m: 0.4625 - recall_m: 0.3593\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3086 - acc: 0.8737 - f1_m: 0.4849 - precision_m: 0.5745 - recall_m: 0.4490\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2621 - acc: 0.8965 - f1_m: 0.5420 - precision_m: 0.6713 - recall_m: 0.4831\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2397 - acc: 0.9052 - f1_m: 0.6103 - precision_m: 0.7320 - recall_m: 0.5435\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2132 - acc: 0.9131 - f1_m: 0.6050 - precision_m: 0.7387 - recall_m: 0.5198\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1989 - acc: 0.9168 - f1_m: 0.6311 - precision_m: 0.7568 - recall_m: 0.5516\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1870 - acc: 0.9189 - f1_m: 0.6399 - precision_m: 0.7526 - recall_m: 0.5694\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1767 - acc: 0.9207 - f1_m: 0.6718 - precision_m: 0.7752 - recall_m: 0.6104\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1637 - acc: 0.9359 - f1_m: 0.7336 - precision_m: 0.8642 - recall_m: 0.6575\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9345 - f1_m: 0.7378 - precision_m: 0.8344 - recall_m: 0.6792\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1321 - acc: 0.9486 - f1_m: 0.7841 - precision_m: 0.8817 - recall_m: 0.7211\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9472 - f1_m: 0.7933 - precision_m: 0.8642 - recall_m: 0.7434\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1244 - acc: 0.9515 - f1_m: 0.7927 - precision_m: 0.9174 - recall_m: 0.7251\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1120 - acc: 0.9555 - f1_m: 0.8220 - precision_m: 0.8847 - recall_m: 0.7745\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9569 - f1_m: 0.8262 - precision_m: 0.8795 - recall_m: 0.7888\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 0.9522 - f1_m: 0.8107 - precision_m: 0.8852 - recall_m: 0.7629\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1037 - acc: 0.9555 - f1_m: 0.8312 - precision_m: 0.8934 - recall_m: 0.7885\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1048 - acc: 0.9602 - f1_m: 0.8357 - precision_m: 0.8832 - recall_m: 0.8081\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0920 - acc: 0.9609 - f1_m: 0.8451 - precision_m: 0.8978 - recall_m: 0.8084\n",
      "153/153 [==============================] - 1s 3ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(64, 32), score=(train=0.987, test=0.946), total=   9.5s\n",
      "[CV] optimizer=rmsprop, units=(64, 32) ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   36.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.4734 - acc: 0.8096 - f1_m: 0.2316 - precision_m: 0.3279 - recall_m: 0.2080\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3417 - acc: 0.8570 - f1_m: 0.3335 - precision_m: 0.5328 - recall_m: 0.2631\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3078 - acc: 0.8664 - f1_m: 0.3474 - precision_m: 0.5328 - recall_m: 0.2677\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2928 - acc: 0.8690 - f1_m: 0.4068 - precision_m: 0.6242 - recall_m: 0.3339\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2634 - acc: 0.8827 - f1_m: 0.4442 - precision_m: 0.6543 - recall_m: 0.3671\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2219 - acc: 0.9008 - f1_m: 0.5448 - precision_m: 0.7584 - recall_m: 0.4342\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2275 - acc: 0.8979 - f1_m: 0.5626 - precision_m: 0.7313 - recall_m: 0.4670\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2034 - acc: 0.9008 - f1_m: 0.5536 - precision_m: 0.7633 - recall_m: 0.4561\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1924 - acc: 0.9095 - f1_m: 0.5974 - precision_m: 0.7610 - recall_m: 0.5062\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1811 - acc: 0.9168 - f1_m: 0.6422 - precision_m: 0.8326 - recall_m: 0.5359\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1639 - acc: 0.9258 - f1_m: 0.6889 - precision_m: 0.8337 - recall_m: 0.6052\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1544 - acc: 0.9316 - f1_m: 0.7260 - precision_m: 0.8489 - recall_m: 0.6473\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1579 - acc: 0.9273 - f1_m: 0.7136 - precision_m: 0.8258 - recall_m: 0.6396\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1556 - acc: 0.9240 - f1_m: 0.7086 - precision_m: 0.7949 - recall_m: 0.6526\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1410 - acc: 0.9356 - f1_m: 0.7531 - precision_m: 0.8522 - recall_m: 0.6917\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1282 - acc: 0.9472 - f1_m: 0.7979 - precision_m: 0.8760 - recall_m: 0.7412\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1304 - acc: 0.9439 - f1_m: 0.7811 - precision_m: 0.8555 - recall_m: 0.7298\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1120 - acc: 0.9472 - f1_m: 0.8087 - precision_m: 0.8550 - recall_m: 0.7769\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1129 - acc: 0.9486 - f1_m: 0.8048 - precision_m: 0.8592 - recall_m: 0.7659\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1069 - acc: 0.9569 - f1_m: 0.8369 - precision_m: 0.8849 - recall_m: 0.8039\n",
      "153/153 [==============================] - 0s 2ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(64, 32), score=(train=0.978, test=0.946), total=   9.2s\n",
      "[CV] optimizer=rmsprop, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 0.4592 - acc: 0.8065 - f1_m: 0.1764 - precision_m: 0.2679 - recall_m: 0.1507\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3140 - acc: 0.8667 - f1_m: 0.3086 - precision_m: 0.5710 - recall_m: 0.2306\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.8867 - f1_m: 0.4845 - precision_m: 0.6207 - recall_m: 0.4210\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.9049 - f1_m: 0.6012 - precision_m: 0.7108 - recall_m: 0.5542\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2276 - acc: 0.9099 - f1_m: 0.5873 - precision_m: 0.7077 - recall_m: 0.5309\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1928 - acc: 0.9245 - f1_m: 0.6592 - precision_m: 0.7854 - recall_m: 0.5965\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1816 - acc: 0.9267 - f1_m: 0.6926 - precision_m: 0.7734 - recall_m: 0.6659\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1599 - acc: 0.9306 - f1_m: 0.7256 - precision_m: 0.8272 - recall_m: 0.6689\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1512 - acc: 0.9419 - f1_m: 0.7679 - precision_m: 0.8393 - recall_m: 0.7374\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1385 - acc: 0.9473 - f1_m: 0.7782 - precision_m: 0.8513 - recall_m: 0.7283\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1309 - acc: 0.9488 - f1_m: 0.7874 - precision_m: 0.8531 - recall_m: 0.7415\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1202 - acc: 0.9550 - f1_m: 0.8029 - precision_m: 0.8623 - recall_m: 0.7586\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1159 - acc: 0.9521 - f1_m: 0.7891 - precision_m: 0.8505 - recall_m: 0.7528\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0962 - acc: 0.9604 - f1_m: 0.8405 - precision_m: 0.8849 - recall_m: 0.8165\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0918 - acc: 0.9619 - f1_m: 0.8509 - precision_m: 0.8798 - recall_m: 0.8323\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0805 - acc: 0.9706 - f1_m: 0.8757 - precision_m: 0.9170 - recall_m: 0.8517\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0901 - acc: 0.9637 - f1_m: 0.8640 - precision_m: 0.8996 - recall_m: 0.8506\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0782 - acc: 0.9702 - f1_m: 0.8725 - precision_m: 0.9082 - recall_m: 0.8465\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0668 - acc: 0.9724 - f1_m: 0.8820 - precision_m: 0.9078 - recall_m: 0.8651\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9695 - f1_m: 0.8728 - precision_m: 0.9120 - recall_m: 0.8458\n",
      "154/154 [==============================] - 0s 2ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 32), score=(train=0.986, test=0.942), total=   9.5s\n",
      "[CV] optimizer=rmsprop, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.5731 - acc: 0.7264 - f1_m: 0.2237 - precision_m: 0.2010 - recall_m: 0.3014\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4072 - acc: 0.8252 - f1_m: 0.3398 - precision_m: 0.3675 - recall_m: 0.3437\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3267 - acc: 0.8643 - f1_m: 0.4283 - precision_m: 0.5141 - recall_m: 0.3871\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2677 - acc: 0.8950 - f1_m: 0.5587 - precision_m: 0.6737 - recall_m: 0.4881\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2512 - acc: 0.8990 - f1_m: 0.5676 - precision_m: 0.6500 - recall_m: 0.5263\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2213 - acc: 0.9073 - f1_m: 0.6042 - precision_m: 0.6811 - recall_m: 0.5567\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1883 - acc: 0.9160 - f1_m: 0.6371 - precision_m: 0.7553 - recall_m: 0.5716\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1757 - acc: 0.9283 - f1_m: 0.6796 - precision_m: 0.7710 - recall_m: 0.6267\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1537 - acc: 0.9363 - f1_m: 0.7344 - precision_m: 0.8291 - recall_m: 0.6690\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1435 - acc: 0.9435 - f1_m: 0.7708 - precision_m: 0.8368 - recall_m: 0.7268\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1433 - acc: 0.9406 - f1_m: 0.7517 - precision_m: 0.8491 - recall_m: 0.6918\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1371 - acc: 0.9385 - f1_m: 0.7584 - precision_m: 0.8268 - recall_m: 0.7170\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1246 - acc: 0.9479 - f1_m: 0.7865 - precision_m: 0.8826 - recall_m: 0.7239\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1240 - acc: 0.9450 - f1_m: 0.7740 - precision_m: 0.8532 - recall_m: 0.7505\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1075 - acc: 0.9533 - f1_m: 0.8054 - precision_m: 0.8610 - recall_m: 0.7766\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9577 - f1_m: 0.8292 - precision_m: 0.8816 - recall_m: 0.7964\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0890 - acc: 0.9631 - f1_m: 0.8602 - precision_m: 0.9065 - recall_m: 0.8277\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0905 - acc: 0.9606 - f1_m: 0.8546 - precision_m: 0.9028 - recall_m: 0.8226\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0834 - acc: 0.9649 - f1_m: 0.8699 - precision_m: 0.9004 - recall_m: 0.8476\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9620 - f1_m: 0.8561 - precision_m: 0.9052 - recall_m: 0.8212\n",
      "153/153 [==============================] - 0s 3ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 32), score=(train=0.988, test=0.947), total=   9.7s\n",
      "[CV] optimizer=rmsprop, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.4807 - acc: 0.8046 - f1_m: 0.2534 - precision_m: 0.3078 - recall_m: 0.2493\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3337 - acc: 0.8563 - f1_m: 0.4071 - precision_m: 0.5076 - recall_m: 0.3656\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.8769 - f1_m: 0.4855 - precision_m: 0.5904 - recall_m: 0.4439\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2573 - acc: 0.8893 - f1_m: 0.5708 - precision_m: 0.6532 - recall_m: 0.5254\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.9052 - f1_m: 0.6299 - precision_m: 0.7411 - recall_m: 0.5888\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2081 - acc: 0.9124 - f1_m: 0.6364 - precision_m: 0.7630 - recall_m: 0.5655\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1887 - acc: 0.9251 - f1_m: 0.7077 - precision_m: 0.7955 - recall_m: 0.6469\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1676 - acc: 0.9305 - f1_m: 0.7264 - precision_m: 0.8115 - recall_m: 0.6826\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1571 - acc: 0.9305 - f1_m: 0.7136 - precision_m: 0.8014 - recall_m: 0.6534\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1493 - acc: 0.9370 - f1_m: 0.7528 - precision_m: 0.8217 - recall_m: 0.7145\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1213 - acc: 0.9537 - f1_m: 0.8085 - precision_m: 0.8654 - recall_m: 0.7680\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1195 - acc: 0.9508 - f1_m: 0.8058 - precision_m: 0.8928 - recall_m: 0.7482\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1108 - acc: 0.9566 - f1_m: 0.8195 - precision_m: 0.8815 - recall_m: 0.7750\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1053 - acc: 0.9533 - f1_m: 0.8251 - precision_m: 0.8696 - recall_m: 0.7931\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0903 - acc: 0.9634 - f1_m: 0.8710 - precision_m: 0.9031 - recall_m: 0.8486\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0877 - acc: 0.9660 - f1_m: 0.8734 - precision_m: 0.9103 - recall_m: 0.8482\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0854 - acc: 0.9685 - f1_m: 0.8837 - precision_m: 0.9113 - recall_m: 0.8717\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 0.9707 - f1_m: 0.8884 - precision_m: 0.9320 - recall_m: 0.8583\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0786 - acc: 0.9671 - f1_m: 0.8791 - precision_m: 0.9066 - recall_m: 0.8596\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0670 - acc: 0.9747 - f1_m: 0.9059 - precision_m: 0.9322 - recall_m: 0.8870\n",
      "153/153 [==============================] - 0s 3ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 32), score=(train=0.979, test=0.944), total=   9.8s\n",
      "[CV] optimizer=rmsprop, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 1s 4ms/step - loss: 0.5193 - acc: 0.7404 - f1_m: 0.1793 - precision_m: 0.1804 - recall_m: 0.2186\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.4500 - acc: 0.8050 - f1_m: 0.1924 - precision_m: 0.2213 - recall_m: 0.1857\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3894 - acc: 0.8246 - f1_m: 0.2293 - precision_m: 0.2841 - recall_m: 0.2032\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3726 - acc: 0.8326 - f1_m: 0.2222 - precision_m: 0.3080 - recall_m: 0.1857\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3536 - acc: 0.8337 - f1_m: 0.2732 - precision_m: 0.3557 - recall_m: 0.2488\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8544 - f1_m: 0.2973 - precision_m: 0.4034 - recall_m: 0.2536\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.8638 - f1_m: 0.2783 - precision_m: 0.5142 - recall_m: 0.2145\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2857 - acc: 0.8722 - f1_m: 0.3337 - precision_m: 0.5563 - recall_m: 0.2722\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2898 - acc: 0.8689 - f1_m: 0.3648 - precision_m: 0.5206 - recall_m: 0.3079\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2845 - acc: 0.8755 - f1_m: 0.4252 - precision_m: 0.5839 - recall_m: 0.3605\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2654 - acc: 0.8831 - f1_m: 0.4660 - precision_m: 0.5873 - recall_m: 0.4112\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2447 - acc: 0.8951 - f1_m: 0.5114 - precision_m: 0.6561 - recall_m: 0.4479\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2347 - acc: 0.8998 - f1_m: 0.5483 - precision_m: 0.6724 - recall_m: 0.4947\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9031 - f1_m: 0.5543 - precision_m: 0.7099 - recall_m: 0.4826\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2178 - acc: 0.8998 - f1_m: 0.5307 - precision_m: 0.6570 - recall_m: 0.4621\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2152 - acc: 0.9092 - f1_m: 0.6016 - precision_m: 0.7407 - recall_m: 0.5283\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2010 - acc: 0.9165 - f1_m: 0.6359 - precision_m: 0.7538 - recall_m: 0.5760\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1896 - acc: 0.9172 - f1_m: 0.6149 - precision_m: 0.7521 - recall_m: 0.5566\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1966 - acc: 0.9208 - f1_m: 0.6245 - precision_m: 0.7911 - recall_m: 0.5385\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1839 - acc: 0.9230 - f1_m: 0.6911 - precision_m: 0.7799 - recall_m: 0.6360\n",
      "154/154 [==============================] - 0s 3ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(32, 16), score=(train=0.947, test=0.914), total=  10.0s\n",
      "[CV] optimizer=rmsprop, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 0.6747 - acc: 0.5997 - f1_m: 0.1971 - precision_m: 0.1415 - recall_m: 0.3651\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.6082 - acc: 0.6652 - f1_m: 0.2251 - precision_m: 0.1733 - recall_m: 0.3538\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5570 - acc: 0.7181 - f1_m: 0.2444 - precision_m: 0.2026 - recall_m: 0.3453\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5134 - acc: 0.7557 - f1_m: 0.2388 - precision_m: 0.2185 - recall_m: 0.2720\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4782 - acc: 0.7799 - f1_m: 0.2077 - precision_m: 0.2199 - recall_m: 0.2146\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4389 - acc: 0.8093 - f1_m: 0.2590 - precision_m: 0.2915 - recall_m: 0.2467\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3984 - acc: 0.8172 - f1_m: 0.2026 - precision_m: 0.2748 - recall_m: 0.1743\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3939 - acc: 0.8169 - f1_m: 0.2038 - precision_m: 0.2795 - recall_m: 0.1828\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3712 - acc: 0.8360 - f1_m: 0.2523 - precision_m: 0.3493 - recall_m: 0.2068\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3604 - acc: 0.8386 - f1_m: 0.1926 - precision_m: 0.3390 - recall_m: 0.1424\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3254 - acc: 0.8552 - f1_m: 0.2398 - precision_m: 0.4278 - recall_m: 0.1755\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3244 - acc: 0.8567 - f1_m: 0.2794 - precision_m: 0.4627 - recall_m: 0.2095\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.8632 - f1_m: 0.2718 - precision_m: 0.5478 - recall_m: 0.1940\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.8599 - f1_m: 0.2502 - precision_m: 0.5090 - recall_m: 0.1813\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2896 - acc: 0.8697 - f1_m: 0.3287 - precision_m: 0.5974 - recall_m: 0.2336\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2854 - acc: 0.8701 - f1_m: 0.3297 - precision_m: 0.6042 - recall_m: 0.2361\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2708 - acc: 0.8791 - f1_m: 0.4044 - precision_m: 0.7052 - recall_m: 0.3020\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2612 - acc: 0.8755 - f1_m: 0.3796 - precision_m: 0.6310 - recall_m: 0.2782\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2593 - acc: 0.8860 - f1_m: 0.4126 - precision_m: 0.6690 - recall_m: 0.3099\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2517 - acc: 0.8867 - f1_m: 0.4307 - precision_m: 0.6095 - recall_m: 0.3506\n",
      "153/153 [==============================] - 0s 3ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(32, 16), score=(train=0.923, test=0.895), total=  10.2s\n",
      "[CV] optimizer=rmsprop, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 0.5097 - acc: 0.7695 - f1_m: 0.1400 - precision_m: 0.1620 - recall_m: 0.1351\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3904 - acc: 0.8205 - f1_m: 0.2459 - precision_m: 0.3025 - recall_m: 0.2131\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.8299 - f1_m: 0.3344 - precision_m: 0.3901 - recall_m: 0.3113\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3242 - acc: 0.8509 - f1_m: 0.3718 - precision_m: 0.4721 - recall_m: 0.3282\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2935 - acc: 0.8650 - f1_m: 0.4387 - precision_m: 0.5398 - recall_m: 0.3905\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2917 - acc: 0.8657 - f1_m: 0.4349 - precision_m: 0.5498 - recall_m: 0.3905\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2643 - acc: 0.8762 - f1_m: 0.4801 - precision_m: 0.6395 - recall_m: 0.4143\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2626 - acc: 0.8853 - f1_m: 0.5265 - precision_m: 0.6328 - recall_m: 0.4674\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2464 - acc: 0.8943 - f1_m: 0.5903 - precision_m: 0.6828 - recall_m: 0.5430\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2207 - acc: 0.9034 - f1_m: 0.5658 - precision_m: 0.7567 - recall_m: 0.4872\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.8972 - f1_m: 0.5847 - precision_m: 0.6748 - recall_m: 0.5377\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2106 - acc: 0.9037 - f1_m: 0.6104 - precision_m: 0.7176 - recall_m: 0.5460\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1966 - acc: 0.9128 - f1_m: 0.6599 - precision_m: 0.7582 - recall_m: 0.6250\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1942 - acc: 0.9121 - f1_m: 0.6598 - precision_m: 0.7396 - recall_m: 0.6278\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1874 - acc: 0.9139 - f1_m: 0.6603 - precision_m: 0.7541 - recall_m: 0.6242\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1874 - acc: 0.9131 - f1_m: 0.6463 - precision_m: 0.7171 - recall_m: 0.6063\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1790 - acc: 0.9197 - f1_m: 0.7099 - precision_m: 0.7665 - recall_m: 0.6796\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1814 - acc: 0.9197 - f1_m: 0.6953 - precision_m: 0.7415 - recall_m: 0.6690\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1771 - acc: 0.9225 - f1_m: 0.7023 - precision_m: 0.7720 - recall_m: 0.6527\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1629 - acc: 0.9236 - f1_m: 0.7111 - precision_m: 0.7805 - recall_m: 0.6655\n",
      "153/153 [==============================] - 1s 3ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(32, 16), score=(train=0.952, test=0.932), total=  10.3s\n",
      "[CV] optimizer=rmsprop, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 1s 5ms/step - loss: 0.4945 - acc: 0.8025 - f1_m: 0.2032 - precision_m: 0.2935 - recall_m: 0.2070\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2924 - acc: 0.8816 - f1_m: 0.4387 - precision_m: 0.6084 - recall_m: 0.3598\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2720 - acc: 0.8940 - f1_m: 0.5259 - precision_m: 0.6728 - recall_m: 0.4660\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2288 - acc: 0.9020 - f1_m: 0.5871 - precision_m: 0.7055 - recall_m: 0.5258\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2092 - acc: 0.9147 - f1_m: 0.6317 - precision_m: 0.7564 - recall_m: 0.5829\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1856 - acc: 0.9208 - f1_m: 0.6167 - precision_m: 0.7799 - recall_m: 0.5663\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1492 - acc: 0.9379 - f1_m: 0.7199 - precision_m: 0.8378 - recall_m: 0.6643\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1393 - acc: 0.9383 - f1_m: 0.7520 - precision_m: 0.8367 - recall_m: 0.7079\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1299 - acc: 0.9466 - f1_m: 0.7616 - precision_m: 0.8610 - recall_m: 0.7093\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1141 - acc: 0.9517 - f1_m: 0.8166 - precision_m: 0.8353 - recall_m: 0.8150\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1105 - acc: 0.9561 - f1_m: 0.8141 - precision_m: 0.8797 - recall_m: 0.7804\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0855 - acc: 0.9677 - f1_m: 0.8572 - precision_m: 0.8995 - recall_m: 0.8276\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0757 - acc: 0.9717 - f1_m: 0.8932 - precision_m: 0.9385 - recall_m: 0.8652\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0830 - acc: 0.9680 - f1_m: 0.8777 - precision_m: 0.9021 - recall_m: 0.8706\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0594 - acc: 0.9760 - f1_m: 0.9005 - precision_m: 0.9486 - recall_m: 0.8657\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0744 - acc: 0.9720 - f1_m: 0.8756 - precision_m: 0.9089 - recall_m: 0.8594\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0604 - acc: 0.9735 - f1_m: 0.8938 - precision_m: 0.9294 - recall_m: 0.8698\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0574 - acc: 0.9793 - f1_m: 0.9076 - precision_m: 0.9608 - recall_m: 0.8676\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0516 - acc: 0.9797 - f1_m: 0.9190 - precision_m: 0.9307 - recall_m: 0.9150\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0474 - acc: 0.9815 - f1_m: 0.9171 - precision_m: 0.9408 - recall_m: 0.9033\n",
      "154/154 [==============================] - 1s 4ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 64), score=(train=0.999, test=0.940), total=  10.9s\n",
      "[CV] optimizer=rmsprop, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 1s 5ms/step - loss: 0.4399 - acc: 0.8227 - f1_m: 0.2187 - precision_m: 0.3442 - recall_m: 0.1814\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3171 - acc: 0.8733 - f1_m: 0.4027 - precision_m: 0.6251 - recall_m: 0.3244\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2442 - acc: 0.8983 - f1_m: 0.5294 - precision_m: 0.7299 - recall_m: 0.4485\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2251 - acc: 0.9070 - f1_m: 0.6060 - precision_m: 0.7394 - recall_m: 0.5310\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1930 - acc: 0.9225 - f1_m: 0.6583 - precision_m: 0.8145 - recall_m: 0.5771\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1729 - acc: 0.9283 - f1_m: 0.6850 - precision_m: 0.8171 - recall_m: 0.6037\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1584 - acc: 0.9345 - f1_m: 0.7446 - precision_m: 0.8410 - recall_m: 0.6830\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1387 - acc: 0.9403 - f1_m: 0.7591 - precision_m: 0.8827 - recall_m: 0.6915\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1133 - acc: 0.9526 - f1_m: 0.8173 - precision_m: 0.8971 - recall_m: 0.7564\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1305 - acc: 0.9472 - f1_m: 0.8118 - precision_m: 0.8570 - recall_m: 0.8032\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9580 - f1_m: 0.8420 - precision_m: 0.8846 - recall_m: 0.8113\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0854 - acc: 0.9663 - f1_m: 0.8615 - precision_m: 0.9054 - recall_m: 0.8310\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0947 - acc: 0.9606 - f1_m: 0.8590 - precision_m: 0.9017 - recall_m: 0.8304\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0813 - acc: 0.9663 - f1_m: 0.8710 - precision_m: 0.8845 - recall_m: 0.8784\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0712 - acc: 0.9750 - f1_m: 0.9004 - precision_m: 0.9487 - recall_m: 0.8656\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0569 - acc: 0.9772 - f1_m: 0.9187 - precision_m: 0.9468 - recall_m: 0.8969\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0643 - acc: 0.9732 - f1_m: 0.8982 - precision_m: 0.9366 - recall_m: 0.8726\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0644 - acc: 0.9758 - f1_m: 0.9210 - precision_m: 0.9521 - recall_m: 0.9013\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0454 - acc: 0.9826 - f1_m: 0.9327 - precision_m: 0.9602 - recall_m: 0.9123\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0488 - acc: 0.9808 - f1_m: 0.9249 - precision_m: 0.9297 - recall_m: 0.9246\n",
      "153/153 [==============================] - 1s 4ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 64), score=(train=0.990, test=0.926), total=  10.9s\n",
      "[CV] optimizer=rmsprop, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.4819 - acc: 0.7959 - f1_m: 0.2188 - precision_m: 0.2887 - recall_m: 0.2158\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3371 - acc: 0.8628 - f1_m: 0.3496 - precision_m: 0.5548 - recall_m: 0.2683\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2711 - acc: 0.8874 - f1_m: 0.4741 - precision_m: 0.6942 - recall_m: 0.3860\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2438 - acc: 0.8954 - f1_m: 0.5249 - precision_m: 0.7579 - recall_m: 0.4245\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2186 - acc: 0.9077 - f1_m: 0.6038 - precision_m: 0.7710 - recall_m: 0.5179\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1921 - acc: 0.9236 - f1_m: 0.6770 - precision_m: 0.8507 - recall_m: 0.5830\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.9330 - f1_m: 0.7210 - precision_m: 0.7948 - recall_m: 0.6779\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1514 - acc: 0.9457 - f1_m: 0.7898 - precision_m: 0.8551 - recall_m: 0.7430\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1350 - acc: 0.9464 - f1_m: 0.7726 - precision_m: 0.8572 - recall_m: 0.7224\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9504 - f1_m: 0.8011 - precision_m: 0.8518 - recall_m: 0.7690\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1119 - acc: 0.9551 - f1_m: 0.8230 - precision_m: 0.8662 - recall_m: 0.8030\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1071 - acc: 0.9540 - f1_m: 0.8320 - precision_m: 0.8698 - recall_m: 0.8098\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0873 - acc: 0.9671 - f1_m: 0.8676 - precision_m: 0.9223 - recall_m: 0.8318\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0770 - acc: 0.9700 - f1_m: 0.9017 - precision_m: 0.9319 - recall_m: 0.8775\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0800 - acc: 0.9689 - f1_m: 0.8738 - precision_m: 0.9011 - recall_m: 0.8598\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0741 - acc: 0.9689 - f1_m: 0.8738 - precision_m: 0.9090 - recall_m: 0.8511\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0724 - acc: 0.9721 - f1_m: 0.8941 - precision_m: 0.9116 - recall_m: 0.8944\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0617 - acc: 0.9772 - f1_m: 0.9154 - precision_m: 0.9288 - recall_m: 0.9132\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0502 - acc: 0.9834 - f1_m: 0.9384 - precision_m: 0.9527 - recall_m: 0.9281\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0573 - acc: 0.9808 - f1_m: 0.9299 - precision_m: 0.9550 - recall_m: 0.9121\n",
      "153/153 [==============================] - 1s 4ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=rmsprop, units=(128, 64), score=(train=0.971, test=0.916), total=  11.2s\n",
      "[CV] optimizer=adam, units=(64, 32) ..................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 2s 6ms/step - loss: 0.5242 - acc: 0.7382 - f1_m: 0.1765 - precision_m: 0.1862 - recall_m: 0.2029\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3617 - acc: 0.8598 - f1_m: 0.3672 - precision_m: 0.4738 - recall_m: 0.3236\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2965 - acc: 0.8704 - f1_m: 0.4122 - precision_m: 0.5218 - recall_m: 0.3605\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2504 - acc: 0.8929 - f1_m: 0.4716 - precision_m: 0.6446 - recall_m: 0.3868\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2210 - acc: 0.9056 - f1_m: 0.5621 - precision_m: 0.7426 - recall_m: 0.4768\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2175 - acc: 0.9049 - f1_m: 0.5733 - precision_m: 0.6769 - recall_m: 0.5108\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1782 - acc: 0.9234 - f1_m: 0.6564 - precision_m: 0.7712 - recall_m: 0.5816\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1779 - acc: 0.9223 - f1_m: 0.6496 - precision_m: 0.7617 - recall_m: 0.5919\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1678 - acc: 0.9343 - f1_m: 0.7054 - precision_m: 0.8381 - recall_m: 0.6245\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 0.9339 - f1_m: 0.7247 - precision_m: 0.8263 - recall_m: 0.6565\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1432 - acc: 0.9452 - f1_m: 0.7774 - precision_m: 0.8683 - recall_m: 0.7113\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1508 - acc: 0.9365 - f1_m: 0.7411 - precision_m: 0.8084 - recall_m: 0.6937\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1412 - acc: 0.9419 - f1_m: 0.7538 - precision_m: 0.8273 - recall_m: 0.7080\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1292 - acc: 0.9484 - f1_m: 0.7920 - precision_m: 0.8711 - recall_m: 0.7337\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9517 - f1_m: 0.7819 - precision_m: 0.9039 - recall_m: 0.7118\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0998 - acc: 0.9608 - f1_m: 0.8447 - precision_m: 0.9067 - recall_m: 0.7942\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0950 - acc: 0.9619 - f1_m: 0.8430 - precision_m: 0.8945 - recall_m: 0.8060\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0960 - acc: 0.9641 - f1_m: 0.8522 - precision_m: 0.9074 - recall_m: 0.8084\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0967 - acc: 0.9619 - f1_m: 0.8474 - precision_m: 0.8792 - recall_m: 0.8337\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0820 - acc: 0.9648 - f1_m: 0.8484 - precision_m: 0.8955 - recall_m: 0.8135\n",
      "154/154 [==============================] - 1s 4ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(64, 32), score=(train=0.988, test=0.929), total=  11.6s\n",
      "[CV] optimizer=adam, units=(64, 32) ..................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 2s 6ms/step - loss: 0.5538 - acc: 0.7050 - f1_m: 0.2504 - precision_m: 0.2050 - recall_m: 0.3544\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4283 - acc: 0.8071 - f1_m: 0.3633 - precision_m: 0.3450 - recall_m: 0.4089\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3374 - acc: 0.8628 - f1_m: 0.5034 - precision_m: 0.5222 - recall_m: 0.5018\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3017 - acc: 0.8766 - f1_m: 0.5356 - precision_m: 0.5668 - recall_m: 0.5182\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2827 - acc: 0.8871 - f1_m: 0.5358 - precision_m: 0.5932 - recall_m: 0.4975\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2322 - acc: 0.9048 - f1_m: 0.5780 - precision_m: 0.6683 - recall_m: 0.5278\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2260 - acc: 0.9081 - f1_m: 0.6185 - precision_m: 0.7119 - recall_m: 0.5584\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2034 - acc: 0.9229 - f1_m: 0.6524 - precision_m: 0.7107 - recall_m: 0.6163\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1886 - acc: 0.9254 - f1_m: 0.6689 - precision_m: 0.7880 - recall_m: 0.5898\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1848 - acc: 0.9251 - f1_m: 0.7086 - precision_m: 0.7578 - recall_m: 0.6754\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1660 - acc: 0.9327 - f1_m: 0.6867 - precision_m: 0.8078 - recall_m: 0.6122\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1667 - acc: 0.9345 - f1_m: 0.7199 - precision_m: 0.7797 - recall_m: 0.6827\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1537 - acc: 0.9374 - f1_m: 0.7304 - precision_m: 0.8169 - recall_m: 0.6746\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1436 - acc: 0.9414 - f1_m: 0.7601 - precision_m: 0.8487 - recall_m: 0.7043\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1467 - acc: 0.9385 - f1_m: 0.7404 - precision_m: 0.8351 - recall_m: 0.6749\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1319 - acc: 0.9461 - f1_m: 0.7906 - precision_m: 0.8290 - recall_m: 0.7618\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9479 - f1_m: 0.7793 - precision_m: 0.8425 - recall_m: 0.7309\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1188 - acc: 0.9573 - f1_m: 0.8415 - precision_m: 0.9065 - recall_m: 0.7926\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1162 - acc: 0.9533 - f1_m: 0.8125 - precision_m: 0.8801 - recall_m: 0.7576\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1081 - acc: 0.9555 - f1_m: 0.8406 - precision_m: 0.8580 - recall_m: 0.8299\n",
      "153/153 [==============================] - 1s 5ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(64, 32), score=(train=0.978, test=0.938), total=  11.9s\n",
      "[CV] optimizer=adam, units=(64, 32) ..................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 2s 7ms/step - loss: 0.5204 - acc: 0.7611 - f1_m: 0.2194 - precision_m: 0.2390 - recall_m: 0.2402\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3675 - acc: 0.8455 - f1_m: 0.3264 - precision_m: 0.4523 - recall_m: 0.2651\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2979 - acc: 0.8838 - f1_m: 0.5172 - precision_m: 0.6610 - recall_m: 0.4368\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2667 - acc: 0.8878 - f1_m: 0.5263 - precision_m: 0.6293 - recall_m: 0.4651\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2272 - acc: 0.9055 - f1_m: 0.5989 - precision_m: 0.7507 - recall_m: 0.5181\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2145 - acc: 0.9081 - f1_m: 0.5878 - precision_m: 0.7752 - recall_m: 0.5029\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1943 - acc: 0.9204 - f1_m: 0.6693 - precision_m: 0.8170 - recall_m: 0.5899\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1728 - acc: 0.9269 - f1_m: 0.6754 - precision_m: 0.8142 - recall_m: 0.5899\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1513 - acc: 0.9392 - f1_m: 0.7401 - precision_m: 0.8036 - recall_m: 0.6955\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9428 - f1_m: 0.7587 - precision_m: 0.8479 - recall_m: 0.7007\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1583 - acc: 0.9327 - f1_m: 0.7272 - precision_m: 0.8293 - recall_m: 0.6602\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1389 - acc: 0.9482 - f1_m: 0.7909 - precision_m: 0.8651 - recall_m: 0.7397\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9526 - f1_m: 0.8250 - precision_m: 0.8656 - recall_m: 0.7943\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1362 - acc: 0.9428 - f1_m: 0.7687 - precision_m: 0.8449 - recall_m: 0.7187\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1145 - acc: 0.9548 - f1_m: 0.8304 - precision_m: 0.8854 - recall_m: 0.7890\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1127 - acc: 0.9544 - f1_m: 0.8257 - precision_m: 0.8907 - recall_m: 0.7783\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1026 - acc: 0.9616 - f1_m: 0.8497 - precision_m: 0.8911 - recall_m: 0.8183\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1073 - acc: 0.9558 - f1_m: 0.8334 - precision_m: 0.8885 - recall_m: 0.7955\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0919 - acc: 0.9660 - f1_m: 0.8625 - precision_m: 0.9129 - recall_m: 0.8276\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0931 - acc: 0.9627 - f1_m: 0.8579 - precision_m: 0.9031 - recall_m: 0.8282\n",
      "153/153 [==============================] - 1s 5ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(64, 32), score=(train=0.989, test=0.946), total=  12.4s\n",
      "[CV] optimizer=adam, units=(128, 32) .................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 2s 7ms/step - loss: 0.5677 - acc: 0.7106 - f1_m: 0.1617 - precision_m: 0.1442 - recall_m: 0.2243\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.4324 - acc: 0.8028 - f1_m: 0.2218 - precision_m: 0.2362 - recall_m: 0.2145\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3503 - acc: 0.8537 - f1_m: 0.3904 - precision_m: 0.4564 - recall_m: 0.3678\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2979 - acc: 0.8609 - f1_m: 0.4042 - precision_m: 0.4702 - recall_m: 0.3732\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2715 - acc: 0.8871 - f1_m: 0.4573 - precision_m: 0.5844 - recall_m: 0.3917\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2321 - acc: 0.9001 - f1_m: 0.5433 - precision_m: 0.6720 - recall_m: 0.4816\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2167 - acc: 0.9085 - f1_m: 0.5911 - precision_m: 0.6949 - recall_m: 0.5355\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1926 - acc: 0.9150 - f1_m: 0.5785 - precision_m: 0.6679 - recall_m: 0.5203\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1847 - acc: 0.9267 - f1_m: 0.6970 - precision_m: 0.7711 - recall_m: 0.6517\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1627 - acc: 0.9354 - f1_m: 0.7415 - precision_m: 0.7688 - recall_m: 0.7326\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1428 - acc: 0.9430 - f1_m: 0.7729 - precision_m: 0.8306 - recall_m: 0.7357\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1443 - acc: 0.9448 - f1_m: 0.7697 - precision_m: 0.8250 - recall_m: 0.7373\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1352 - acc: 0.9463 - f1_m: 0.7778 - precision_m: 0.8312 - recall_m: 0.7398\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1265 - acc: 0.9495 - f1_m: 0.7785 - precision_m: 0.8174 - recall_m: 0.7476\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1176 - acc: 0.9532 - f1_m: 0.7971 - precision_m: 0.8614 - recall_m: 0.7517\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9564 - f1_m: 0.8161 - precision_m: 0.8625 - recall_m: 0.7846\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1097 - acc: 0.9521 - f1_m: 0.8011 - precision_m: 0.8540 - recall_m: 0.7729\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0879 - acc: 0.9659 - f1_m: 0.8608 - precision_m: 0.8966 - recall_m: 0.8355\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0941 - acc: 0.9575 - f1_m: 0.8276 - precision_m: 0.8628 - recall_m: 0.8149\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0836 - acc: 0.9670 - f1_m: 0.8734 - precision_m: 0.8890 - recall_m: 0.8645\n",
      "154/154 [==============================] - 1s 5ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 32), score=(train=0.991, test=0.937), total=  12.6s\n",
      "[CV] optimizer=adam, units=(128, 32) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 2s 7ms/step - loss: 0.5104 - acc: 0.7752 - f1_m: 0.1830 - precision_m: 0.2152 - recall_m: 0.1935\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3907 - acc: 0.8277 - f1_m: 0.2235 - precision_m: 0.3342 - recall_m: 0.1739\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3121 - acc: 0.8697 - f1_m: 0.3830 - precision_m: 0.5729 - recall_m: 0.2984\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2846 - acc: 0.8795 - f1_m: 0.4820 - precision_m: 0.6344 - recall_m: 0.4104\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2388 - acc: 0.9026 - f1_m: 0.6078 - precision_m: 0.7023 - recall_m: 0.5518\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2295 - acc: 0.9142 - f1_m: 0.6495 - precision_m: 0.7264 - recall_m: 0.6056\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1992 - acc: 0.9186 - f1_m: 0.6576 - precision_m: 0.7449 - recall_m: 0.6056\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1699 - acc: 0.9298 - f1_m: 0.7178 - precision_m: 0.7946 - recall_m: 0.6739\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1689 - acc: 0.9312 - f1_m: 0.7436 - precision_m: 0.7979 - recall_m: 0.7216\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1466 - acc: 0.9425 - f1_m: 0.7761 - precision_m: 0.8242 - recall_m: 0.7408\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1487 - acc: 0.9377 - f1_m: 0.7556 - precision_m: 0.8269 - recall_m: 0.7129\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1337 - acc: 0.9425 - f1_m: 0.7526 - precision_m: 0.8116 - recall_m: 0.7231\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9468 - f1_m: 0.7822 - precision_m: 0.8551 - recall_m: 0.7394\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1174 - acc: 0.9501 - f1_m: 0.8054 - precision_m: 0.8491 - recall_m: 0.7731\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1033 - acc: 0.9587 - f1_m: 0.8497 - precision_m: 0.8818 - recall_m: 0.8255\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0976 - acc: 0.9671 - f1_m: 0.8772 - precision_m: 0.9014 - recall_m: 0.8602\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0919 - acc: 0.9634 - f1_m: 0.8672 - precision_m: 0.9004 - recall_m: 0.8501\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0821 - acc: 0.9692 - f1_m: 0.8735 - precision_m: 0.9033 - recall_m: 0.8520\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0857 - acc: 0.9663 - f1_m: 0.8762 - precision_m: 0.9121 - recall_m: 0.8478\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0760 - acc: 0.9729 - f1_m: 0.8981 - precision_m: 0.9191 - recall_m: 0.8847\n",
      "153/153 [==============================] - 1s 6ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 32), score=(train=0.995, test=0.952), total=  12.8s\n",
      "[CV] optimizer=adam, units=(128, 32) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 0.5501 - acc: 0.7398 - f1_m: 0.1753 - precision_m: 0.1796 - recall_m: 0.1881\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3734 - acc: 0.8382 - f1_m: 0.2386 - precision_m: 0.3912 - recall_m: 0.1857\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2940 - acc: 0.8668 - f1_m: 0.3958 - precision_m: 0.5871 - recall_m: 0.3074\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2600 - acc: 0.8788 - f1_m: 0.4879 - precision_m: 0.6230 - recall_m: 0.4130\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2341 - acc: 0.8896 - f1_m: 0.5468 - precision_m: 0.6876 - recall_m: 0.4601\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2202 - acc: 0.9063 - f1_m: 0.5947 - precision_m: 0.7680 - recall_m: 0.5010\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2036 - acc: 0.9110 - f1_m: 0.6507 - precision_m: 0.7594 - recall_m: 0.5813\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1854 - acc: 0.9164 - f1_m: 0.6642 - precision_m: 0.7737 - recall_m: 0.5974\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1787 - acc: 0.9225 - f1_m: 0.6884 - precision_m: 0.7983 - recall_m: 0.6214\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1566 - acc: 0.9363 - f1_m: 0.7459 - precision_m: 0.8417 - recall_m: 0.6856\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1465 - acc: 0.9370 - f1_m: 0.7804 - precision_m: 0.8174 - recall_m: 0.7660\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1332 - acc: 0.9417 - f1_m: 0.7712 - precision_m: 0.8622 - recall_m: 0.7160\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1321 - acc: 0.9406 - f1_m: 0.7659 - precision_m: 0.8631 - recall_m: 0.6986\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9497 - f1_m: 0.8244 - precision_m: 0.8788 - recall_m: 0.7861\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9555 - f1_m: 0.8330 - precision_m: 0.8672 - recall_m: 0.8088\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1007 - acc: 0.9566 - f1_m: 0.8332 - precision_m: 0.8853 - recall_m: 0.7973\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0894 - acc: 0.9616 - f1_m: 0.8580 - precision_m: 0.8957 - recall_m: 0.8309\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0812 - acc: 0.9692 - f1_m: 0.8948 - precision_m: 0.9110 - recall_m: 0.8901\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0732 - acc: 0.9689 - f1_m: 0.8742 - precision_m: 0.9024 - recall_m: 0.8525\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9671 - f1_m: 0.8827 - precision_m: 0.9096 - recall_m: 0.8691\n",
      "153/153 [==============================] - 1s 6ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 32), score=(train=0.995, test=0.951), total=  13.0s\n",
      "[CV] optimizer=adam, units=(32, 16) ..................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 2s 8ms/step - loss: 0.5529 - acc: 0.7237 - f1_m: 0.2288 - precision_m: 0.1937 - recall_m: 0.3105\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.4345 - acc: 0.7948 - f1_m: 0.3034 - precision_m: 0.2880 - recall_m: 0.3391\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3761 - acc: 0.8286 - f1_m: 0.3238 - precision_m: 0.3448 - recall_m: 0.3173\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3214 - acc: 0.8646 - f1_m: 0.3834 - precision_m: 0.4695 - recall_m: 0.3316\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.8696 - f1_m: 0.3737 - precision_m: 0.4737 - recall_m: 0.3245\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2793 - acc: 0.8762 - f1_m: 0.3862 - precision_m: 0.5301 - recall_m: 0.3255\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2600 - acc: 0.8954 - f1_m: 0.5222 - precision_m: 0.6669 - recall_m: 0.4431\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2425 - acc: 0.8991 - f1_m: 0.5058 - precision_m: 0.7086 - recall_m: 0.4104\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2367 - acc: 0.9049 - f1_m: 0.5379 - precision_m: 0.7396 - recall_m: 0.4392\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9110 - f1_m: 0.5881 - precision_m: 0.7765 - recall_m: 0.4937\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2189 - acc: 0.9085 - f1_m: 0.5876 - precision_m: 0.7218 - recall_m: 0.5043\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2172 - acc: 0.9056 - f1_m: 0.5309 - precision_m: 0.7745 - recall_m: 0.4219\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2042 - acc: 0.9143 - f1_m: 0.6098 - precision_m: 0.7433 - recall_m: 0.5280\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1788 - acc: 0.9208 - f1_m: 0.6438 - precision_m: 0.7756 - recall_m: 0.5678\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1861 - acc: 0.9165 - f1_m: 0.6085 - precision_m: 0.7785 - recall_m: 0.5142\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1849 - acc: 0.9219 - f1_m: 0.6419 - precision_m: 0.7878 - recall_m: 0.5604\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1737 - acc: 0.9252 - f1_m: 0.6102 - precision_m: 0.7176 - recall_m: 0.5424\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1782 - acc: 0.9219 - f1_m: 0.6306 - precision_m: 0.7919 - recall_m: 0.5380\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1692 - acc: 0.9245 - f1_m: 0.6477 - precision_m: 0.7861 - recall_m: 0.5622\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.9223 - f1_m: 0.6562 - precision_m: 0.7712 - recall_m: 0.5954\n",
      "154/154 [==============================] - 1s 6ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(32, 16), score=(train=0.960, test=0.923), total=  13.2s\n",
      "[CV] optimizer=adam, units=(32, 16) ..................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 8ms/step - loss: 0.6684 - acc: 0.6149 - f1_m: 0.2299 - precision_m: 0.1639 - recall_m: 0.4011\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.6068 - acc: 0.6620 - f1_m: 0.2619 - precision_m: 0.1926 - recall_m: 0.4363\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5603 - acc: 0.7036 - f1_m: 0.2866 - precision_m: 0.2245 - recall_m: 0.4417\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5047 - acc: 0.7434 - f1_m: 0.2978 - precision_m: 0.2486 - recall_m: 0.3873\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4332 - acc: 0.8038 - f1_m: 0.3724 - precision_m: 0.3407 - recall_m: 0.4344\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3834 - acc: 0.8447 - f1_m: 0.4273 - precision_m: 0.4504 - recall_m: 0.4234\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3549 - acc: 0.8502 - f1_m: 0.4138 - precision_m: 0.4569 - recall_m: 0.3891\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3199 - acc: 0.8607 - f1_m: 0.4276 - precision_m: 0.5037 - recall_m: 0.3918\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2930 - acc: 0.8853 - f1_m: 0.5067 - precision_m: 0.5800 - recall_m: 0.4678\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2953 - acc: 0.8704 - f1_m: 0.4320 - precision_m: 0.5379 - recall_m: 0.3737\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2638 - acc: 0.8976 - f1_m: 0.5545 - precision_m: 0.6482 - recall_m: 0.4902\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2714 - acc: 0.8849 - f1_m: 0.4787 - precision_m: 0.5798 - recall_m: 0.4222\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2453 - acc: 0.9059 - f1_m: 0.5957 - precision_m: 0.7325 - recall_m: 0.5222\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2273 - acc: 0.9099 - f1_m: 0.5966 - precision_m: 0.7682 - recall_m: 0.4991\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2317 - acc: 0.9092 - f1_m: 0.6211 - precision_m: 0.7523 - recall_m: 0.5386\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2284 - acc: 0.9052 - f1_m: 0.5797 - precision_m: 0.7285 - recall_m: 0.5062\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2047 - acc: 0.9139 - f1_m: 0.6465 - precision_m: 0.7624 - recall_m: 0.5766\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2210 - acc: 0.9110 - f1_m: 0.6212 - precision_m: 0.7680 - recall_m: 0.5277\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2200 - acc: 0.9102 - f1_m: 0.5972 - precision_m: 0.7276 - recall_m: 0.5208\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1989 - acc: 0.9139 - f1_m: 0.6173 - precision_m: 0.7326 - recall_m: 0.5409\n",
      "153/153 [==============================] - 1s 7ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(32, 16), score=(train=0.940, test=0.922), total=  13.7s\n",
      "[CV] optimizer=adam, units=(32, 16) ..................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 9ms/step - loss: 0.6799 - acc: 0.5414 - f1_m: 0.2002 - precision_m: 0.1382 - recall_m: 0.3921\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.6416 - acc: 0.5986 - f1_m: 0.2090 - precision_m: 0.1509 - recall_m: 0.3808\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5937 - acc: 0.6446 - f1_m: 0.1984 - precision_m: 0.1501 - recall_m: 0.3166\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5420 - acc: 0.6902 - f1_m: 0.2031 - precision_m: 0.1673 - recall_m: 0.2822\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4817 - acc: 0.7633 - f1_m: 0.1839 - precision_m: 0.1947 - recall_m: 0.1914\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4387 - acc: 0.7955 - f1_m: 0.1656 - precision_m: 0.2030 - recall_m: 0.1478\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3992 - acc: 0.8248 - f1_m: 0.2353 - precision_m: 0.3171 - recall_m: 0.1968\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3670 - acc: 0.8306 - f1_m: 0.1865 - precision_m: 0.2497 - recall_m: 0.1743\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3469 - acc: 0.8487 - f1_m: 0.2637 - precision_m: 0.4073 - recall_m: 0.2021\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3351 - acc: 0.8498 - f1_m: 0.3198 - precision_m: 0.4279 - recall_m: 0.2617\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3172 - acc: 0.8607 - f1_m: 0.3053 - precision_m: 0.4844 - recall_m: 0.2362\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.8701 - f1_m: 0.3516 - precision_m: 0.5631 - recall_m: 0.2661\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2932 - acc: 0.8730 - f1_m: 0.4005 - precision_m: 0.6050 - recall_m: 0.3099\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2689 - acc: 0.8853 - f1_m: 0.4779 - precision_m: 0.6714 - recall_m: 0.3843\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2734 - acc: 0.8817 - f1_m: 0.4149 - precision_m: 0.7101 - recall_m: 0.3005\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2630 - acc: 0.8925 - f1_m: 0.4604 - precision_m: 0.7252 - recall_m: 0.3585\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.8842 - f1_m: 0.4466 - precision_m: 0.7020 - recall_m: 0.3378\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2636 - acc: 0.8918 - f1_m: 0.4905 - precision_m: 0.7148 - recall_m: 0.3878\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.8987 - f1_m: 0.5189 - precision_m: 0.7288 - recall_m: 0.4168\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2346 - acc: 0.9016 - f1_m: 0.5651 - precision_m: 0.7432 - recall_m: 0.4660\n",
      "153/153 [==============================] - 1s 7ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(32, 16), score=(train=0.934, test=0.916), total=  14.0s\n",
      "[CV] optimizer=adam, units=(128, 64) .................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 3s 9ms/step - loss: 0.4832 - acc: 0.7930 - f1_m: 0.1941 - precision_m: 0.2244 - recall_m: 0.1910\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3471 - acc: 0.8606 - f1_m: 0.3364 - precision_m: 0.4703 - recall_m: 0.2756\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.8929 - f1_m: 0.4395 - precision_m: 0.6903 - recall_m: 0.3384\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2135 - acc: 0.9063 - f1_m: 0.5545 - precision_m: 0.7618 - recall_m: 0.4517\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1981 - acc: 0.9161 - f1_m: 0.6136 - precision_m: 0.8206 - recall_m: 0.5011\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1708 - acc: 0.9277 - f1_m: 0.6705 - precision_m: 0.8251 - recall_m: 0.5873\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1465 - acc: 0.9415 - f1_m: 0.7518 - precision_m: 0.8624 - recall_m: 0.6825\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1434 - acc: 0.9394 - f1_m: 0.7428 - precision_m: 0.8579 - recall_m: 0.6675\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1616 - acc: 0.9386 - f1_m: 0.7387 - precision_m: 0.8529 - recall_m: 0.6860\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1256 - acc: 0.9477 - f1_m: 0.7868 - precision_m: 0.8779 - recall_m: 0.7248\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9590 - f1_m: 0.8372 - precision_m: 0.9216 - recall_m: 0.7745\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0962 - acc: 0.9633 - f1_m: 0.8535 - precision_m: 0.9031 - recall_m: 0.8200\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0804 - acc: 0.9702 - f1_m: 0.8921 - precision_m: 0.9222 - recall_m: 0.8697\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0870 - acc: 0.9590 - f1_m: 0.8373 - precision_m: 0.8917 - recall_m: 0.8058\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 0.9717 - f1_m: 0.8806 - precision_m: 0.9297 - recall_m: 0.8511\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0655 - acc: 0.9764 - f1_m: 0.9180 - precision_m: 0.9275 - recall_m: 0.9117\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0531 - acc: 0.9826 - f1_m: 0.9270 - precision_m: 0.9573 - recall_m: 0.9026\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0516 - acc: 0.9822 - f1_m: 0.9256 - precision_m: 0.9611 - recall_m: 0.8998\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0471 - acc: 0.9840 - f1_m: 0.9340 - precision_m: 0.9367 - recall_m: 0.9362\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0413 - acc: 0.9855 - f1_m: 0.9475 - precision_m: 0.9617 - recall_m: 0.9379\n",
      "154/154 [==============================] - 1s 7ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 64), score=(train=0.995, test=0.937), total=  14.3s\n",
      "[CV] optimizer=adam, units=(128, 64) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 0.4848 - acc: 0.7999 - f1_m: 0.1747 - precision_m: 0.2482 - recall_m: 0.1594\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3319 - acc: 0.8697 - f1_m: 0.3922 - precision_m: 0.5213 - recall_m: 0.3266\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2610 - acc: 0.8983 - f1_m: 0.5550 - precision_m: 0.7095 - recall_m: 0.4665\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2211 - acc: 0.9149 - f1_m: 0.6585 - precision_m: 0.7793 - recall_m: 0.5841\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1970 - acc: 0.9204 - f1_m: 0.6600 - precision_m: 0.7768 - recall_m: 0.6041\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1652 - acc: 0.9334 - f1_m: 0.7001 - precision_m: 0.8587 - recall_m: 0.6104\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1480 - acc: 0.9417 - f1_m: 0.7450 - precision_m: 0.8283 - recall_m: 0.6973\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1346 - acc: 0.9486 - f1_m: 0.7974 - precision_m: 0.9019 - recall_m: 0.7252\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1178 - acc: 0.9519 - f1_m: 0.8174 - precision_m: 0.8820 - recall_m: 0.7810\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1043 - acc: 0.9602 - f1_m: 0.8408 - precision_m: 0.9147 - recall_m: 0.7888\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1001 - acc: 0.9616 - f1_m: 0.8537 - precision_m: 0.9049 - recall_m: 0.8169\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0859 - acc: 0.9663 - f1_m: 0.8758 - precision_m: 0.9019 - recall_m: 0.8568\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0763 - acc: 0.9732 - f1_m: 0.8897 - precision_m: 0.9290 - recall_m: 0.8641\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0727 - acc: 0.9747 - f1_m: 0.9044 - precision_m: 0.9273 - recall_m: 0.8911\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0663 - acc: 0.9747 - f1_m: 0.9032 - precision_m: 0.9340 - recall_m: 0.8804\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0679 - acc: 0.9743 - f1_m: 0.8787 - precision_m: 0.9175 - recall_m: 0.8515\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0592 - acc: 0.9779 - f1_m: 0.9146 - precision_m: 0.9251 - recall_m: 0.9183\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0430 - acc: 0.9859 - f1_m: 0.9385 - precision_m: 0.9648 - recall_m: 0.9173\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0456 - acc: 0.9823 - f1_m: 0.9243 - precision_m: 0.9519 - recall_m: 0.9039\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0462 - acc: 0.9837 - f1_m: 0.9393 - precision_m: 0.9498 - recall_m: 0.9319\n",
      "153/153 [==============================] - 1s 8ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 64), score=(train=0.996, test=0.946), total=  14.7s\n",
      "[CV] optimizer=adam, units=(128, 64) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 0.4495 - acc: 0.8140 - f1_m: 0.1833 - precision_m: 0.3169 - recall_m: 0.1676\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2964 - acc: 0.8827 - f1_m: 0.4774 - precision_m: 0.6733 - recall_m: 0.3904\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2517 - acc: 0.8950 - f1_m: 0.5565 - precision_m: 0.7441 - recall_m: 0.4804\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2244 - acc: 0.9059 - f1_m: 0.6339 - precision_m: 0.7569 - recall_m: 0.5589\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2038 - acc: 0.9240 - f1_m: 0.6701 - precision_m: 0.7803 - recall_m: 0.5920\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1668 - acc: 0.9341 - f1_m: 0.7450 - precision_m: 0.8116 - recall_m: 0.7057\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1408 - acc: 0.9403 - f1_m: 0.7605 - precision_m: 0.8532 - recall_m: 0.6949\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1145 - acc: 0.9562 - f1_m: 0.8335 - precision_m: 0.9025 - recall_m: 0.7851\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1207 - acc: 0.9537 - f1_m: 0.8250 - precision_m: 0.8892 - recall_m: 0.7795\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9526 - f1_m: 0.8158 - precision_m: 0.8908 - recall_m: 0.7702\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0868 - acc: 0.9700 - f1_m: 0.8884 - precision_m: 0.9188 - recall_m: 0.8649\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0706 - acc: 0.9743 - f1_m: 0.9062 - precision_m: 0.9397 - recall_m: 0.8828\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0800 - acc: 0.9700 - f1_m: 0.8768 - precision_m: 0.9148 - recall_m: 0.8516\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0706 - acc: 0.9743 - f1_m: 0.9060 - precision_m: 0.9339 - recall_m: 0.8840\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0685 - acc: 0.9743 - f1_m: 0.9081 - precision_m: 0.9336 - recall_m: 0.8878\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0560 - acc: 0.9772 - f1_m: 0.9141 - precision_m: 0.9475 - recall_m: 0.8873\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0491 - acc: 0.9834 - f1_m: 0.9374 - precision_m: 0.9608 - recall_m: 0.9204\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0500 - acc: 0.9830 - f1_m: 0.9409 - precision_m: 0.9471 - recall_m: 0.9383\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0501 - acc: 0.9805 - f1_m: 0.9295 - precision_m: 0.9460 - recall_m: 0.9178\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0464 - acc: 0.9805 - f1_m: 0.9289 - precision_m: 0.9471 - recall_m: 0.9187\n",
      "153/153 [==============================] - 1s 8ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adam, units=(128, 64), score=(train=0.998, test=0.956), total=  15.2s\n",
      "[CV] optimizer=adagrad, units=(64, 32) ...............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 3s 10ms/step - loss: 0.6553 - acc: 0.7967 - f1_m: 0.1705 - precision_m: 0.2478 - recall_m: 0.1741\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3127 - acc: 0.8773 - f1_m: 0.3610 - precision_m: 0.6150 - recall_m: 0.2677\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.8882 - f1_m: 0.3684 - precision_m: 0.6112 - recall_m: 0.2735\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2521 - acc: 0.8958 - f1_m: 0.4664 - precision_m: 0.7007 - recall_m: 0.3581\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2473 - acc: 0.8983 - f1_m: 0.4814 - precision_m: 0.7326 - recall_m: 0.3695\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2286 - acc: 0.9023 - f1_m: 0.5105 - precision_m: 0.7190 - recall_m: 0.4237\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2080 - acc: 0.9099 - f1_m: 0.5550 - precision_m: 0.7275 - recall_m: 0.4670\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1934 - acc: 0.9208 - f1_m: 0.6394 - precision_m: 0.8102 - recall_m: 0.5460\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1948 - acc: 0.9136 - f1_m: 0.6116 - precision_m: 0.7407 - recall_m: 0.5410\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1935 - acc: 0.9161 - f1_m: 0.5887 - precision_m: 0.8180 - recall_m: 0.4785\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1853 - acc: 0.9158 - f1_m: 0.6145 - precision_m: 0.7255 - recall_m: 0.5478\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1763 - acc: 0.9245 - f1_m: 0.6644 - precision_m: 0.8119 - recall_m: 0.5772\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1733 - acc: 0.9252 - f1_m: 0.6688 - precision_m: 0.8105 - recall_m: 0.5830\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1695 - acc: 0.9259 - f1_m: 0.6607 - precision_m: 0.7971 - recall_m: 0.5757\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1640 - acc: 0.9303 - f1_m: 0.6785 - precision_m: 0.8630 - recall_m: 0.5734\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1612 - acc: 0.9285 - f1_m: 0.6987 - precision_m: 0.8259 - recall_m: 0.6169\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9365 - f1_m: 0.7054 - precision_m: 0.8183 - recall_m: 0.6332\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9346 - f1_m: 0.7039 - precision_m: 0.8203 - recall_m: 0.6312\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1380 - acc: 0.9405 - f1_m: 0.7077 - precision_m: 0.8307 - recall_m: 0.6275\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1555 - acc: 0.9306 - f1_m: 0.6662 - precision_m: 0.7936 - recall_m: 0.5852\n",
      "154/154 [==============================] - 1s 9ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(64, 32), score=(train=0.966, test=0.925), total=  15.0s\n",
      "[CV] optimizer=adagrad, units=(64, 32) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 0.5947 - acc: 0.7825 - f1_m: 0.2367 - precision_m: 0.2732 - recall_m: 0.2507\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3566 - acc: 0.8560 - f1_m: 0.3008 - precision_m: 0.4555 - recall_m: 0.2395\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2919 - acc: 0.8809 - f1_m: 0.4377 - precision_m: 0.6260 - recall_m: 0.3510\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2783 - acc: 0.8867 - f1_m: 0.4245 - precision_m: 0.6511 - recall_m: 0.3262\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.8943 - f1_m: 0.4977 - precision_m: 0.7011 - recall_m: 0.4038\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2457 - acc: 0.8969 - f1_m: 0.5149 - precision_m: 0.6932 - recall_m: 0.4250\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2332 - acc: 0.9037 - f1_m: 0.5798 - precision_m: 0.7134 - recall_m: 0.5054\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2238 - acc: 0.9088 - f1_m: 0.6036 - precision_m: 0.7334 - recall_m: 0.5463\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2112 - acc: 0.9135 - f1_m: 0.6250 - precision_m: 0.7442 - recall_m: 0.5518\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2049 - acc: 0.9160 - f1_m: 0.6480 - precision_m: 0.7771 - recall_m: 0.5722\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1975 - acc: 0.9175 - f1_m: 0.6436 - precision_m: 0.7815 - recall_m: 0.5651\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1787 - acc: 0.9280 - f1_m: 0.6818 - precision_m: 0.8455 - recall_m: 0.5859\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1785 - acc: 0.9280 - f1_m: 0.7191 - precision_m: 0.7926 - recall_m: 0.6653\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1646 - acc: 0.9352 - f1_m: 0.7318 - precision_m: 0.8525 - recall_m: 0.6569\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1614 - acc: 0.9334 - f1_m: 0.7350 - precision_m: 0.8210 - recall_m: 0.6732\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1680 - acc: 0.9291 - f1_m: 0.6852 - precision_m: 0.8004 - recall_m: 0.6242\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1556 - acc: 0.9345 - f1_m: 0.7297 - precision_m: 0.8224 - recall_m: 0.6655\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1476 - acc: 0.9377 - f1_m: 0.7286 - precision_m: 0.8080 - recall_m: 0.6786\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1374 - acc: 0.9421 - f1_m: 0.7656 - precision_m: 0.8631 - recall_m: 0.6974\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1318 - acc: 0.9453 - f1_m: 0.7880 - precision_m: 0.8647 - recall_m: 0.7313\n",
      "153/153 [==============================] - 1s 9ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(64, 32), score=(train=0.969, test=0.932), total=  15.3s\n",
      "[CV] optimizer=adagrad, units=(64, 32) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 0.5984 - acc: 0.7333 - f1_m: 0.1909 - precision_m: 0.2010 - recall_m: 0.2451\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3954 - acc: 0.8263 - f1_m: 0.1839 - precision_m: 0.3327 - recall_m: 0.1458\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3376 - acc: 0.8480 - f1_m: 0.2609 - precision_m: 0.4621 - recall_m: 0.2073\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3152 - acc: 0.8541 - f1_m: 0.2833 - precision_m: 0.4762 - recall_m: 0.2117\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2907 - acc: 0.8693 - f1_m: 0.3896 - precision_m: 0.6068 - recall_m: 0.3071\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2873 - acc: 0.8773 - f1_m: 0.4691 - precision_m: 0.6606 - recall_m: 0.3779\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2712 - acc: 0.8777 - f1_m: 0.4420 - precision_m: 0.6723 - recall_m: 0.3492\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2607 - acc: 0.8885 - f1_m: 0.4709 - precision_m: 0.7167 - recall_m: 0.3729\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.8979 - f1_m: 0.5625 - precision_m: 0.7425 - recall_m: 0.4763\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.8965 - f1_m: 0.5336 - precision_m: 0.7312 - recall_m: 0.4483\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2325 - acc: 0.8979 - f1_m: 0.5401 - precision_m: 0.7130 - recall_m: 0.4501\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2230 - acc: 0.9106 - f1_m: 0.6177 - precision_m: 0.7705 - recall_m: 0.5308\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9142 - f1_m: 0.6162 - precision_m: 0.8401 - recall_m: 0.5023\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2068 - acc: 0.9128 - f1_m: 0.6196 - precision_m: 0.8161 - recall_m: 0.5135\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2063 - acc: 0.9092 - f1_m: 0.5895 - precision_m: 0.7648 - recall_m: 0.4989\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1983 - acc: 0.9135 - f1_m: 0.6348 - precision_m: 0.7966 - recall_m: 0.5455\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1951 - acc: 0.9157 - f1_m: 0.6212 - precision_m: 0.7699 - recall_m: 0.5337\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1874 - acc: 0.9204 - f1_m: 0.6511 - precision_m: 0.7993 - recall_m: 0.5619\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1837 - acc: 0.9211 - f1_m: 0.6405 - precision_m: 0.7792 - recall_m: 0.5505\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1873 - acc: 0.9233 - f1_m: 0.6728 - precision_m: 0.8245 - recall_m: 0.5838\n",
      "153/153 [==============================] - 1s 9ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(64, 32), score=(train=0.942, test=0.923), total=  15.5s\n",
      "[CV] optimizer=adagrad, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 3s 11ms/step - loss: 0.8249 - acc: 0.7720 - f1_m: 0.1884 - precision_m: 0.2235 - recall_m: 0.1994\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3394 - acc: 0.8537 - f1_m: 0.3053 - precision_m: 0.4491 - recall_m: 0.2557\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2896 - acc: 0.8827 - f1_m: 0.4396 - precision_m: 0.6563 - recall_m: 0.3619\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2645 - acc: 0.8951 - f1_m: 0.5362 - precision_m: 0.6471 - recall_m: 0.4698\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.9005 - f1_m: 0.5602 - precision_m: 0.6533 - recall_m: 0.5082\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2142 - acc: 0.9168 - f1_m: 0.6396 - precision_m: 0.7491 - recall_m: 0.5685\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1940 - acc: 0.9241 - f1_m: 0.6537 - precision_m: 0.7775 - recall_m: 0.5798\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2042 - acc: 0.9147 - f1_m: 0.5761 - precision_m: 0.8074 - recall_m: 0.4902\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1764 - acc: 0.9277 - f1_m: 0.6845 - precision_m: 0.7830 - recall_m: 0.6304\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1735 - acc: 0.9296 - f1_m: 0.6881 - precision_m: 0.8177 - recall_m: 0.6138\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1585 - acc: 0.9361 - f1_m: 0.7157 - precision_m: 0.8125 - recall_m: 0.6500\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1622 - acc: 0.9343 - f1_m: 0.7291 - precision_m: 0.7923 - recall_m: 0.6833\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1442 - acc: 0.9437 - f1_m: 0.7696 - precision_m: 0.8655 - recall_m: 0.7074\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9452 - f1_m: 0.7475 - precision_m: 0.8386 - recall_m: 0.6803\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1262 - acc: 0.9535 - f1_m: 0.7845 - precision_m: 0.8814 - recall_m: 0.7267\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1277 - acc: 0.9448 - f1_m: 0.7722 - precision_m: 0.8515 - recall_m: 0.7156\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1203 - acc: 0.9524 - f1_m: 0.7972 - precision_m: 0.8754 - recall_m: 0.7398\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1261 - acc: 0.9448 - f1_m: 0.7729 - precision_m: 0.8455 - recall_m: 0.7226\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1112 - acc: 0.9524 - f1_m: 0.7984 - precision_m: 0.8740 - recall_m: 0.7435\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1177 - acc: 0.9524 - f1_m: 0.8047 - precision_m: 0.8777 - recall_m: 0.7516\n",
      "154/154 [==============================] - 1s 9ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 32), score=(train=0.971, test=0.918), total=  15.9s\n",
      "[CV] optimizer=adagrad, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.6584 - acc: 0.7926 - f1_m: 0.2672 - precision_m: 0.3197 - recall_m: 0.2924\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3188 - acc: 0.8690 - f1_m: 0.3996 - precision_m: 0.5406 - recall_m: 0.3390\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2707 - acc: 0.8871 - f1_m: 0.5081 - precision_m: 0.6488 - recall_m: 0.4338\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2371 - acc: 0.9037 - f1_m: 0.5897 - precision_m: 0.7187 - recall_m: 0.5173\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2257 - acc: 0.9077 - f1_m: 0.6028 - precision_m: 0.7289 - recall_m: 0.5326\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2008 - acc: 0.9178 - f1_m: 0.6630 - precision_m: 0.7730 - recall_m: 0.6090\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2027 - acc: 0.9182 - f1_m: 0.6521 - precision_m: 0.7527 - recall_m: 0.6018\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1955 - acc: 0.9193 - f1_m: 0.6414 - precision_m: 0.7514 - recall_m: 0.5756\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1730 - acc: 0.9254 - f1_m: 0.6942 - precision_m: 0.7822 - recall_m: 0.6357\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1531 - acc: 0.9374 - f1_m: 0.7189 - precision_m: 0.8401 - recall_m: 0.6474\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1529 - acc: 0.9399 - f1_m: 0.7406 - precision_m: 0.8277 - recall_m: 0.6868\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1452 - acc: 0.9406 - f1_m: 0.7540 - precision_m: 0.8588 - recall_m: 0.6945\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1230 - acc: 0.9519 - f1_m: 0.8104 - precision_m: 0.9002 - recall_m: 0.7460\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1273 - acc: 0.9501 - f1_m: 0.7885 - precision_m: 0.8674 - recall_m: 0.7388\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1155 - acc: 0.9504 - f1_m: 0.7963 - precision_m: 0.8576 - recall_m: 0.7582\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1283 - acc: 0.9472 - f1_m: 0.7826 - precision_m: 0.8300 - recall_m: 0.7507\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1166 - acc: 0.9529 - f1_m: 0.8191 - precision_m: 0.8584 - recall_m: 0.7970\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1030 - acc: 0.9616 - f1_m: 0.8540 - precision_m: 0.9022 - recall_m: 0.8174\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0974 - acc: 0.9627 - f1_m: 0.8502 - precision_m: 0.8966 - recall_m: 0.8153\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0985 - acc: 0.9627 - f1_m: 0.8345 - precision_m: 0.9050 - recall_m: 0.7924\n",
      "153/153 [==============================] - 1s 10ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 32), score=(train=0.990, test=0.948), total=  16.2s\n",
      "[CV] optimizer=adagrad, units=(128, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.8649 - acc: 0.7322 - f1_m: 0.1743 - precision_m: 0.1743 - recall_m: 0.2213\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3906 - acc: 0.8256 - f1_m: 0.2455 - precision_m: 0.3281 - recall_m: 0.2019\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3344 - acc: 0.8585 - f1_m: 0.3694 - precision_m: 0.5145 - recall_m: 0.3110\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3000 - acc: 0.8737 - f1_m: 0.4138 - precision_m: 0.6262 - recall_m: 0.3235\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2803 - acc: 0.8853 - f1_m: 0.4401 - precision_m: 0.6325 - recall_m: 0.3457\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2543 - acc: 0.8903 - f1_m: 0.4813 - precision_m: 0.7073 - recall_m: 0.3696\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2392 - acc: 0.8958 - f1_m: 0.5057 - precision_m: 0.7678 - recall_m: 0.3818\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2346 - acc: 0.8969 - f1_m: 0.5363 - precision_m: 0.7496 - recall_m: 0.4242\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2171 - acc: 0.9030 - f1_m: 0.5763 - precision_m: 0.7876 - recall_m: 0.4667\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2156 - acc: 0.9034 - f1_m: 0.5798 - precision_m: 0.7646 - recall_m: 0.4749\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2068 - acc: 0.9095 - f1_m: 0.5938 - precision_m: 0.7885 - recall_m: 0.4894\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2010 - acc: 0.9106 - f1_m: 0.6128 - precision_m: 0.7365 - recall_m: 0.5348\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1763 - acc: 0.9258 - f1_m: 0.7027 - precision_m: 0.8338 - recall_m: 0.6205\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1776 - acc: 0.9247 - f1_m: 0.6867 - precision_m: 0.7829 - recall_m: 0.6225\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1669 - acc: 0.9280 - f1_m: 0.7138 - precision_m: 0.8177 - recall_m: 0.6410\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1643 - acc: 0.9291 - f1_m: 0.7251 - precision_m: 0.8129 - recall_m: 0.6725\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1440 - acc: 0.9396 - f1_m: 0.7362 - precision_m: 0.8433 - recall_m: 0.6657\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1459 - acc: 0.9370 - f1_m: 0.7601 - precision_m: 0.8397 - recall_m: 0.7079\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1318 - acc: 0.9453 - f1_m: 0.7783 - precision_m: 0.8663 - recall_m: 0.7237\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1301 - acc: 0.9432 - f1_m: 0.7784 - precision_m: 0.8400 - recall_m: 0.7340\n",
      "153/153 [==============================] - 2s 10ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 32), score=(train=0.971, test=0.938), total=  16.4s\n",
      "[CV] optimizer=adagrad, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 4s 12ms/step - loss: 0.5926 - acc: 0.7810 - f1_m: 0.2047 - precision_m: 0.2215 - recall_m: 0.2196\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3969 - acc: 0.8297 - f1_m: 0.1894 - precision_m: 0.2818 - recall_m: 0.1530\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.8558 - f1_m: 0.3125 - precision_m: 0.4306 - recall_m: 0.2623\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3214 - acc: 0.8704 - f1_m: 0.3145 - precision_m: 0.5682 - recall_m: 0.2389\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3090 - acc: 0.8715 - f1_m: 0.3432 - precision_m: 0.5003 - recall_m: 0.2814\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2986 - acc: 0.8704 - f1_m: 0.3441 - precision_m: 0.4699 - recall_m: 0.2778\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2833 - acc: 0.8918 - f1_m: 0.4129 - precision_m: 0.5964 - recall_m: 0.3324\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2795 - acc: 0.8845 - f1_m: 0.3859 - precision_m: 0.5636 - recall_m: 0.3080\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2688 - acc: 0.8951 - f1_m: 0.4822 - precision_m: 0.6756 - recall_m: 0.3966\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2602 - acc: 0.8983 - f1_m: 0.4695 - precision_m: 0.7002 - recall_m: 0.3744\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2554 - acc: 0.8980 - f1_m: 0.4997 - precision_m: 0.7167 - recall_m: 0.4024\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2545 - acc: 0.8987 - f1_m: 0.4920 - precision_m: 0.6748 - recall_m: 0.4093\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2472 - acc: 0.8976 - f1_m: 0.4597 - precision_m: 0.6701 - recall_m: 0.3630\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.9067 - f1_m: 0.5151 - precision_m: 0.6987 - recall_m: 0.4239\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2342 - acc: 0.9041 - f1_m: 0.5073 - precision_m: 0.7201 - recall_m: 0.4082\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.9005 - f1_m: 0.4984 - precision_m: 0.7094 - recall_m: 0.3962\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2471 - acc: 0.8951 - f1_m: 0.4659 - precision_m: 0.6218 - recall_m: 0.3937\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.8962 - f1_m: 0.4600 - precision_m: 0.6476 - recall_m: 0.3813\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2254 - acc: 0.9092 - f1_m: 0.5008 - precision_m: 0.7324 - recall_m: 0.4166\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9176 - f1_m: 0.5747 - precision_m: 0.8272 - recall_m: 0.4660\n",
      "154/154 [==============================] - 2s 10ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(32, 16), score=(train=0.933, test=0.905), total=  16.5s\n",
      "[CV] optimizer=adagrad, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 0.6253 - acc: 0.7387 - f1_m: 0.2157 - precision_m: 0.2171 - recall_m: 0.2572\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4193 - acc: 0.8056 - f1_m: 0.2910 - precision_m: 0.3097 - recall_m: 0.2899\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3603 - acc: 0.8426 - f1_m: 0.3707 - precision_m: 0.4251 - recall_m: 0.3467\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3352 - acc: 0.8603 - f1_m: 0.4145 - precision_m: 0.4881 - recall_m: 0.3822\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.8740 - f1_m: 0.4845 - precision_m: 0.5704 - recall_m: 0.4421\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2920 - acc: 0.8701 - f1_m: 0.4680 - precision_m: 0.5484 - recall_m: 0.4211\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3006 - acc: 0.8708 - f1_m: 0.4830 - precision_m: 0.5568 - recall_m: 0.4537\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2706 - acc: 0.8845 - f1_m: 0.5397 - precision_m: 0.6031 - recall_m: 0.5020\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2640 - acc: 0.8871 - f1_m: 0.5291 - precision_m: 0.6282 - recall_m: 0.4770\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2514 - acc: 0.8882 - f1_m: 0.5237 - precision_m: 0.6121 - recall_m: 0.4671\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.8954 - f1_m: 0.5500 - precision_m: 0.6189 - recall_m: 0.5164\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2354 - acc: 0.8997 - f1_m: 0.5822 - precision_m: 0.6695 - recall_m: 0.5315\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2350 - acc: 0.8997 - f1_m: 0.5787 - precision_m: 0.6839 - recall_m: 0.5162\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2298 - acc: 0.9001 - f1_m: 0.5810 - precision_m: 0.6605 - recall_m: 0.5378\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2249 - acc: 0.9037 - f1_m: 0.6199 - precision_m: 0.6909 - recall_m: 0.5814\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2242 - acc: 0.9034 - f1_m: 0.5985 - precision_m: 0.6732 - recall_m: 0.5567\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2309 - acc: 0.9037 - f1_m: 0.5936 - precision_m: 0.6743 - recall_m: 0.5422\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2203 - acc: 0.9052 - f1_m: 0.5969 - precision_m: 0.6673 - recall_m: 0.5492\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2078 - acc: 0.9149 - f1_m: 0.6547 - precision_m: 0.7593 - recall_m: 0.5909\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1925 - acc: 0.9215 - f1_m: 0.6402 - precision_m: 0.7577 - recall_m: 0.5755\n",
      "153/153 [==============================] - 2s 11ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(32, 16), score=(train=0.944, test=0.922), total=  16.9s\n",
      "[CV] optimizer=adagrad, units=(32, 16) ...............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 0.6785 - acc: 0.6735 - f1_m: 0.2103 - precision_m: 0.1774 - recall_m: 0.2906\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4479 - acc: 0.8089 - f1_m: 0.3089 - precision_m: 0.3298 - recall_m: 0.3002\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3915 - acc: 0.8288 - f1_m: 0.3528 - precision_m: 0.3862 - recall_m: 0.3334\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3429 - acc: 0.8610 - f1_m: 0.4277 - precision_m: 0.5219 - recall_m: 0.3778\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3208 - acc: 0.8636 - f1_m: 0.4513 - precision_m: 0.5275 - recall_m: 0.4085\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2905 - acc: 0.8820 - f1_m: 0.5076 - precision_m: 0.6298 - recall_m: 0.4399\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2880 - acc: 0.8726 - f1_m: 0.4653 - precision_m: 0.5693 - recall_m: 0.4009\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2693 - acc: 0.8791 - f1_m: 0.4988 - precision_m: 0.5939 - recall_m: 0.4369\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2508 - acc: 0.8932 - f1_m: 0.5344 - precision_m: 0.6760 - recall_m: 0.4569\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2508 - acc: 0.8936 - f1_m: 0.5497 - precision_m: 0.6746 - recall_m: 0.4703\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2313 - acc: 0.8990 - f1_m: 0.5631 - precision_m: 0.6956 - recall_m: 0.4931\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2379 - acc: 0.8925 - f1_m: 0.5373 - precision_m: 0.6554 - recall_m: 0.4640\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2217 - acc: 0.9034 - f1_m: 0.5918 - precision_m: 0.7443 - recall_m: 0.5071\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2143 - acc: 0.9077 - f1_m: 0.5986 - precision_m: 0.7554 - recall_m: 0.5039\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2147 - acc: 0.9041 - f1_m: 0.5821 - precision_m: 0.7672 - recall_m: 0.4953\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2076 - acc: 0.9135 - f1_m: 0.6514 - precision_m: 0.7698 - recall_m: 0.5818\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2075 - acc: 0.9084 - f1_m: 0.6060 - precision_m: 0.7896 - recall_m: 0.5088\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1938 - acc: 0.9160 - f1_m: 0.6660 - precision_m: 0.7871 - recall_m: 0.5904\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2022 - acc: 0.9113 - f1_m: 0.6101 - precision_m: 0.7731 - recall_m: 0.5169\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2107 - acc: 0.9095 - f1_m: 0.6325 - precision_m: 0.7853 - recall_m: 0.5365\n",
      "153/153 [==============================] - 2s 11ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(32, 16), score=(train=0.941, test=0.923), total=  17.3s\n",
      "[CV] optimizer=adagrad, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 4s 14ms/step - loss: 0.8792 - acc: 0.7967 - f1_m: 0.2449 - precision_m: 0.2897 - recall_m: 0.2542\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2782 - acc: 0.8853 - f1_m: 0.4925 - precision_m: 0.6105 - recall_m: 0.4415\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2380 - acc: 0.9060 - f1_m: 0.5541 - precision_m: 0.6846 - recall_m: 0.4819\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1948 - acc: 0.9241 - f1_m: 0.6330 - precision_m: 0.7829 - recall_m: 0.5555\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1698 - acc: 0.9292 - f1_m: 0.6786 - precision_m: 0.7912 - recall_m: 0.6052\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1732 - acc: 0.9248 - f1_m: 0.6862 - precision_m: 0.7742 - recall_m: 0.6267\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1605 - acc: 0.9346 - f1_m: 0.7048 - precision_m: 0.7950 - recall_m: 0.6499\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1448 - acc: 0.9459 - f1_m: 0.7384 - precision_m: 0.8728 - recall_m: 0.6598\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1290 - acc: 0.9484 - f1_m: 0.7818 - precision_m: 0.8478 - recall_m: 0.7349\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1277 - acc: 0.9481 - f1_m: 0.7892 - precision_m: 0.8518 - recall_m: 0.7452\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9473 - f1_m: 0.7698 - precision_m: 0.8258 - recall_m: 0.7322\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9510 - f1_m: 0.7938 - precision_m: 0.8547 - recall_m: 0.7591\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1074 - acc: 0.9593 - f1_m: 0.8105 - precision_m: 0.9296 - recall_m: 0.7340\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0975 - acc: 0.9611 - f1_m: 0.8274 - precision_m: 0.8833 - recall_m: 0.7922\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1002 - acc: 0.9601 - f1_m: 0.8438 - precision_m: 0.9122 - recall_m: 0.7925\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0849 - acc: 0.9677 - f1_m: 0.8633 - precision_m: 0.9356 - recall_m: 0.8042\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0902 - acc: 0.9670 - f1_m: 0.8736 - precision_m: 0.9205 - recall_m: 0.8367\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0751 - acc: 0.9731 - f1_m: 0.8753 - precision_m: 0.9176 - recall_m: 0.8432\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0759 - acc: 0.9706 - f1_m: 0.8790 - precision_m: 0.9325 - recall_m: 0.8370\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0803 - acc: 0.9702 - f1_m: 0.8798 - precision_m: 0.9291 - recall_m: 0.8446\n",
      "154/154 [==============================] - 2s 12ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 64), score=(train=0.988, test=0.932), total=  17.7s\n",
      "[CV] optimizer=adagrad, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.8213 - acc: 0.7792 - f1_m: 0.2399 - precision_m: 0.2536 - recall_m: 0.2846\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3287 - acc: 0.8607 - f1_m: 0.3964 - precision_m: 0.4916 - recall_m: 0.3570\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2472 - acc: 0.8950 - f1_m: 0.5456 - precision_m: 0.6583 - recall_m: 0.4843\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2296 - acc: 0.9059 - f1_m: 0.6016 - precision_m: 0.7075 - recall_m: 0.5357\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1993 - acc: 0.9160 - f1_m: 0.6578 - precision_m: 0.7378 - recall_m: 0.6219\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1835 - acc: 0.9301 - f1_m: 0.6946 - precision_m: 0.8004 - recall_m: 0.6368\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1589 - acc: 0.9377 - f1_m: 0.7593 - precision_m: 0.8332 - recall_m: 0.7036\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9410 - f1_m: 0.7712 - precision_m: 0.8353 - recall_m: 0.7257\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1397 - acc: 0.9468 - f1_m: 0.7910 - precision_m: 0.8557 - recall_m: 0.7458\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1288 - acc: 0.9425 - f1_m: 0.7650 - precision_m: 0.8382 - recall_m: 0.7149\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9504 - f1_m: 0.8079 - precision_m: 0.8706 - recall_m: 0.7605\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1106 - acc: 0.9591 - f1_m: 0.8385 - precision_m: 0.8869 - recall_m: 0.8007\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1092 - acc: 0.9613 - f1_m: 0.8448 - precision_m: 0.9060 - recall_m: 0.8031\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0948 - acc: 0.9649 - f1_m: 0.8682 - precision_m: 0.9118 - recall_m: 0.8360\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0958 - acc: 0.9634 - f1_m: 0.8443 - precision_m: 0.9286 - recall_m: 0.7836\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0881 - acc: 0.9660 - f1_m: 0.8723 - precision_m: 0.8946 - recall_m: 0.8564\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0782 - acc: 0.9707 - f1_m: 0.8687 - precision_m: 0.9184 - recall_m: 0.8340\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0678 - acc: 0.9758 - f1_m: 0.8925 - precision_m: 0.9380 - recall_m: 0.8588\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0698 - acc: 0.9743 - f1_m: 0.8957 - precision_m: 0.9322 - recall_m: 0.8716\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0717 - acc: 0.9765 - f1_m: 0.9092 - precision_m: 0.9353 - recall_m: 0.8900\n",
      "153/153 [==============================] - 2s 12ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 64), score=(train=0.995, test=0.951), total=  18.3s\n",
      "[CV] optimizer=adagrad, units=(128, 64) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.7702 - acc: 0.7850 - f1_m: 0.2640 - precision_m: 0.2923 - recall_m: 0.2619\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3261 - acc: 0.8712 - f1_m: 0.4434 - precision_m: 0.5529 - recall_m: 0.3827\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2619 - acc: 0.8867 - f1_m: 0.5220 - precision_m: 0.6467 - recall_m: 0.4603\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2243 - acc: 0.9059 - f1_m: 0.5856 - precision_m: 0.6984 - recall_m: 0.5144\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2007 - acc: 0.9218 - f1_m: 0.7015 - precision_m: 0.8006 - recall_m: 0.6342\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1889 - acc: 0.9240 - f1_m: 0.7015 - precision_m: 0.8189 - recall_m: 0.6191\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1721 - acc: 0.9312 - f1_m: 0.7220 - precision_m: 0.8050 - recall_m: 0.6658\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1586 - acc: 0.9377 - f1_m: 0.7408 - precision_m: 0.8656 - recall_m: 0.6615\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1380 - acc: 0.9475 - f1_m: 0.7896 - precision_m: 0.8631 - recall_m: 0.7348\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1410 - acc: 0.9443 - f1_m: 0.7790 - precision_m: 0.8393 - recall_m: 0.7318\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1360 - acc: 0.9457 - f1_m: 0.7778 - precision_m: 0.8488 - recall_m: 0.7367\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1208 - acc: 0.9508 - f1_m: 0.8024 - precision_m: 0.8770 - recall_m: 0.7473\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1052 - acc: 0.9584 - f1_m: 0.8472 - precision_m: 0.9273 - recall_m: 0.7873\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 0.9566 - f1_m: 0.8323 - precision_m: 0.9171 - recall_m: 0.7679\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1043 - acc: 0.9598 - f1_m: 0.8452 - precision_m: 0.8948 - recall_m: 0.8038\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0980 - acc: 0.9642 - f1_m: 0.8663 - precision_m: 0.9083 - recall_m: 0.8334\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0947 - acc: 0.9645 - f1_m: 0.8595 - precision_m: 0.9351 - recall_m: 0.8033\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0883 - acc: 0.9667 - f1_m: 0.8709 - precision_m: 0.9143 - recall_m: 0.8385\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0805 - acc: 0.9703 - f1_m: 0.8911 - precision_m: 0.9385 - recall_m: 0.8515\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0760 - acc: 0.9739 - f1_m: 0.9053 - precision_m: 0.9351 - recall_m: 0.8820\n",
      "153/153 [==============================] - 2s 12ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adagrad, units=(128, 64), score=(train=0.985, test=0.936), total=  18.2s\n",
      "[CV] optimizer=adadelta, units=(64, 32) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 5s 15ms/step - loss: 0.5084 - acc: 0.7571 - f1_m: 0.2193 - precision_m: 0.2352 - recall_m: 0.2672\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3750 - acc: 0.8544 - f1_m: 0.3172 - precision_m: 0.4427 - recall_m: 0.2644\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.8700 - f1_m: 0.3769 - precision_m: 0.5048 - recall_m: 0.3206\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2792 - acc: 0.8896 - f1_m: 0.4962 - precision_m: 0.6430 - recall_m: 0.4211\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2571 - acc: 0.8954 - f1_m: 0.5108 - precision_m: 0.6728 - recall_m: 0.4364\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2303 - acc: 0.9132 - f1_m: 0.5995 - precision_m: 0.7186 - recall_m: 0.5301\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2279 - acc: 0.9121 - f1_m: 0.6050 - precision_m: 0.7744 - recall_m: 0.5139\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2058 - acc: 0.9179 - f1_m: 0.6130 - precision_m: 0.7210 - recall_m: 0.5487\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2060 - acc: 0.9190 - f1_m: 0.6282 - precision_m: 0.7586 - recall_m: 0.5508\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1844 - acc: 0.9176 - f1_m: 0.6345 - precision_m: 0.7470 - recall_m: 0.5706\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1824 - acc: 0.9241 - f1_m: 0.6636 - precision_m: 0.7806 - recall_m: 0.5990\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1679 - acc: 0.9292 - f1_m: 0.6863 - precision_m: 0.7823 - recall_m: 0.6271\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1653 - acc: 0.9292 - f1_m: 0.6960 - precision_m: 0.8047 - recall_m: 0.6374\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1554 - acc: 0.9343 - f1_m: 0.7030 - precision_m: 0.8115 - recall_m: 0.6332\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1542 - acc: 0.9365 - f1_m: 0.7345 - precision_m: 0.8555 - recall_m: 0.6549\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1422 - acc: 0.9397 - f1_m: 0.7383 - precision_m: 0.8198 - recall_m: 0.6874\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1443 - acc: 0.9354 - f1_m: 0.7274 - precision_m: 0.8376 - recall_m: 0.6614\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1381 - acc: 0.9390 - f1_m: 0.7383 - precision_m: 0.8171 - recall_m: 0.6879\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1298 - acc: 0.9466 - f1_m: 0.7783 - precision_m: 0.8479 - recall_m: 0.7294\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1228 - acc: 0.9459 - f1_m: 0.7455 - precision_m: 0.8162 - recall_m: 0.6996\n",
      "154/154 [==============================] - 2s 12ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(64, 32), score=(train=0.966, test=0.921), total=  18.6s\n",
      "[CV] optimizer=adadelta, units=(64, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 0.4524 - acc: 0.8216 - f1_m: 0.1980 - precision_m: 0.3244 - recall_m: 0.1772\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3347 - acc: 0.8632 - f1_m: 0.3356 - precision_m: 0.5583 - recall_m: 0.2615\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3061 - acc: 0.8777 - f1_m: 0.3843 - precision_m: 0.6431 - recall_m: 0.2854\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2693 - acc: 0.8871 - f1_m: 0.4078 - precision_m: 0.7144 - recall_m: 0.2945\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2488 - acc: 0.8997 - f1_m: 0.4816 - precision_m: 0.7744 - recall_m: 0.3651\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2378 - acc: 0.8969 - f1_m: 0.5008 - precision_m: 0.7265 - recall_m: 0.4033\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2238 - acc: 0.9157 - f1_m: 0.6261 - precision_m: 0.8186 - recall_m: 0.5237\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2174 - acc: 0.9048 - f1_m: 0.5511 - precision_m: 0.7448 - recall_m: 0.4517\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2002 - acc: 0.9171 - f1_m: 0.6216 - precision_m: 0.7973 - recall_m: 0.5247\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1901 - acc: 0.9229 - f1_m: 0.6389 - precision_m: 0.8345 - recall_m: 0.5308\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1865 - acc: 0.9182 - f1_m: 0.6560 - precision_m: 0.8079 - recall_m: 0.5726\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1895 - acc: 0.9182 - f1_m: 0.6398 - precision_m: 0.7873 - recall_m: 0.5577\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1586 - acc: 0.9312 - f1_m: 0.7131 - precision_m: 0.8392 - recall_m: 0.6381\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1636 - acc: 0.9265 - f1_m: 0.6739 - precision_m: 0.8370 - recall_m: 0.5800\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1542 - acc: 0.9359 - f1_m: 0.7207 - precision_m: 0.8501 - recall_m: 0.6445\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1504 - acc: 0.9312 - f1_m: 0.7245 - precision_m: 0.8310 - recall_m: 0.6585\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1416 - acc: 0.9381 - f1_m: 0.7469 - precision_m: 0.8492 - recall_m: 0.6835\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1465 - acc: 0.9359 - f1_m: 0.7423 - precision_m: 0.8538 - recall_m: 0.6673\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1422 - acc: 0.9428 - f1_m: 0.7623 - precision_m: 0.8697 - recall_m: 0.6899\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1291 - acc: 0.9508 - f1_m: 0.8026 - precision_m: 0.8683 - recall_m: 0.7540\n",
      "153/153 [==============================] - 2s 13ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(64, 32), score=(train=0.939, test=0.906), total=  19.0s\n",
      "[CV] optimizer=adadelta, units=(64, 32) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 5s 16ms/step - loss: 0.4707 - acc: 0.8002 - f1_m: 0.1901 - precision_m: 0.2538 - recall_m: 0.1650\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3493 - acc: 0.8588 - f1_m: 0.3301 - precision_m: 0.4958 - recall_m: 0.2812\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2968 - acc: 0.8831 - f1_m: 0.4752 - precision_m: 0.6411 - recall_m: 0.3891\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2681 - acc: 0.8932 - f1_m: 0.5296 - precision_m: 0.7229 - recall_m: 0.4511\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.9041 - f1_m: 0.5743 - precision_m: 0.7988 - recall_m: 0.4735\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2306 - acc: 0.9092 - f1_m: 0.5929 - precision_m: 0.7796 - recall_m: 0.5060\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.8976 - f1_m: 0.6099 - precision_m: 0.7129 - recall_m: 0.5560\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2049 - acc: 0.9218 - f1_m: 0.6674 - precision_m: 0.8169 - recall_m: 0.5762\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2046 - acc: 0.9113 - f1_m: 0.6153 - precision_m: 0.7874 - recall_m: 0.5346\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2033 - acc: 0.9160 - f1_m: 0.6619 - precision_m: 0.7809 - recall_m: 0.5956\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1711 - acc: 0.9298 - f1_m: 0.6941 - precision_m: 0.8234 - recall_m: 0.6200\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1523 - acc: 0.9392 - f1_m: 0.7462 - precision_m: 0.8640 - recall_m: 0.6737\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1657 - acc: 0.9301 - f1_m: 0.7228 - precision_m: 0.8251 - recall_m: 0.6562\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1542 - acc: 0.9388 - f1_m: 0.7466 - precision_m: 0.8650 - recall_m: 0.6744\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1479 - acc: 0.9399 - f1_m: 0.7390 - precision_m: 0.8790 - recall_m: 0.6709\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1310 - acc: 0.9508 - f1_m: 0.7881 - precision_m: 0.9078 - recall_m: 0.7041\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9349 - f1_m: 0.7391 - precision_m: 0.8704 - recall_m: 0.6609\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1252 - acc: 0.9501 - f1_m: 0.7900 - precision_m: 0.8834 - recall_m: 0.7282\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1226 - acc: 0.9475 - f1_m: 0.7906 - precision_m: 0.8689 - recall_m: 0.7402\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1104 - acc: 0.9555 - f1_m: 0.8253 - precision_m: 0.9108 - recall_m: 0.7607\n",
      "153/153 [==============================] - 2s 13ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(64, 32), score=(train=0.970, test=0.940), total=  19.5s\n",
      "[CV] optimizer=adadelta, units=(128, 32) .............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 5s 16ms/step - loss: 0.4429 - acc: 0.8105 - f1_m: 0.2250 - precision_m: 0.3236 - recall_m: 0.2099\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3482 - acc: 0.8635 - f1_m: 0.2832 - precision_m: 0.4732 - recall_m: 0.2225\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2844 - acc: 0.8820 - f1_m: 0.3556 - precision_m: 0.6768 - recall_m: 0.2559\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2695 - acc: 0.8853 - f1_m: 0.4129 - precision_m: 0.6631 - recall_m: 0.3222\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2569 - acc: 0.8903 - f1_m: 0.4411 - precision_m: 0.6817 - recall_m: 0.3361\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2247 - acc: 0.9016 - f1_m: 0.5151 - precision_m: 0.7770 - recall_m: 0.4017\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2227 - acc: 0.9118 - f1_m: 0.5784 - precision_m: 0.7647 - recall_m: 0.4813\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2075 - acc: 0.9110 - f1_m: 0.5828 - precision_m: 0.7418 - recall_m: 0.4978\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1953 - acc: 0.9223 - f1_m: 0.6310 - precision_m: 0.8041 - recall_m: 0.5496\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1939 - acc: 0.9150 - f1_m: 0.6141 - precision_m: 0.7494 - recall_m: 0.5439\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1725 - acc: 0.9281 - f1_m: 0.6746 - precision_m: 0.7962 - recall_m: 0.6026\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1598 - acc: 0.9354 - f1_m: 0.7106 - precision_m: 0.8411 - recall_m: 0.6341\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1505 - acc: 0.9346 - f1_m: 0.7266 - precision_m: 0.8008 - recall_m: 0.6935\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1499 - acc: 0.9343 - f1_m: 0.6969 - precision_m: 0.7947 - recall_m: 0.6394\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1380 - acc: 0.9430 - f1_m: 0.7537 - precision_m: 0.8454 - recall_m: 0.6939\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1370 - acc: 0.9448 - f1_m: 0.7774 - precision_m: 0.8574 - recall_m: 0.7264\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1268 - acc: 0.9452 - f1_m: 0.7679 - precision_m: 0.8504 - recall_m: 0.7126\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1171 - acc: 0.9517 - f1_m: 0.7930 - precision_m: 0.8695 - recall_m: 0.7550\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9513 - f1_m: 0.7922 - precision_m: 0.8470 - recall_m: 0.7590\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1067 - acc: 0.9542 - f1_m: 0.8088 - precision_m: 0.8352 - recall_m: 0.7898\n",
      "154/154 [==============================] - 2s 13ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 32), score=(train=0.977, test=0.920), total=  19.7s\n",
      "[CV] optimizer=adadelta, units=(128, 32) .............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 5s 17ms/step - loss: 0.4945 - acc: 0.7651 - f1_m: 0.2090 - precision_m: 0.2333 - recall_m: 0.2376\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3768 - acc: 0.8480 - f1_m: 0.3181 - precision_m: 0.4598 - recall_m: 0.2751\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3049 - acc: 0.8791 - f1_m: 0.4556 - precision_m: 0.6171 - recall_m: 0.3786\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2649 - acc: 0.8932 - f1_m: 0.5286 - precision_m: 0.7032 - recall_m: 0.4469\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.9008 - f1_m: 0.5550 - precision_m: 0.7482 - recall_m: 0.4603\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2238 - acc: 0.9081 - f1_m: 0.5830 - precision_m: 0.7353 - recall_m: 0.5072\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2065 - acc: 0.9168 - f1_m: 0.6296 - precision_m: 0.7596 - recall_m: 0.5506\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1860 - acc: 0.9244 - f1_m: 0.6790 - precision_m: 0.8028 - recall_m: 0.6008\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1880 - acc: 0.9287 - f1_m: 0.7081 - precision_m: 0.8234 - recall_m: 0.6435\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1587 - acc: 0.9359 - f1_m: 0.7058 - precision_m: 0.8549 - recall_m: 0.6283\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1600 - acc: 0.9330 - f1_m: 0.7248 - precision_m: 0.8391 - recall_m: 0.6605\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1450 - acc: 0.9428 - f1_m: 0.7759 - precision_m: 0.8904 - recall_m: 0.6988\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1406 - acc: 0.9428 - f1_m: 0.7551 - precision_m: 0.8424 - recall_m: 0.7015\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1398 - acc: 0.9406 - f1_m: 0.7467 - precision_m: 0.8599 - recall_m: 0.6687\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1315 - acc: 0.9446 - f1_m: 0.7735 - precision_m: 0.8387 - recall_m: 0.7404\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9562 - f1_m: 0.8132 - precision_m: 0.9109 - recall_m: 0.7509\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 0.9522 - f1_m: 0.7934 - precision_m: 0.8634 - recall_m: 0.7440\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1014 - acc: 0.9631 - f1_m: 0.8548 - precision_m: 0.9321 - recall_m: 0.7992\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0950 - acc: 0.9616 - f1_m: 0.8469 - precision_m: 0.9033 - recall_m: 0.8054\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0972 - acc: 0.9609 - f1_m: 0.8475 - precision_m: 0.8955 - recall_m: 0.8112\n",
      "153/153 [==============================] - 2s 14ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 32), score=(train=0.980, test=0.940), total=  20.1s\n",
      "[CV] optimizer=adadelta, units=(128, 32) .............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 5s 17ms/step - loss: 0.5661 - acc: 0.7115 - f1_m: 0.1693 - precision_m: 0.1591 - recall_m: 0.2128\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4220 - acc: 0.8140 - f1_m: 0.2333 - precision_m: 0.2873 - recall_m: 0.2100\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3548 - acc: 0.8462 - f1_m: 0.3789 - precision_m: 0.4565 - recall_m: 0.3428\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3193 - acc: 0.8701 - f1_m: 0.4765 - precision_m: 0.5636 - recall_m: 0.4394\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2857 - acc: 0.8751 - f1_m: 0.5112 - precision_m: 0.5793 - recall_m: 0.4774\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2604 - acc: 0.8950 - f1_m: 0.5612 - precision_m: 0.6614 - recall_m: 0.5178\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2652 - acc: 0.8864 - f1_m: 0.5273 - precision_m: 0.6146 - recall_m: 0.4867\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2454 - acc: 0.9030 - f1_m: 0.6088 - precision_m: 0.6526 - recall_m: 0.5858\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2146 - acc: 0.9095 - f1_m: 0.6382 - precision_m: 0.7317 - recall_m: 0.5795\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2101 - acc: 0.9113 - f1_m: 0.6347 - precision_m: 0.6974 - recall_m: 0.6002\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2080 - acc: 0.9149 - f1_m: 0.6733 - precision_m: 0.7532 - recall_m: 0.6289\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1901 - acc: 0.9233 - f1_m: 0.6935 - precision_m: 0.7996 - recall_m: 0.6427\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1732 - acc: 0.9320 - f1_m: 0.7318 - precision_m: 0.8327 - recall_m: 0.6711\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1616 - acc: 0.9341 - f1_m: 0.7570 - precision_m: 0.8267 - recall_m: 0.7180\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1635 - acc: 0.9327 - f1_m: 0.7397 - precision_m: 0.8329 - recall_m: 0.6896\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1466 - acc: 0.9443 - f1_m: 0.7834 - precision_m: 0.8686 - recall_m: 0.7405\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1470 - acc: 0.9410 - f1_m: 0.7647 - precision_m: 0.8079 - recall_m: 0.7428\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1394 - acc: 0.9464 - f1_m: 0.8001 - precision_m: 0.8650 - recall_m: 0.7547\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9515 - f1_m: 0.8190 - precision_m: 0.8748 - recall_m: 0.7788\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1362 - acc: 0.9453 - f1_m: 0.7914 - precision_m: 0.8435 - recall_m: 0.7637\n",
      "153/153 [==============================] - 2s 14ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 32), score=(train=0.968, test=0.925), total=  20.3s\n",
      "[CV] optimizer=adadelta, units=(32, 16) ..............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 5s 18ms/step - loss: 0.6041 - acc: 0.6594 - f1_m: 0.1786 - precision_m: 0.1367 - recall_m: 0.2844\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.4676 - acc: 0.7734 - f1_m: 0.2299 - precision_m: 0.2189 - recall_m: 0.2546\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3904 - acc: 0.8105 - f1_m: 0.2641 - precision_m: 0.2851 - recall_m: 0.2792\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3466 - acc: 0.8482 - f1_m: 0.2698 - precision_m: 0.3951 - recall_m: 0.2144\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3051 - acc: 0.8591 - f1_m: 0.2935 - precision_m: 0.4559 - recall_m: 0.2309\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2926 - acc: 0.8704 - f1_m: 0.3398 - precision_m: 0.5132 - recall_m: 0.2607\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2924 - acc: 0.8649 - f1_m: 0.3395 - precision_m: 0.5106 - recall_m: 0.2747\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2810 - acc: 0.8773 - f1_m: 0.3617 - precision_m: 0.5831 - recall_m: 0.2726\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2664 - acc: 0.8853 - f1_m: 0.4251 - precision_m: 0.6847 - recall_m: 0.3183\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2634 - acc: 0.8911 - f1_m: 0.4806 - precision_m: 0.6740 - recall_m: 0.3903\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2550 - acc: 0.8856 - f1_m: 0.3932 - precision_m: 0.6427 - recall_m: 0.2916\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2359 - acc: 0.8903 - f1_m: 0.4264 - precision_m: 0.6847 - recall_m: 0.3202\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.8976 - f1_m: 0.5125 - precision_m: 0.6954 - recall_m: 0.4130\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2337 - acc: 0.8925 - f1_m: 0.4796 - precision_m: 0.6707 - recall_m: 0.3861\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2268 - acc: 0.8965 - f1_m: 0.4957 - precision_m: 0.6865 - recall_m: 0.4016\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2282 - acc: 0.9020 - f1_m: 0.5263 - precision_m: 0.7272 - recall_m: 0.4348\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2169 - acc: 0.8972 - f1_m: 0.5144 - precision_m: 0.6112 - recall_m: 0.4550\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2121 - acc: 0.9056 - f1_m: 0.5466 - precision_m: 0.7247 - recall_m: 0.4524\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2061 - acc: 0.9074 - f1_m: 0.5298 - precision_m: 0.7047 - recall_m: 0.4424\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1975 - acc: 0.9165 - f1_m: 0.6021 - precision_m: 0.7569 - recall_m: 0.5164\n",
      "154/154 [==============================] - 2s 14ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(32, 16), score=(train=0.945, test=0.912), total=  20.6s\n",
      "[CV] optimizer=adadelta, units=(32, 16) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 5s 18ms/step - loss: 0.5262 - acc: 0.7485 - f1_m: 0.1908 - precision_m: 0.1903 - recall_m: 0.2244\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4149 - acc: 0.8180 - f1_m: 0.2562 - precision_m: 0.3189 - recall_m: 0.2256\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3629 - acc: 0.8408 - f1_m: 0.2958 - precision_m: 0.3692 - recall_m: 0.2668\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3306 - acc: 0.8657 - f1_m: 0.4063 - precision_m: 0.5414 - recall_m: 0.3426\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3102 - acc: 0.8740 - f1_m: 0.4378 - precision_m: 0.5681 - recall_m: 0.3744\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2775 - acc: 0.8896 - f1_m: 0.4671 - precision_m: 0.6066 - recall_m: 0.4026\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2782 - acc: 0.8921 - f1_m: 0.5309 - precision_m: 0.6789 - recall_m: 0.4502\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2562 - acc: 0.9005 - f1_m: 0.5711 - precision_m: 0.7181 - recall_m: 0.4945\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2478 - acc: 0.9034 - f1_m: 0.5605 - precision_m: 0.7059 - recall_m: 0.4928\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.9008 - f1_m: 0.5905 - precision_m: 0.6957 - recall_m: 0.5337\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2280 - acc: 0.9110 - f1_m: 0.5762 - precision_m: 0.7592 - recall_m: 0.4959\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2121 - acc: 0.9142 - f1_m: 0.6217 - precision_m: 0.7709 - recall_m: 0.5383\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2277 - acc: 0.9070 - f1_m: 0.5763 - precision_m: 0.7124 - recall_m: 0.5255\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2010 - acc: 0.9215 - f1_m: 0.6588 - precision_m: 0.7405 - recall_m: 0.6106\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.9124 - f1_m: 0.6168 - precision_m: 0.7071 - recall_m: 0.5714\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1943 - acc: 0.9186 - f1_m: 0.6636 - precision_m: 0.7614 - recall_m: 0.5966\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1992 - acc: 0.9262 - f1_m: 0.6842 - precision_m: 0.8119 - recall_m: 0.6140\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1894 - acc: 0.9218 - f1_m: 0.6844 - precision_m: 0.7610 - recall_m: 0.6372\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1988 - acc: 0.9200 - f1_m: 0.6530 - precision_m: 0.7588 - recall_m: 0.5859\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1875 - acc: 0.9211 - f1_m: 0.6636 - precision_m: 0.7541 - recall_m: 0.5992\n",
      "153/153 [==============================] - 2s 15ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(32, 16), score=(train=0.943, test=0.922), total=  20.8s\n",
      "[CV] optimizer=adadelta, units=(32, 16) ..............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 6s 18ms/step - loss: 0.6498 - acc: 0.6460 - f1_m: 0.1757 - precision_m: 0.1364 - recall_m: 0.2836\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.5083 - acc: 0.7517 - f1_m: 0.1435 - precision_m: 0.1530 - recall_m: 0.1642\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4147 - acc: 0.8017 - f1_m: 0.1668 - precision_m: 0.2104 - recall_m: 0.1472\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3705 - acc: 0.8227 - f1_m: 0.1667 - precision_m: 0.2573 - recall_m: 0.1329\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3526 - acc: 0.8328 - f1_m: 0.1443 - precision_m: 0.2855 - recall_m: 0.1020\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3207 - acc: 0.8502 - f1_m: 0.1969 - precision_m: 0.4572 - recall_m: 0.1353\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.8531 - f1_m: 0.1979 - precision_m: 0.5100 - recall_m: 0.1301\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3051 - acc: 0.8581 - f1_m: 0.2809 - precision_m: 0.5493 - recall_m: 0.1962\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2893 - acc: 0.8628 - f1_m: 0.2888 - precision_m: 0.5558 - recall_m: 0.1989\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2763 - acc: 0.8675 - f1_m: 0.3012 - precision_m: 0.6426 - recall_m: 0.2060\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2710 - acc: 0.8744 - f1_m: 0.3233 - precision_m: 0.6306 - recall_m: 0.2275\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2632 - acc: 0.8889 - f1_m: 0.4161 - precision_m: 0.7484 - recall_m: 0.2947\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2542 - acc: 0.8896 - f1_m: 0.4383 - precision_m: 0.7825 - recall_m: 0.3146\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2584 - acc: 0.8853 - f1_m: 0.4103 - precision_m: 0.7223 - recall_m: 0.2977\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2453 - acc: 0.8958 - f1_m: 0.4777 - precision_m: 0.7862 - recall_m: 0.3517\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2478 - acc: 0.8979 - f1_m: 0.5173 - precision_m: 0.7956 - recall_m: 0.3958\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.8969 - f1_m: 0.4974 - precision_m: 0.8222 - recall_m: 0.3708\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2350 - acc: 0.9005 - f1_m: 0.5447 - precision_m: 0.8269 - recall_m: 0.4185\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2212 - acc: 0.9055 - f1_m: 0.5548 - precision_m: 0.8348 - recall_m: 0.4273\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2303 - acc: 0.9030 - f1_m: 0.5365 - precision_m: 0.8198 - recall_m: 0.4126\n",
      "153/153 [==============================] - 2s 15ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(32, 16), score=(train=0.882, test=0.882), total=  21.2s\n",
      "[CV] optimizer=adadelta, units=(128, 64) .............................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 6s 18ms/step - loss: 0.4490 - acc: 0.8086 - f1_m: 0.1597 - precision_m: 0.2801 - recall_m: 0.1540\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3148 - acc: 0.8816 - f1_m: 0.3805 - precision_m: 0.6814 - recall_m: 0.2820\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2688 - acc: 0.8922 - f1_m: 0.4545 - precision_m: 0.7081 - recall_m: 0.3557\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2255 - acc: 0.9114 - f1_m: 0.5817 - precision_m: 0.7801 - recall_m: 0.4771\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2170 - acc: 0.9078 - f1_m: 0.5878 - precision_m: 0.7490 - recall_m: 0.4974\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2121 - acc: 0.9165 - f1_m: 0.5903 - precision_m: 0.8401 - recall_m: 0.4886\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1965 - acc: 0.9223 - f1_m: 0.6339 - precision_m: 0.8036 - recall_m: 0.5441\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1613 - acc: 0.9325 - f1_m: 0.6960 - precision_m: 0.8026 - recall_m: 0.6425\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1560 - acc: 0.9368 - f1_m: 0.7202 - precision_m: 0.8346 - recall_m: 0.6602\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1382 - acc: 0.9426 - f1_m: 0.7486 - precision_m: 0.8645 - recall_m: 0.6774\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1471 - acc: 0.9423 - f1_m: 0.7600 - precision_m: 0.8407 - recall_m: 0.7203\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1297 - acc: 0.9528 - f1_m: 0.8045 - precision_m: 0.8613 - recall_m: 0.7702\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1176 - acc: 0.9539 - f1_m: 0.8136 - precision_m: 0.9012 - recall_m: 0.7569\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1092 - acc: 0.9546 - f1_m: 0.8183 - precision_m: 0.8584 - recall_m: 0.7892\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1073 - acc: 0.9564 - f1_m: 0.8253 - precision_m: 0.8752 - recall_m: 0.8096\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9550 - f1_m: 0.7994 - precision_m: 0.8879 - recall_m: 0.7527\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0801 - acc: 0.9706 - f1_m: 0.8923 - precision_m: 0.9228 - recall_m: 0.8687\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0906 - acc: 0.9662 - f1_m: 0.8627 - precision_m: 0.9096 - recall_m: 0.8312\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0827 - acc: 0.9673 - f1_m: 0.8661 - precision_m: 0.9067 - recall_m: 0.8372\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0751 - acc: 0.9731 - f1_m: 0.8843 - precision_m: 0.9395 - recall_m: 0.8459\n",
      "154/154 [==============================] - 2s 15ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 64), score=(train=0.978, test=0.924), total=  21.5s\n",
      "[CV] optimizer=adadelta, units=(128, 64) .............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 6s 19ms/step - loss: 0.4987 - acc: 0.7799 - f1_m: 0.2182 - precision_m: 0.3197 - recall_m: 0.2191\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3443 - acc: 0.8661 - f1_m: 0.2827 - precision_m: 0.5035 - recall_m: 0.2020\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2984 - acc: 0.8860 - f1_m: 0.4301 - precision_m: 0.7432 - recall_m: 0.3293\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.9005 - f1_m: 0.4997 - precision_m: 0.7103 - recall_m: 0.4085\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2342 - acc: 0.9052 - f1_m: 0.5772 - precision_m: 0.7773 - recall_m: 0.4817\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2259 - acc: 0.9070 - f1_m: 0.5742 - precision_m: 0.7592 - recall_m: 0.4843\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2060 - acc: 0.9164 - f1_m: 0.6110 - precision_m: 0.7736 - recall_m: 0.5351\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1882 - acc: 0.9233 - f1_m: 0.6742 - precision_m: 0.8081 - recall_m: 0.5885\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1817 - acc: 0.9291 - f1_m: 0.6883 - precision_m: 0.8519 - recall_m: 0.5974\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1571 - acc: 0.9359 - f1_m: 0.7226 - precision_m: 0.8228 - recall_m: 0.6626\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1615 - acc: 0.9341 - f1_m: 0.7034 - precision_m: 0.8314 - recall_m: 0.6412\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1510 - acc: 0.9338 - f1_m: 0.7192 - precision_m: 0.8212 - recall_m: 0.6543\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9490 - f1_m: 0.7900 - precision_m: 0.8842 - recall_m: 0.7268\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1160 - acc: 0.9529 - f1_m: 0.8159 - precision_m: 0.8934 - recall_m: 0.7624\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1213 - acc: 0.9493 - f1_m: 0.7911 - precision_m: 0.8713 - recall_m: 0.7365\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1071 - acc: 0.9573 - f1_m: 0.8280 - precision_m: 0.8876 - recall_m: 0.7945\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9555 - f1_m: 0.8320 - precision_m: 0.9052 - recall_m: 0.7870\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0921 - acc: 0.9642 - f1_m: 0.8682 - precision_m: 0.9111 - recall_m: 0.8432\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0897 - acc: 0.9656 - f1_m: 0.8676 - precision_m: 0.9127 - recall_m: 0.8381\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0831 - acc: 0.9671 - f1_m: 0.8783 - precision_m: 0.9190 - recall_m: 0.8547\n",
      "153/153 [==============================] - 2s 16ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 64), score=(train=0.981, test=0.935), total=  22.4s\n",
      "[CV] optimizer=adadelta, units=(128, 64) .............................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 6s 19ms/step - loss: 0.4381 - acc: 0.8198 - f1_m: 0.1593 - precision_m: 0.3634 - recall_m: 0.1533\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.8780 - f1_m: 0.3535 - precision_m: 0.6334 - recall_m: 0.2642\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2644 - acc: 0.8943 - f1_m: 0.5250 - precision_m: 0.7536 - recall_m: 0.4271\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2352 - acc: 0.9092 - f1_m: 0.5899 - precision_m: 0.8085 - recall_m: 0.4736\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2185 - acc: 0.9121 - f1_m: 0.6306 - precision_m: 0.8106 - recall_m: 0.5372\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2024 - acc: 0.9088 - f1_m: 0.6094 - precision_m: 0.7811 - recall_m: 0.5261\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1827 - acc: 0.9309 - f1_m: 0.6991 - precision_m: 0.8443 - recall_m: 0.6283\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1696 - acc: 0.9338 - f1_m: 0.7010 - precision_m: 0.8548 - recall_m: 0.6159\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1588 - acc: 0.9330 - f1_m: 0.6988 - precision_m: 0.7778 - recall_m: 0.6538\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1443 - acc: 0.9406 - f1_m: 0.7553 - precision_m: 0.8452 - recall_m: 0.6972\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1315 - acc: 0.9439 - f1_m: 0.7851 - precision_m: 0.8604 - recall_m: 0.7455\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1365 - acc: 0.9392 - f1_m: 0.7687 - precision_m: 0.8551 - recall_m: 0.7248\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1221 - acc: 0.9519 - f1_m: 0.8221 - precision_m: 0.8941 - recall_m: 0.7729\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1074 - acc: 0.9577 - f1_m: 0.8405 - precision_m: 0.8955 - recall_m: 0.8077\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0905 - acc: 0.9649 - f1_m: 0.8470 - precision_m: 0.9076 - recall_m: 0.8038\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0938 - acc: 0.9631 - f1_m: 0.8677 - precision_m: 0.9023 - recall_m: 0.8463\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0910 - acc: 0.9667 - f1_m: 0.8773 - precision_m: 0.9313 - recall_m: 0.8449\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0874 - acc: 0.9660 - f1_m: 0.8811 - precision_m: 0.9174 - recall_m: 0.8603\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0834 - acc: 0.9674 - f1_m: 0.8796 - precision_m: 0.9025 - recall_m: 0.8658\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0697 - acc: 0.9739 - f1_m: 0.8934 - precision_m: 0.9306 - recall_m: 0.8724\n",
      "153/153 [==============================] - 2s 16ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=adadelta, units=(128, 64), score=(train=0.978, test=0.930), total=  22.2s\n",
      "[CV] optimizer=nadam, units=(64, 32) .................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 6s 20ms/step - loss: 0.4408 - acc: 0.8145 - f1_m: 0.1160 - precision_m: 0.1515 - recall_m: 0.1057\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8675 - f1_m: 0.2381 - precision_m: 0.4940 - recall_m: 0.1663\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2723 - acc: 0.8943 - f1_m: 0.4542 - precision_m: 0.6979 - recall_m: 0.3444\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.8994 - f1_m: 0.4655 - precision_m: 0.7309 - recall_m: 0.3567\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2084 - acc: 0.9096 - f1_m: 0.5621 - precision_m: 0.7899 - recall_m: 0.4437\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1883 - acc: 0.9176 - f1_m: 0.6329 - precision_m: 0.7675 - recall_m: 0.5509\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1621 - acc: 0.9339 - f1_m: 0.6872 - precision_m: 0.8340 - recall_m: 0.6108\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1590 - acc: 0.9310 - f1_m: 0.7021 - precision_m: 0.8463 - recall_m: 0.6084\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1488 - acc: 0.9361 - f1_m: 0.7160 - precision_m: 0.8152 - recall_m: 0.6531\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1462 - acc: 0.9383 - f1_m: 0.7455 - precision_m: 0.8608 - recall_m: 0.6681\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9408 - f1_m: 0.7421 - precision_m: 0.8358 - recall_m: 0.6903\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9386 - f1_m: 0.7331 - precision_m: 0.8003 - recall_m: 0.6882\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9477 - f1_m: 0.7643 - precision_m: 0.8520 - recall_m: 0.7052\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1287 - acc: 0.9401 - f1_m: 0.7367 - precision_m: 0.8467 - recall_m: 0.6637\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1199 - acc: 0.9470 - f1_m: 0.7868 - precision_m: 0.8501 - recall_m: 0.7420\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1063 - acc: 0.9513 - f1_m: 0.8028 - precision_m: 0.8494 - recall_m: 0.7755\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1165 - acc: 0.9528 - f1_m: 0.8075 - precision_m: 0.8367 - recall_m: 0.7929\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1026 - acc: 0.9546 - f1_m: 0.8139 - precision_m: 0.8782 - recall_m: 0.7686\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1004 - acc: 0.9604 - f1_m: 0.8329 - precision_m: 0.8743 - recall_m: 0.8053\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9546 - f1_m: 0.8151 - precision_m: 0.8697 - recall_m: 0.7783\n",
      "154/154 [==============================] - 3s 16ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(64, 32), score=(train=0.978, test=0.916), total=  22.7s\n",
      "[CV] optimizer=nadam, units=(64, 32) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 6s 21ms/step - loss: 0.4834 - acc: 0.7796 - f1_m: 0.2239 - precision_m: 0.2586 - recall_m: 0.2439\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3343 - acc: 0.8531 - f1_m: 0.3574 - precision_m: 0.4759 - recall_m: 0.3012\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2795 - acc: 0.8813 - f1_m: 0.4606 - precision_m: 0.6215 - recall_m: 0.3872\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2608 - acc: 0.8835 - f1_m: 0.5233 - precision_m: 0.6182 - recall_m: 0.4723\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2314 - acc: 0.8965 - f1_m: 0.5782 - precision_m: 0.7191 - recall_m: 0.5074\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2105 - acc: 0.9070 - f1_m: 0.6181 - precision_m: 0.7431 - recall_m: 0.5547\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1862 - acc: 0.9146 - f1_m: 0.6347 - precision_m: 0.7378 - recall_m: 0.5843\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1679 - acc: 0.9294 - f1_m: 0.7035 - precision_m: 0.8214 - recall_m: 0.6341\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1740 - acc: 0.9236 - f1_m: 0.6933 - precision_m: 0.7536 - recall_m: 0.6594\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1604 - acc: 0.9334 - f1_m: 0.7358 - precision_m: 0.8159 - recall_m: 0.6943\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1521 - acc: 0.9349 - f1_m: 0.7522 - precision_m: 0.8248 - recall_m: 0.7087\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1338 - acc: 0.9443 - f1_m: 0.7797 - precision_m: 0.8577 - recall_m: 0.7292\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1470 - acc: 0.9396 - f1_m: 0.7671 - precision_m: 0.8334 - recall_m: 0.7269\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1219 - acc: 0.9522 - f1_m: 0.8195 - precision_m: 0.8815 - recall_m: 0.7765\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1207 - acc: 0.9504 - f1_m: 0.8118 - precision_m: 0.8788 - recall_m: 0.7636\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1070 - acc: 0.9548 - f1_m: 0.8280 - precision_m: 0.8586 - recall_m: 0.8114\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0927 - acc: 0.9616 - f1_m: 0.8573 - precision_m: 0.9136 - recall_m: 0.8181\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1118 - acc: 0.9544 - f1_m: 0.8136 - precision_m: 0.8707 - recall_m: 0.7786\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9663 - f1_m: 0.8794 - precision_m: 0.9135 - recall_m: 0.8549\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0786 - acc: 0.9671 - f1_m: 0.8663 - precision_m: 0.9004 - recall_m: 0.8456\n",
      "153/153 [==============================] - 3s 17ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(64, 32), score=(train=0.992, test=0.943), total=  23.2s\n",
      "[CV] optimizer=nadam, units=(64, 32) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 6s 21ms/step - loss: 0.4695 - acc: 0.8013 - f1_m: 0.2455 - precision_m: 0.3087 - recall_m: 0.2354\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3199 - acc: 0.8646 - f1_m: 0.4035 - precision_m: 0.5778 - recall_m: 0.3391\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2713 - acc: 0.8791 - f1_m: 0.4593 - precision_m: 0.6152 - recall_m: 0.3882\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2300 - acc: 0.8972 - f1_m: 0.5632 - precision_m: 0.7211 - recall_m: 0.4834\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2092 - acc: 0.9110 - f1_m: 0.6441 - precision_m: 0.7848 - recall_m: 0.5827\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2061 - acc: 0.9030 - f1_m: 0.6246 - precision_m: 0.7234 - recall_m: 0.5822\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1777 - acc: 0.9258 - f1_m: 0.6935 - precision_m: 0.8139 - recall_m: 0.6425\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1582 - acc: 0.9363 - f1_m: 0.7329 - precision_m: 0.8404 - recall_m: 0.6571\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1382 - acc: 0.9453 - f1_m: 0.7889 - precision_m: 0.8729 - recall_m: 0.7324\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1297 - acc: 0.9501 - f1_m: 0.7609 - precision_m: 0.8258 - recall_m: 0.7194\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1195 - acc: 0.9526 - f1_m: 0.8177 - precision_m: 0.8696 - recall_m: 0.7817\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9533 - f1_m: 0.8140 - precision_m: 0.8844 - recall_m: 0.7775\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0991 - acc: 0.9616 - f1_m: 0.8374 - precision_m: 0.8976 - recall_m: 0.7954\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0766 - acc: 0.9754 - f1_m: 0.9188 - precision_m: 0.9538 - recall_m: 0.8909\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9551 - f1_m: 0.8165 - precision_m: 0.8711 - recall_m: 0.7823\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0872 - acc: 0.9649 - f1_m: 0.8571 - precision_m: 0.8828 - recall_m: 0.8397\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0863 - acc: 0.9642 - f1_m: 0.8689 - precision_m: 0.9060 - recall_m: 0.8417\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0908 - acc: 0.9609 - f1_m: 0.8625 - precision_m: 0.8919 - recall_m: 0.8448\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0722 - acc: 0.9703 - f1_m: 0.8866 - precision_m: 0.9118 - recall_m: 0.8674\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0763 - acc: 0.9710 - f1_m: 0.8808 - precision_m: 0.9261 - recall_m: 0.8451\n",
      "153/153 [==============================] - 3s 17ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(64, 32), score=(train=0.992, test=0.943), total=  23.3s\n",
      "[CV] optimizer=nadam, units=(128, 32) ................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 7s 21ms/step - loss: 0.4699 - acc: 0.7956 - f1_m: 0.1355 - precision_m: 0.1896 - recall_m: 0.1348\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.8747 - f1_m: 0.3955 - precision_m: 0.5535 - recall_m: 0.3214\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.8896 - f1_m: 0.4853 - precision_m: 0.6482 - recall_m: 0.4101\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2135 - acc: 0.9107 - f1_m: 0.5960 - precision_m: 0.7537 - recall_m: 0.5088\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2025 - acc: 0.9096 - f1_m: 0.5679 - precision_m: 0.7507 - recall_m: 0.4718\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1898 - acc: 0.9223 - f1_m: 0.6463 - precision_m: 0.7845 - recall_m: 0.5713\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1725 - acc: 0.9259 - f1_m: 0.6851 - precision_m: 0.7967 - recall_m: 0.6181\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1604 - acc: 0.9277 - f1_m: 0.6964 - precision_m: 0.7962 - recall_m: 0.6362\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1495 - acc: 0.9390 - f1_m: 0.7417 - precision_m: 0.8355 - recall_m: 0.6847\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1270 - acc: 0.9448 - f1_m: 0.7698 - precision_m: 0.8570 - recall_m: 0.7215\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1425 - acc: 0.9405 - f1_m: 0.7507 - precision_m: 0.7859 - recall_m: 0.7412\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1257 - acc: 0.9521 - f1_m: 0.8004 - precision_m: 0.8568 - recall_m: 0.7652\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1023 - acc: 0.9575 - f1_m: 0.8327 - precision_m: 0.8695 - recall_m: 0.8058\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0977 - acc: 0.9601 - f1_m: 0.8344 - precision_m: 0.8835 - recall_m: 0.7979\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0944 - acc: 0.9608 - f1_m: 0.8448 - precision_m: 0.9005 - recall_m: 0.8008\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0817 - acc: 0.9655 - f1_m: 0.8573 - precision_m: 0.8895 - recall_m: 0.8335\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0681 - acc: 0.9720 - f1_m: 0.8822 - precision_m: 0.9333 - recall_m: 0.8474\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0650 - acc: 0.9746 - f1_m: 0.8996 - precision_m: 0.9173 - recall_m: 0.8875\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1205 - acc: 0.9593 - f1_m: 0.8134 - precision_m: 0.8861 - recall_m: 0.7931\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0686 - acc: 0.9742 - f1_m: 0.8980 - precision_m: 0.9233 - recall_m: 0.8816\n",
      "154/154 [==============================] - 3s 18ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 32), score=(train=0.993, test=0.940), total=  23.9s\n",
      "[CV] optimizer=nadam, units=(128, 32) ................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 7s 21ms/step - loss: 0.4349 - acc: 0.8042 - f1_m: 0.2352 - precision_m: 0.3204 - recall_m: 0.2155\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3259 - acc: 0.8672 - f1_m: 0.3863 - precision_m: 0.5764 - recall_m: 0.3115\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2958 - acc: 0.8773 - f1_m: 0.4202 - precision_m: 0.6639 - recall_m: 0.3199\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.8885 - f1_m: 0.4907 - precision_m: 0.6905 - recall_m: 0.3980\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2346 - acc: 0.9001 - f1_m: 0.5240 - precision_m: 0.7498 - recall_m: 0.4139\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2119 - acc: 0.9113 - f1_m: 0.6059 - precision_m: 0.8045 - recall_m: 0.5110\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1808 - acc: 0.9244 - f1_m: 0.6514 - precision_m: 0.8010 - recall_m: 0.5652\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1593 - acc: 0.9316 - f1_m: 0.7081 - precision_m: 0.8053 - recall_m: 0.6464\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1450 - acc: 0.9363 - f1_m: 0.7378 - precision_m: 0.8433 - recall_m: 0.6707\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1225 - acc: 0.9490 - f1_m: 0.7889 - precision_m: 0.8750 - recall_m: 0.7378\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1162 - acc: 0.9511 - f1_m: 0.8003 - precision_m: 0.8786 - recall_m: 0.7474\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1056 - acc: 0.9602 - f1_m: 0.8202 - precision_m: 0.8833 - recall_m: 0.7786\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0914 - acc: 0.9634 - f1_m: 0.8626 - precision_m: 0.9014 - recall_m: 0.8355\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0885 - acc: 0.9616 - f1_m: 0.8549 - precision_m: 0.8675 - recall_m: 0.8490\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0805 - acc: 0.9703 - f1_m: 0.8890 - precision_m: 0.9270 - recall_m: 0.8626\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0868 - acc: 0.9613 - f1_m: 0.8420 - precision_m: 0.8615 - recall_m: 0.8361\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0740 - acc: 0.9707 - f1_m: 0.8773 - precision_m: 0.9143 - recall_m: 0.8561\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0597 - acc: 0.9783 - f1_m: 0.9152 - precision_m: 0.9420 - recall_m: 0.8952\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0610 - acc: 0.9736 - f1_m: 0.8860 - precision_m: 0.9233 - recall_m: 0.8558\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0490 - acc: 0.9790 - f1_m: 0.9174 - precision_m: 0.9285 - recall_m: 0.9111\n",
      "153/153 [==============================] - 3s 18ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 32), score=(train=0.993, test=0.943), total=  24.1s\n",
      "[CV] optimizer=nadam, units=(128, 32) ................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 7s 22ms/step - loss: 0.4992 - acc: 0.7760 - f1_m: 0.1768 - precision_m: 0.2197 - recall_m: 0.1719\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3721 - acc: 0.8357 - f1_m: 0.2331 - precision_m: 0.4000 - recall_m: 0.1707\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2843 - acc: 0.8806 - f1_m: 0.4550 - precision_m: 0.6966 - recall_m: 0.3633\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2696 - acc: 0.8827 - f1_m: 0.4726 - precision_m: 0.6194 - recall_m: 0.4093\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2484 - acc: 0.9008 - f1_m: 0.6004 - precision_m: 0.7421 - recall_m: 0.5175\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1951 - acc: 0.9197 - f1_m: 0.6659 - precision_m: 0.7750 - recall_m: 0.6052\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1800 - acc: 0.9254 - f1_m: 0.6607 - precision_m: 0.7949 - recall_m: 0.5852\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1655 - acc: 0.9312 - f1_m: 0.7173 - precision_m: 0.8096 - recall_m: 0.6630\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1395 - acc: 0.9396 - f1_m: 0.7708 - precision_m: 0.8280 - recall_m: 0.7321\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1354 - acc: 0.9425 - f1_m: 0.7848 - precision_m: 0.8463 - recall_m: 0.7424\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1116 - acc: 0.9529 - f1_m: 0.8186 - precision_m: 0.8731 - recall_m: 0.7859\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1042 - acc: 0.9529 - f1_m: 0.8266 - precision_m: 0.8921 - recall_m: 0.7789\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0973 - acc: 0.9613 - f1_m: 0.8564 - precision_m: 0.8859 - recall_m: 0.8351\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0935 - acc: 0.9598 - f1_m: 0.8332 - precision_m: 0.8890 - recall_m: 0.7935\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0822 - acc: 0.9696 - f1_m: 0.8865 - precision_m: 0.9364 - recall_m: 0.8506\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0870 - acc: 0.9627 - f1_m: 0.8627 - precision_m: 0.9003 - recall_m: 0.8379\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0824 - acc: 0.9660 - f1_m: 0.8768 - precision_m: 0.8958 - recall_m: 0.8649\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0692 - acc: 0.9765 - f1_m: 0.9150 - precision_m: 0.9346 - recall_m: 0.9020\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1197 - acc: 0.9529 - f1_m: 0.8363 - precision_m: 0.8806 - recall_m: 0.8136\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0844 - acc: 0.9631 - f1_m: 0.8627 - precision_m: 0.8966 - recall_m: 0.8485\n",
      "153/153 [==============================] - 3s 18ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 32), score=(train=0.987, test=0.940), total=  24.4s\n",
      "[CV] optimizer=nadam, units=(32, 16) .................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 7s 23ms/step - loss: 0.5860 - acc: 0.6954 - f1_m: 0.2081 - precision_m: 0.1672 - recall_m: 0.3037\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.4725 - acc: 0.7658 - f1_m: 0.1721 - precision_m: 0.1739 - recall_m: 0.1924\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3757 - acc: 0.8250 - f1_m: 0.1600 - precision_m: 0.2464 - recall_m: 0.1340\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3520 - acc: 0.8388 - f1_m: 0.1039 - precision_m: 0.2161 - recall_m: 0.0744\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3230 - acc: 0.8515 - f1_m: 0.0791 - precision_m: 0.2380 - recall_m: 0.0509\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2972 - acc: 0.8569 - f1_m: 0.0830 - precision_m: 0.3092 - recall_m: 0.0507\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2861 - acc: 0.8642 - f1_m: 0.1172 - precision_m: 0.4505 - recall_m: 0.0693\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2865 - acc: 0.8664 - f1_m: 0.1832 - precision_m: 0.5606 - recall_m: 0.1132\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2560 - acc: 0.8747 - f1_m: 0.2457 - precision_m: 0.6227 - recall_m: 0.1574\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2486 - acc: 0.8794 - f1_m: 0.3251 - precision_m: 0.6196 - recall_m: 0.2288\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2339 - acc: 0.8911 - f1_m: 0.4105 - precision_m: 0.6832 - recall_m: 0.3054\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2309 - acc: 0.9016 - f1_m: 0.5247 - precision_m: 0.7463 - recall_m: 0.4193\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2170 - acc: 0.9067 - f1_m: 0.5631 - precision_m: 0.7767 - recall_m: 0.4544\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2117 - acc: 0.9063 - f1_m: 0.5354 - precision_m: 0.7208 - recall_m: 0.4328\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2172 - acc: 0.9038 - f1_m: 0.5409 - precision_m: 0.7199 - recall_m: 0.4472\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2014 - acc: 0.9020 - f1_m: 0.5441 - precision_m: 0.7033 - recall_m: 0.4525\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2089 - acc: 0.9031 - f1_m: 0.5207 - precision_m: 0.7695 - recall_m: 0.4070\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1953 - acc: 0.9118 - f1_m: 0.5609 - precision_m: 0.7641 - recall_m: 0.4507\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1928 - acc: 0.9121 - f1_m: 0.5911 - precision_m: 0.7625 - recall_m: 0.4943\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1939 - acc: 0.9049 - f1_m: 0.5257 - precision_m: 0.7398 - recall_m: 0.4303\n",
      "154/154 [==============================] - 3s 19ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(32, 16), score=(train=0.929, test=0.908), total=  24.6s\n",
      "[CV] optimizer=nadam, units=(32, 16) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 7s 23ms/step - loss: 0.6592 - acc: 0.6153 - f1_m: 0.2370 - precision_m: 0.1743 - recall_m: 0.4442\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4961 - acc: 0.7492 - f1_m: 0.2870 - precision_m: 0.2403 - recall_m: 0.3819\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.4088 - acc: 0.8223 - f1_m: 0.3739 - precision_m: 0.3761 - recall_m: 0.3986\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3626 - acc: 0.8411 - f1_m: 0.4052 - precision_m: 0.4444 - recall_m: 0.3995\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3405 - acc: 0.8444 - f1_m: 0.3883 - precision_m: 0.4297 - recall_m: 0.3806\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3075 - acc: 0.8632 - f1_m: 0.4158 - precision_m: 0.5082 - recall_m: 0.3701\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2781 - acc: 0.8769 - f1_m: 0.4339 - precision_m: 0.5434 - recall_m: 0.3760\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2687 - acc: 0.8802 - f1_m: 0.4590 - precision_m: 0.5922 - recall_m: 0.3870\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2477 - acc: 0.8856 - f1_m: 0.4816 - precision_m: 0.6073 - recall_m: 0.4190\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2434 - acc: 0.8961 - f1_m: 0.5411 - precision_m: 0.6862 - recall_m: 0.4895\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.8947 - f1_m: 0.5344 - precision_m: 0.6552 - recall_m: 0.4782\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2370 - acc: 0.8969 - f1_m: 0.5136 - precision_m: 0.7027 - recall_m: 0.4278\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2252 - acc: 0.8950 - f1_m: 0.4928 - precision_m: 0.6912 - recall_m: 0.3990\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2184 - acc: 0.9023 - f1_m: 0.5375 - precision_m: 0.7222 - recall_m: 0.4466\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2009 - acc: 0.9121 - f1_m: 0.6266 - precision_m: 0.7532 - recall_m: 0.5537\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2153 - acc: 0.9070 - f1_m: 0.5859 - precision_m: 0.7717 - recall_m: 0.4881\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2030 - acc: 0.9055 - f1_m: 0.5434 - precision_m: 0.7053 - recall_m: 0.4656\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1847 - acc: 0.9189 - f1_m: 0.6421 - precision_m: 0.7870 - recall_m: 0.5597\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1965 - acc: 0.9135 - f1_m: 0.5808 - precision_m: 0.7536 - recall_m: 0.5094\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1855 - acc: 0.9128 - f1_m: 0.5713 - precision_m: 0.8027 - recall_m: 0.4658\n",
      "153/153 [==============================] - 3s 20ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(32, 16), score=(train=0.944, test=0.928), total=  25.1s\n",
      "[CV] optimizer=nadam, units=(32, 16) .................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 7s 23ms/step - loss: 0.5598 - acc: 0.7105 - f1_m: 0.1654 - precision_m: 0.1519 - recall_m: 0.2119\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3910 - acc: 0.8165 - f1_m: 0.2220 - precision_m: 0.2822 - recall_m: 0.1923\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3318 - acc: 0.8494 - f1_m: 0.3198 - precision_m: 0.4492 - recall_m: 0.2608\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.3172 - acc: 0.8592 - f1_m: 0.3574 - precision_m: 0.4979 - recall_m: 0.2894\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2762 - acc: 0.8708 - f1_m: 0.3716 - precision_m: 0.6975 - recall_m: 0.2733\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2853 - acc: 0.8726 - f1_m: 0.3962 - precision_m: 0.5970 - recall_m: 0.3146\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2441 - acc: 0.8979 - f1_m: 0.5354 - precision_m: 0.7264 - recall_m: 0.4374\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2490 - acc: 0.9030 - f1_m: 0.5808 - precision_m: 0.7481 - recall_m: 0.4821\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2495 - acc: 0.8911 - f1_m: 0.5437 - precision_m: 0.6870 - recall_m: 0.4649\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2447 - acc: 0.8950 - f1_m: 0.5688 - precision_m: 0.7283 - recall_m: 0.4761\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2207 - acc: 0.9041 - f1_m: 0.5900 - precision_m: 0.7681 - recall_m: 0.4969\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2184 - acc: 0.9084 - f1_m: 0.6334 - precision_m: 0.7776 - recall_m: 0.5426\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2136 - acc: 0.9102 - f1_m: 0.6405 - precision_m: 0.7617 - recall_m: 0.5606\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2150 - acc: 0.9081 - f1_m: 0.6241 - precision_m: 0.7379 - recall_m: 0.5581\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2053 - acc: 0.9149 - f1_m: 0.6781 - precision_m: 0.7695 - recall_m: 0.6183\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2162 - acc: 0.9016 - f1_m: 0.5858 - precision_m: 0.6945 - recall_m: 0.5117\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2072 - acc: 0.9077 - f1_m: 0.6067 - precision_m: 0.7146 - recall_m: 0.5367\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2017 - acc: 0.9128 - f1_m: 0.6555 - precision_m: 0.7558 - recall_m: 0.5943\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2025 - acc: 0.9135 - f1_m: 0.6483 - precision_m: 0.7822 - recall_m: 0.5673\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1980 - acc: 0.9110 - f1_m: 0.6243 - precision_m: 0.7676 - recall_m: 0.5395\n",
      "153/153 [==============================] - 3s 20ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(32, 16), score=(train=0.940, test=0.922), total=  25.4s\n",
      "[CV] optimizer=nadam, units=(128, 64) ................................\n",
      "Epoch 1/20\n",
      "306/306 [==============================] - 7s 24ms/step - loss: 0.4359 - acc: 0.8177 - f1_m: 0.2206 - precision_m: 0.3173 - recall_m: 0.2038\n",
      "Epoch 2/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2843 - acc: 0.8834 - f1_m: 0.4336 - precision_m: 0.6365 - recall_m: 0.3497\n",
      "Epoch 3/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.9067 - f1_m: 0.5497 - precision_m: 0.7737 - recall_m: 0.4488\n",
      "Epoch 4/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1931 - acc: 0.9230 - f1_m: 0.6542 - precision_m: 0.8150 - recall_m: 0.5590\n",
      "Epoch 5/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1699 - acc: 0.9350 - f1_m: 0.6818 - precision_m: 0.8070 - recall_m: 0.6019\n",
      "Epoch 6/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1926 - acc: 0.9219 - f1_m: 0.6634 - precision_m: 0.8019 - recall_m: 0.6017\n",
      "Epoch 7/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1406 - acc: 0.9448 - f1_m: 0.7221 - precision_m: 0.8924 - recall_m: 0.6406\n",
      "Epoch 8/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1297 - acc: 0.9455 - f1_m: 0.7793 - precision_m: 0.8525 - recall_m: 0.7315\n",
      "Epoch 9/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1019 - acc: 0.9601 - f1_m: 0.8170 - precision_m: 0.8912 - recall_m: 0.7794\n",
      "Epoch 10/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1095 - acc: 0.9528 - f1_m: 0.8011 - precision_m: 0.8661 - recall_m: 0.7632\n",
      "Epoch 11/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9546 - f1_m: 0.8032 - precision_m: 0.8868 - recall_m: 0.7716\n",
      "Epoch 12/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0876 - acc: 0.9637 - f1_m: 0.8582 - precision_m: 0.8879 - recall_m: 0.8402\n",
      "Epoch 13/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0782 - acc: 0.9662 - f1_m: 0.8682 - precision_m: 0.9196 - recall_m: 0.8274\n",
      "Epoch 14/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0797 - acc: 0.9666 - f1_m: 0.8590 - precision_m: 0.8890 - recall_m: 0.8375\n",
      "Epoch 15/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0746 - acc: 0.9688 - f1_m: 0.8738 - precision_m: 0.8935 - recall_m: 0.8586\n",
      "Epoch 16/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0537 - acc: 0.9797 - f1_m: 0.9227 - precision_m: 0.9554 - recall_m: 0.8965\n",
      "Epoch 17/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0655 - acc: 0.9753 - f1_m: 0.9068 - precision_m: 0.9414 - recall_m: 0.8790\n",
      "Epoch 18/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0585 - acc: 0.9746 - f1_m: 0.9007 - precision_m: 0.9270 - recall_m: 0.8852\n",
      "Epoch 19/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0534 - acc: 0.9800 - f1_m: 0.9129 - precision_m: 0.9291 - recall_m: 0.9045\n",
      "Epoch 20/20\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 0.0447 - acc: 0.9837 - f1_m: 0.9437 - precision_m: 0.9531 - recall_m: 0.9369\n",
      "154/154 [==============================] - 3s 19ms/step\n",
      "306/306 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 64), score=(train=0.991, test=0.929), total=  25.8s\n",
      "[CV] optimizer=nadam, units=(128, 64) ................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 0.4282 - acc: 0.8208 - f1_m: 0.1709 - precision_m: 0.4943 - recall_m: 0.1503\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2835 - acc: 0.8849 - f1_m: 0.4228 - precision_m: 0.7370 - recall_m: 0.3155\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.8979 - f1_m: 0.5320 - precision_m: 0.7510 - recall_m: 0.4376\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1890 - acc: 0.9276 - f1_m: 0.6674 - precision_m: 0.7994 - recall_m: 0.5926\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1448 - acc: 0.9396 - f1_m: 0.7570 - precision_m: 0.8532 - recall_m: 0.7042\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1313 - acc: 0.9482 - f1_m: 0.8000 - precision_m: 0.8659 - recall_m: 0.7558\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9511 - f1_m: 0.7910 - precision_m: 0.8469 - recall_m: 0.7641\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9526 - f1_m: 0.8043 - precision_m: 0.8678 - recall_m: 0.7643\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0860 - acc: 0.9653 - f1_m: 0.8630 - precision_m: 0.9007 - recall_m: 0.8377\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0669 - acc: 0.9736 - f1_m: 0.8990 - precision_m: 0.9342 - recall_m: 0.8720\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0718 - acc: 0.9721 - f1_m: 0.8956 - precision_m: 0.9079 - recall_m: 0.8911\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0538 - acc: 0.9805 - f1_m: 0.9192 - precision_m: 0.9397 - recall_m: 0.9026\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0551 - acc: 0.9765 - f1_m: 0.9110 - precision_m: 0.9437 - recall_m: 0.8872\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0399 - acc: 0.9852 - f1_m: 0.9368 - precision_m: 0.9544 - recall_m: 0.9229\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0503 - acc: 0.9826 - f1_m: 0.9209 - precision_m: 0.9181 - recall_m: 0.9360\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0473 - acc: 0.9801 - f1_m: 0.9093 - precision_m: 0.9390 - recall_m: 0.8920\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0369 - acc: 0.9844 - f1_m: 0.9458 - precision_m: 0.9469 - recall_m: 0.9491\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0361 - acc: 0.9862 - f1_m: 0.9533 - precision_m: 0.9662 - recall_m: 0.9433\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0406 - acc: 0.9859 - f1_m: 0.9393 - precision_m: 0.9524 - recall_m: 0.9338\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0305 - acc: 0.9910 - f1_m: 0.9667 - precision_m: 0.9636 - recall_m: 0.9717\n",
      "153/153 [==============================] - 3s 20ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 64), score=(train=0.981, test=0.919), total=  26.2s\n",
      "[CV] optimizer=nadam, units=(128, 64) ................................\n",
      "Epoch 1/20\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 0.4540 - acc: 0.7999 - f1_m: 0.2744 - precision_m: 0.3404 - recall_m: 0.2681\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.8762 - f1_m: 0.4923 - precision_m: 0.5973 - recall_m: 0.4453\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.2397 - acc: 0.9023 - f1_m: 0.6007 - precision_m: 0.7377 - recall_m: 0.5252\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1925 - acc: 0.9229 - f1_m: 0.6809 - precision_m: 0.7964 - recall_m: 0.6029\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1669 - acc: 0.9240 - f1_m: 0.7139 - precision_m: 0.8043 - recall_m: 0.6555\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1523 - acc: 0.9406 - f1_m: 0.7592 - precision_m: 0.8500 - recall_m: 0.7155\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1310 - acc: 0.9475 - f1_m: 0.7953 - precision_m: 0.8967 - recall_m: 0.7310\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.9616 - f1_m: 0.8506 - precision_m: 0.8666 - recall_m: 0.8449\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0876 - acc: 0.9689 - f1_m: 0.8834 - precision_m: 0.9346 - recall_m: 0.8480\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0802 - acc: 0.9674 - f1_m: 0.8809 - precision_m: 0.9163 - recall_m: 0.8570\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0638 - acc: 0.9739 - f1_m: 0.9110 - precision_m: 0.9171 - recall_m: 0.9143\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0774 - acc: 0.9674 - f1_m: 0.8753 - precision_m: 0.9078 - recall_m: 0.8578\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0655 - acc: 0.9747 - f1_m: 0.8900 - precision_m: 0.9218 - recall_m: 0.8729\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0465 - acc: 0.9855 - f1_m: 0.9481 - precision_m: 0.9647 - recall_m: 0.9348\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0470 - acc: 0.9815 - f1_m: 0.9229 - precision_m: 0.9379 - recall_m: 0.9143\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0426 - acc: 0.9841 - f1_m: 0.9430 - precision_m: 0.9586 - recall_m: 0.9325\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0464 - acc: 0.9819 - f1_m: 0.9298 - precision_m: 0.9424 - recall_m: 0.9232\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0431 - acc: 0.9852 - f1_m: 0.9476 - precision_m: 0.9521 - recall_m: 0.9469\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0340 - acc: 0.9881 - f1_m: 0.9564 - precision_m: 0.9691 - recall_m: 0.9470\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0290 - acc: 0.9902 - f1_m: 0.9648 - precision_m: 0.9703 - recall_m: 0.9618\n",
      "153/153 [==============================] - 3s 21ms/step\n",
      "307/307 [==============================] - 0s 1ms/step\n",
      "[CV]  optimizer=nadam, units=(128, 64), score=(train=0.987, test=0.942), total=  26.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "460/460 [==============================] - 8s 18ms/step - loss: 0.4160 - acc: 0.8300 - f1_m: 0.2605 - precision_m: 0.3898 - recall_m: 0.2303\n",
      "Epoch 2/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.2797 - acc: 0.8874 - f1_m: 0.5230 - precision_m: 0.6249 - recall_m: 0.4708\n",
      "Epoch 3/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.2463 - acc: 0.9014 - f1_m: 0.5616 - precision_m: 0.6571 - recall_m: 0.5086\n",
      "Epoch 4/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.2108 - acc: 0.9140 - f1_m: 0.6406 - precision_m: 0.7407 - recall_m: 0.5866\n",
      "Epoch 5/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1881 - acc: 0.9290 - f1_m: 0.7023 - precision_m: 0.8013 - recall_m: 0.6371\n",
      "Epoch 6/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1661 - acc: 0.9324 - f1_m: 0.7186 - precision_m: 0.8082 - recall_m: 0.6607\n",
      "Epoch 7/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1423 - acc: 0.9425 - f1_m: 0.7711 - precision_m: 0.8427 - recall_m: 0.7233\n",
      "Epoch 8/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1237 - acc: 0.9522 - f1_m: 0.8057 - precision_m: 0.8760 - recall_m: 0.7595\n",
      "Epoch 9/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1109 - acc: 0.9568 - f1_m: 0.8324 - precision_m: 0.8752 - recall_m: 0.8014\n",
      "Epoch 10/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.1112 - acc: 0.9575 - f1_m: 0.8302 - precision_m: 0.8641 - recall_m: 0.8142\n",
      "Epoch 11/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0951 - acc: 0.9640 - f1_m: 0.8584 - precision_m: 0.8894 - recall_m: 0.8420\n",
      "Epoch 12/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0853 - acc: 0.9696 - f1_m: 0.8824 - precision_m: 0.9237 - recall_m: 0.8538\n",
      "Epoch 13/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0825 - acc: 0.9664 - f1_m: 0.8632 - precision_m: 0.8891 - recall_m: 0.8436\n",
      "Epoch 14/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0711 - acc: 0.9737 - f1_m: 0.8924 - precision_m: 0.9217 - recall_m: 0.8752\n",
      "Epoch 15/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0712 - acc: 0.9732 - f1_m: 0.9017 - precision_m: 0.9153 - recall_m: 0.8938\n",
      "Epoch 16/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0602 - acc: 0.9766 - f1_m: 0.9091 - precision_m: 0.9067 - recall_m: 0.9190\n",
      "Epoch 17/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0570 - acc: 0.9780 - f1_m: 0.9244 - precision_m: 0.9412 - recall_m: 0.9120\n",
      "Epoch 18/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0474 - acc: 0.9819 - f1_m: 0.9263 - precision_m: 0.9361 - recall_m: 0.9209\n",
      "Epoch 19/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0525 - acc: 0.9797 - f1_m: 0.9219 - precision_m: 0.9404 - recall_m: 0.9088\n",
      "Epoch 20/20\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.0459 - acc: 0.9843 - f1_m: 0.9460 - precision_m: 0.9628 - recall_m: 0.9314\n",
      "Best: 0.946881 using {'optimizer': 'adam', 'units': (128, 32)}\n",
      "0.936272 (0.013098) with: {'optimizer': 'rmsprop', 'units': (64, 32)}\n",
      "0.944209 (0.002218) with: {'optimizer': 'rmsprop', 'units': (128, 32)}\n",
      "0.913767 (0.014826) with: {'optimizer': 'rmsprop', 'units': (32, 16)}\n",
      "0.927509 (0.009712) with: {'optimizer': 'rmsprop', 'units': (128, 64)}\n",
      "0.937701 (0.007233) with: {'optimizer': 'adam', 'units': (64, 32)}\n",
      "0.946881 (0.006831) with: {'optimizer': 'adam', 'units': (128, 32)}\n",
      "0.920284 (0.002733) with: {'optimizer': 'adam', 'units': (32, 16)}\n",
      "0.945914 (0.007840) with: {'optimizer': 'adam', 'units': (128, 64)}\n",
      "0.926816 (0.004071) with: {'optimizer': 'adagrad', 'units': (64, 32)}\n",
      "0.934578 (0.012508) with: {'optimizer': 'adagrad', 'units': (128, 32)}\n",
      "0.916691 (0.007947) with: {'optimizer': 'adagrad', 'units': (32, 16)}\n",
      "0.939630 (0.007932) with: {'optimizer': 'adagrad', 'units': (128, 64)}\n",
      "0.922468 (0.013995) with: {'optimizer': 'adadelta', 'units': (64, 32)}\n",
      "0.928521 (0.008707) with: {'optimizer': 'adadelta', 'units': (128, 32)}\n",
      "0.905299 (0.016691) with: {'optimizer': 'adadelta', 'units': (32, 16)}\n",
      "0.929239 (0.004545) with: {'optimizer': 'adadelta', 'units': (128, 64)}\n",
      "0.934097 (0.012583) with: {'optimizer': 'nadam', 'units': (64, 32)}\n",
      "0.941065 (0.001114) with: {'optimizer': 'nadam', 'units': (128, 32)}\n",
      "0.919348 (0.008209) with: {'optimizer': 'nadam', 'units': (32, 16)}\n",
      "0.929955 (0.009243) with: {'optimizer': 'nadam', 'units': (128, 64)}\n",
      "total time: 1085.0981695652008\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "start= time()\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model_vgg16,epochs=20, \n",
    "                        batch_size=16,verbose=1)\n",
    "\n",
    "units=[(64,32),(128,32),(32,16),(128,64)]\n",
    "optimizers = ['rmsprop', 'adam','adagrad','adadelta','nadam']\n",
    "param_grid = dict(optimizer=optimizers,units=units)\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid,\n",
    "                    return_train_score=True,\n",
    "                    #scoring=['precision_macro','recall_macro','f1_macro'],\n",
    "                    refit='precision_m',\n",
    "                    cv=3,\n",
    "                    verbose=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(\"total time:\",time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149415,
     "status": "ok",
     "timestamp": 1582076310948,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "-BYLC9hegFrd",
    "outputId": "8920e83f-c535-4aa3-a26f-8aceeb49bb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 validated image filenames.\n",
      "(100, 128, 128, 3) (100, 9)\n",
      "100/100 [==============================] - 3s 33ms/step\n",
      "[[1.07288361e-06 2.98023224e-07 2.08616257e-07 2.02953815e-05\n",
      "  1.54078007e-05 2.38418579e-05 3.57627869e-07 1.22487545e-05\n",
      "  2.42888927e-05]\n",
      " [1.30236149e-05 9.08374786e-05 8.45491886e-05 3.95774841e-05\n",
      "  5.88774681e-04 9.93951023e-01 7.70390034e-05 4.05788422e-04\n",
      "  8.13722610e-04]\n",
      " [2.68220901e-07 5.96046448e-07 9.23871994e-07 2.47359276e-05\n",
      "  8.67247581e-06 1.14977360e-04 2.38418579e-07 3.38554382e-05\n",
      "  2.38418579e-06]\n",
      " [8.40425491e-06 2.86102295e-06 7.86781311e-06 1.25676394e-04\n",
      "  9.03606415e-05 1.44335628e-03 4.00543213e-05 1.71542168e-04\n",
      "  1.11192465e-04]\n",
      " [4.10404801e-03 9.98603106e-01 1.15281343e-02 1.13715529e-02\n",
      "  1.10040307e-02 1.31726265e-04 2.13146210e-04 1.31845474e-04\n",
      "  7.21210241e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.34110451e-06\n",
      "  5.96046448e-08 0.00000000e+00 0.00000000e+00 1.19209290e-07\n",
      "  1.19209290e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.80820847e-06\n",
      "  3.57627869e-07 2.98023224e-08 0.00000000e+00 7.15255737e-07\n",
      "  2.98023224e-07]\n",
      " [4.42947865e-01 4.10228968e-04 9.62316990e-05 7.11261630e-01\n",
      "  2.60201097e-01 1.16825104e-05 2.52932310e-04 6.01288438e-01\n",
      "  2.93523073e-04]\n",
      " [3.63588333e-06 6.55651093e-07 5.96046448e-08 1.78217888e-05\n",
      "  2.97725201e-05 5.96046448e-08 2.68220901e-07 1.25169754e-06\n",
      "  3.11136246e-05]\n",
      " [8.64267349e-06 1.62720680e-05 4.00841236e-05 3.85046005e-05\n",
      "  3.10957432e-04 9.86842573e-01 7.18832016e-05 3.17841768e-04\n",
      "  4.06533480e-04]\n",
      " [9.40613031e-01 9.98783529e-01 9.16115761e-01 4.33308482e-02\n",
      "  8.85151386e-01 1.98602676e-04 7.33345747e-04 4.24980551e-01\n",
      "  3.13342810e-02]\n",
      " [1.69873238e-06 4.38094139e-06 9.83476639e-07 3.66270542e-05\n",
      "  2.11298466e-05 4.64618206e-05 9.23871994e-07 1.44541264e-05\n",
      "  2.19643116e-05]\n",
      " [7.95722008e-06 2.89082527e-06 7.03334808e-06 1.02758408e-04\n",
      "  8.83638859e-05 1.92022324e-03 4.21404839e-05 1.77025795e-04\n",
      "  1.18225813e-04]\n",
      " [9.93032813e-01 9.99997735e-01 9.85704899e-01 6.53386116e-04\n",
      "  9.98486280e-01 0.00000000e+00 1.60962343e-04 5.03957272e-05\n",
      "  9.90224004e-01]\n",
      " [9.87168312e-01 9.99840021e-01 9.89321470e-01 2.00615227e-02\n",
      "  9.90256906e-01 1.48415565e-05 6.74804449e-02 6.53842092e-03\n",
      "  9.42780614e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.78813934e-07\n",
      "  1.19209290e-07 1.49011612e-07 0.00000000e+00 2.98023224e-08\n",
      "  5.96046448e-08]\n",
      " [1.12879276e-03 1.28321290e-01 1.05160475e-03 2.04700232e-03\n",
      "  1.92356110e-03 1.45760179e-03 8.30447674e-02 6.72698021e-04\n",
      "  2.82034278e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.32133675e-06\n",
      "  1.78813934e-07 0.00000000e+00 0.00000000e+00 4.17232513e-07\n",
      "  1.49011612e-07]\n",
      " [8.87101889e-03 9.98964965e-01 5.37046790e-03 6.21155500e-02\n",
      "  1.25317574e-02 1.48117542e-05 2.97188759e-04 5.67138195e-05\n",
      "  1.31992698e-02]\n",
      " [1.51991844e-06 2.38418579e-07 5.96046448e-08 6.49690628e-05\n",
      "  1.20103359e-05 7.09295273e-06 2.68220901e-07 4.29153442e-06\n",
      "  1.96993351e-05]\n",
      " [5.75602055e-04 6.57141209e-05 1.33216381e-05 5.48362732e-06\n",
      "  1.20297074e-03 2.41398811e-05 2.84314156e-05 2.91466713e-05\n",
      "  9.88410175e-01]\n",
      " [3.90410423e-06 1.73747540e-05 1.65998936e-05 1.62124634e-05\n",
      "  2.59876251e-04 9.96847928e-01 2.95937061e-05 1.51962042e-04\n",
      "  4.09960747e-04]\n",
      " [9.78152990e-01 9.99573231e-01 9.73185003e-01 1.31900728e-01\n",
      "  9.32535768e-01 4.88758087e-05 3.02013755e-03 8.41070414e-02\n",
      "  2.81482220e-01]\n",
      " [2.98023224e-06 5.66244125e-07 4.76837158e-07 3.70144844e-05\n",
      "  4.10676003e-05 1.02818012e-05 2.68220901e-07 1.59144402e-05\n",
      "  2.47955322e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.18884850e-06\n",
      "  1.19209290e-07 0.00000000e+00 0.00000000e+00 3.57627869e-07\n",
      "  1.78813934e-07]\n",
      " [1.17912889e-03 4.53710556e-03 6.90692663e-03 3.03831697e-03\n",
      "  3.21787596e-03 6.78189993e-02 1.82825327e-03 4.62561846e-03\n",
      "  2.99042463e-03]\n",
      " [9.90233779e-01 9.99628186e-01 9.85545039e-01 7.53582120e-02\n",
      "  9.70517159e-01 2.77161598e-05 3.18530202e-03 1.02971166e-01\n",
      "  3.93677682e-01]\n",
      " [7.99429417e-02 9.98920441e-01 9.61669981e-02 8.46660733e-01\n",
      "  7.24518299e-03 3.72827053e-05 6.70880079e-04 1.73616409e-03\n",
      "  3.72737646e-03]\n",
      " [3.37153673e-04 1.25852227e-03 4.83095646e-05 8.10921192e-04\n",
      "  3.38852406e-04 1.86771154e-04 6.72583282e-02 6.41196966e-04\n",
      "  1.29261613e-03]\n",
      " [7.72126794e-01 9.99667406e-01 8.45713854e-01 2.72515416e-03\n",
      "  8.65261793e-01 6.14523888e-05 1.33275986e-04 2.10546255e-01\n",
      "  8.10217857e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.78813934e-07\n",
      "  1.49011612e-07 1.07288361e-06 0.00000000e+00 2.98023224e-08\n",
      "  8.94069672e-08]\n",
      " [3.57627869e-07 1.49011612e-07 0.00000000e+00 2.88486481e-05\n",
      "  3.54647636e-06 2.62260437e-06 1.78813934e-07 1.54972076e-06\n",
      "  5.15580177e-06]\n",
      " [2.32458115e-06 3.27825546e-06 4.76837158e-07 2.98023224e-05\n",
      "  1.34408474e-05 4.18126583e-05 9.11355019e-05 1.64806843e-05\n",
      "  2.96533108e-05]\n",
      " [1.19736493e-02 9.99383569e-01 3.59554887e-02 2.26140469e-01\n",
      "  6.35963678e-03 3.68356705e-05 2.91407108e-04 6.16610050e-04\n",
      "  1.56596303e-03]\n",
      " [1.07288361e-05 2.64644623e-05 1.25169754e-06 4.35739756e-04\n",
      "  3.16500664e-05 8.64267349e-07 7.27176666e-06 3.31699848e-05\n",
      "  2.11596489e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.80820847e-06\n",
      "  1.78813934e-07 0.00000000e+00 0.00000000e+00 1.19209290e-07\n",
      "  2.98023224e-08]\n",
      " [8.48638833e-01 9.98658538e-01 8.02390575e-01 9.14137840e-01\n",
      "  1.55908406e-01 1.16109848e-04 5.31226397e-03 1.30817980e-01\n",
      "  1.06707811e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.20401382e-05\n",
      "  1.19209290e-07 0.00000000e+00 0.00000000e+00 1.49011612e-07\n",
      "  2.98023224e-08]\n",
      " [9.95335817e-01 9.99868274e-01 9.88660097e-01 1.31576359e-02\n",
      "  9.96491015e-01 3.24845314e-06 6.89843297e-03 3.27048302e-02\n",
      "  8.02697361e-01]\n",
      " [8.50215554e-03 9.98659849e-01 3.10369134e-02 2.06617385e-01\n",
      "  2.88358331e-03 3.85046005e-05 5.61237335e-04 5.24073839e-04\n",
      "  8.78006220e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.49011612e-07\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [2.01573163e-01 9.38326120e-04 1.61778331e-02 1.84481680e-01\n",
      "  1.03958368e-01 3.33257914e-02 4.15882468e-03 1.11015767e-01\n",
      "  5.21972477e-02]\n",
      " [8.09809089e-01 9.98975873e-01 7.54812121e-01 2.46338904e-01\n",
      "  6.44364059e-01 7.65323639e-05 1.48633122e-03 7.49762952e-02\n",
      "  3.75168920e-02]\n",
      " [8.05020332e-04 2.81035900e-05 1.62988901e-04 1.47977471e-03\n",
      "  7.68673420e-03 6.99195564e-02 2.32845545e-04 4.58198786e-03\n",
      "  5.98266721e-03]\n",
      " [7.57452846e-03 1.16676092e-04 3.91006470e-05 1.23715818e-01\n",
      "  1.59070194e-02 8.94069672e-06 3.70740891e-05 5.21393716e-02\n",
      "  5.39422035e-05]\n",
      " [1.10785365e-02 8.69631767e-05 2.86996365e-05 1.76843554e-01\n",
      "  1.80967450e-02 6.25848770e-06 3.91900539e-05 7.03774393e-02\n",
      "  4.25875187e-05]\n",
      " [8.04202676e-01 2.48491764e-04 1.57922506e-04 8.78529549e-01\n",
      "  6.58606529e-01 2.11894512e-05 1.26272440e-04 9.06926632e-01\n",
      "  3.24100256e-04]\n",
      " [3.57627869e-07 1.04308128e-06 8.94069672e-08 2.13682652e-05\n",
      "  5.60283661e-06 5.09619713e-06 6.25848770e-07 1.43051147e-06\n",
      "  6.07967377e-06]\n",
      " [3.57627869e-06 3.45706940e-06 6.25848770e-07 5.17666340e-05\n",
      "  1.32024288e-05 6.35981560e-05 2.65777111e-04 2.81035900e-05\n",
      "  2.93254852e-05]\n",
      " [2.82366574e-02 2.69842744e-02 4.38846648e-02 5.88828325e-03\n",
      "  1.18564248e-01 8.02369356e-01 1.63693130e-02 1.51471198e-02\n",
      "  1.89936727e-01]\n",
      " [9.92158532e-01 9.99838829e-01 9.84165788e-01 3.23238373e-02\n",
      "  9.92101312e-01 4.50015068e-06 1.04753375e-02 1.57232881e-02\n",
      "  8.32237959e-01]\n",
      " [2.71201134e-06 3.06963921e-06 4.76837158e-07 4.10676003e-05\n",
      "  1.18911266e-05 6.09755516e-05 1.96695328e-04 2.31862068e-05\n",
      "  2.36034393e-05]\n",
      " [1.19209290e-07 3.57627869e-07 0.00000000e+00 6.19888306e-06\n",
      "  4.32133675e-06 1.96695328e-05 1.19209290e-07 7.86781311e-06\n",
      "  5.09619713e-06]\n",
      " [1.03424788e-02 9.99365091e-01 3.30922604e-02 2.03266650e-01\n",
      "  5.76171279e-03 3.90410423e-05 3.04549932e-04 5.66154718e-04\n",
      "  1.45393610e-03]\n",
      " [7.04169273e-03 9.98894215e-01 3.72660160e-03 4.78520095e-02\n",
      "  1.17219090e-02 1.07586384e-05 2.75701284e-04 4.15146351e-05\n",
      "  1.20857656e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.78813934e-07\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.94069672e-08]\n",
      " [2.37455964e-03 4.39357758e-03 2.34842300e-04 3.89534235e-03\n",
      "  9.38445330e-04 4.47124243e-04 3.73467028e-01 3.15392017e-03\n",
      "  2.97078490e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.67247581e-06\n",
      "  5.96046448e-08 0.00000000e+00 0.00000000e+00 1.49011612e-07\n",
      "  0.00000000e+00]\n",
      " [2.01761723e-05 1.06329918e-02 3.78489494e-06 1.77264214e-04\n",
      "  6.58035278e-05 6.40749931e-06 1.33901834e-04 6.79492950e-06\n",
      "  3.08394432e-04]\n",
      " [4.23192978e-06 1.49011612e-06 1.05798244e-05 2.05636024e-05\n",
      "  4.04506922e-04 9.99198556e-01 1.38878822e-05 1.96337700e-04\n",
      "  5.32001257e-04]\n",
      " [6.13927841e-06 1.81794167e-06 1.31130219e-06 7.14659691e-05\n",
      "  7.74562359e-05 2.29179859e-05 5.36441803e-07 3.49581242e-05\n",
      "  3.91304493e-05]\n",
      " [1.93715096e-06 5.36441803e-07 2.98023224e-08 1.05798244e-05\n",
      "  2.02357769e-05 2.98023224e-08 5.96046448e-08 7.74860382e-07\n",
      "  8.40425491e-06]\n",
      " [8.31484795e-06 2.92062759e-06 7.30156898e-06 9.11355019e-05\n",
      "  1.04665756e-04 2.94756889e-03 3.89516354e-05 1.94549561e-04\n",
      "  1.36494637e-04]\n",
      " [1.90734863e-06 5.09619713e-06 1.07288361e-06 4.12464142e-05\n",
      "  2.32160091e-05 4.77731228e-05 1.01327896e-06 1.61826611e-05\n",
      "  2.38120556e-05]\n",
      " [9.81868744e-01 9.99496520e-01 9.73789871e-01 1.36858046e-01\n",
      "  9.39472437e-01 4.83393669e-05 3.25456262e-03 1.10161602e-01\n",
      "  2.63886809e-01]\n",
      " [9.87036943e-01 9.99758720e-01 9.72667098e-01 2.55304575e-03\n",
      "  9.88502502e-01 1.80006027e-05 1.06364489e-04 7.24735141e-01\n",
      "  1.59811974e-02]\n",
      " [1.16229057e-05 2.31862068e-05 1.08480453e-05 7.75754452e-05\n",
      "  1.14828348e-04 5.93930483e-04 4.61935997e-06 6.02006912e-05\n",
      "  1.20908022e-03]\n",
      " [1.29303336e-03 3.61111760e-03 1.58101320e-04 2.18960643e-03\n",
      "  9.41693783e-04 3.25441360e-04 1.58219874e-01 1.45041943e-03\n",
      "  3.19790840e-03]\n",
      " [3.15904617e-06 2.65240669e-06 5.39422035e-06 5.73337078e-04\n",
      "  2.89678574e-05 8.10623169e-05 8.49366188e-06 1.92761421e-04\n",
      "  4.41074371e-06]\n",
      " [6.79676771e-01 9.98988867e-01 6.58060491e-01 3.16359520e-01\n",
      "  4.77888972e-01 9.41753387e-05 1.81657076e-03 3.36003900e-02\n",
      "  4.14865613e-02]\n",
      " [6.61611557e-06 5.78165054e-06 2.17556953e-06 1.21593475e-05\n",
      "  6.61909580e-05 5.10841608e-04 1.87754631e-06 1.29342079e-05\n",
      "  3.35901976e-04]\n",
      " [1.25169754e-06 2.08616257e-06 2.38418579e-07 5.22136688e-05\n",
      "  1.84774399e-05 1.46329403e-05 1.31130219e-06 4.64916229e-06\n",
      "  1.86860561e-05]\n",
      " [5.32567501e-05 4.11272049e-06 1.64210796e-05 6.96477294e-03\n",
      "  5.39958477e-04 5.31971455e-05 7.80820847e-06 8.87095928e-04\n",
      "  2.05934048e-05]\n",
      " [9.81265426e-01 5.62679768e-03 1.06176734e-03 9.38347816e-01\n",
      "  9.02953029e-01 5.23030758e-05 1.04007125e-03 9.78119433e-01\n",
      "  2.42823362e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.25848770e-07\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [9.23871994e-07 2.08616257e-07 1.78813934e-07 2.19047070e-05\n",
      "  1.60336494e-05 1.13844872e-05 1.49011612e-07 1.13546848e-05\n",
      "  1.05798244e-05]\n",
      " [4.86463308e-04 5.98400831e-04 1.23381615e-05 2.57843733e-03\n",
      "  4.00930643e-04 5.66244125e-07 7.19130039e-05 2.85476446e-04\n",
      "  1.96367502e-04]\n",
      " [5.96046448e-06 2.80141830e-06 1.87754631e-06 9.80496407e-05\n",
      "  7.48038292e-05 3.09348106e-05 8.04662704e-07 4.79817390e-05\n",
      "  3.36766243e-05]\n",
      " [4.37715650e-03 1.67897344e-03 3.93652916e-03 8.36652517e-03\n",
      "  6.70120120e-02 2.35262513e-03 1.58160925e-04 2.58147717e-03\n",
      "  2.49558687e-02]\n",
      " [9.44733620e-06 3.36766243e-06 1.81794167e-05 4.18424606e-05\n",
      "  6.86347485e-04 9.98751760e-01 3.29613686e-05 3.51995230e-04\n",
      "  7.03006983e-04]\n",
      " [2.98023224e-08 0.00000000e+00 0.00000000e+00 7.03334808e-06\n",
      "  5.96046448e-07 3.27825546e-07 2.98023224e-08 4.76837158e-07\n",
      "  7.74860382e-07]\n",
      " [2.33352184e-05 1.51038170e-04 1.08659267e-04 5.63263893e-05\n",
      "  7.80791044e-04 9.81899917e-01 9.47117805e-05 4.29362059e-04\n",
      "  1.40509009e-03]\n",
      " [1.37090683e-06 1.78813934e-07 4.17232513e-07 3.82661819e-05\n",
      "  2.64942646e-05 5.60283661e-06 0.00000000e+00 2.60770321e-05\n",
      "  1.25467777e-05]\n",
      " [9.18209553e-05 3.16500664e-05 3.56972218e-04 9.53972340e-05\n",
      "  7.65737891e-03 9.98136103e-01 6.52968884e-05 6.19679689e-04\n",
      "  1.41186714e-02]\n",
      " [4.05311584e-06 4.79817390e-06 8.34465027e-07 5.61475754e-05\n",
      "  1.60634518e-05 9.04500484e-05 3.67879868e-04 3.49581242e-05\n",
      "  3.54647636e-05]\n",
      " [8.17403197e-03 1.81892782e-01 6.75761700e-03 2.55900621e-03\n",
      "  4.89336252e-03 1.91429257e-03 8.80632460e-01 4.21684980e-03\n",
      "  1.54830813e-02]\n",
      " [7.67244995e-02 9.98923302e-01 9.03116763e-02 8.06540370e-01\n",
      "  1.08266473e-02 4.53591347e-05 7.34537840e-04 1.61719322e-03\n",
      "  5.00640273e-03]\n",
      " [5.85317612e-05 9.26852226e-06 7.45058060e-05 2.57730484e-04\n",
      "  2.37205625e-03 9.46506023e-01 6.60717487e-05 7.18533993e-04\n",
      "  1.34569407e-03]\n",
      " [5.96046448e-07 2.68220901e-07 2.86102295e-06 3.81469727e-06\n",
      "  1.19149685e-04 9.99612391e-01 2.68220901e-06 6.19590282e-05\n",
      "  9.43541527e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.66594982e-05\n",
      "  2.08616257e-07 0.00000000e+00 0.00000000e+00 1.19209290e-07\n",
      "  5.96046448e-08]\n",
      " [7.78984785e-01 9.98118877e-01 7.40313172e-01 9.33083415e-01\n",
      "  8.82743001e-02 2.02536583e-04 4.77552414e-03 1.34022117e-01\n",
      "  7.01600313e-03]\n",
      " [1.33514404e-05 9.08970833e-06 4.44054604e-06 2.33054161e-05\n",
      "  1.24573708e-04 1.01417303e-03 3.84449959e-06 2.57790089e-05\n",
      "  7.27921724e-04]\n",
      " [1.28567219e-04 6.40749931e-06 5.96046448e-05 1.33173466e-02\n",
      "  9.18835402e-04 2.01642513e-04 6.73532486e-06 3.67677212e-03\n",
      "  2.56299973e-05]\n",
      " [7.19413698e-01 9.98380482e-01 6.99766099e-01 2.94766128e-01\n",
      "  4.65228349e-01 1.36554241e-04 1.92579627e-03 7.24998116e-02\n",
      "  2.79447436e-02]\n",
      " [3.35370362e-01 9.99500394e-01 5.02908945e-01 8.71720135e-01\n",
      "  3.77660692e-02 5.41508198e-05 1.01187825e-03 5.92273474e-03\n",
      "  1.00172758e-02]\n",
      " [3.82310361e-01 2.94722915e-02 7.95257390e-02 5.51116645e-01\n",
      "  1.17916763e-01 4.89830971e-04 1.13666058e-04 2.30101198e-01\n",
      "  1.27398372e-02]\n",
      " [3.80277634e-05 5.56707382e-04 1.18017197e-05 3.54290009e-04\n",
      "  1.41084194e-04 6.99758530e-05 2.28911638e-04 6.54757023e-05\n",
      "  1.54405832e-04]\n",
      " [5.74904680e-03 9.98680949e-01 1.66807771e-02 2.03017294e-02\n",
      "  1.59850121e-02 1.79469585e-04 2.91228294e-04 3.74585390e-04\n",
      "  4.69017029e-03]\n",
      " [7.84289837e-03 9.98944879e-01 4.28819656e-03 4.88232076e-02\n",
      "  1.26799643e-02 1.14142895e-05 2.87294388e-04 4.16338444e-05\n",
      "  1.42145455e-02]\n",
      " [8.94069672e-08 0.00000000e+00 2.98023224e-08 1.86264515e-05\n",
      "  1.75833702e-06 3.03983688e-06 0.00000000e+00 1.16229057e-06\n",
      "  7.45058060e-07]]\n",
      "100 100 100\n",
      "O recall é intuitivamente a capacidade do classificador encontrar todas as amostras positivas.\n",
      "\n",
      "A precisão é intuitivamente a capacidade do classificador não rotular como positiva uma amostra negativa.\n",
      "\n",
      "A pontuação F1 pode ser interpretada como uma média ponderada da precisão e recall.\n",
      "\n",
      "Support é a quantidade de ocorrencia da classe.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    adptador       0.90      0.95      0.92        19\n",
      "     bandeja       1.00      1.00      1.00        26\n",
      "     bateria       1.00      0.94      0.97        17\n",
      "        cabo       0.80      0.89      0.84         9\n",
      "  carregador       1.00      0.94      0.97        16\n",
      "    cartucho       1.00      0.83      0.91        12\n",
      "      coldre       1.00      0.40      0.57         5\n",
      "    pendrive       1.00      0.36      0.53        14\n",
      "       spark       0.83      1.00      0.91         5\n",
      "\n",
      "   micro avg       0.95      0.85      0.90       123\n",
      "   macro avg       0.95      0.81      0.85       123\n",
      "weighted avg       0.96      0.85      0.88       123\n",
      " samples avg       0.41      0.40      0.40       123\n",
      "\n",
      "Matrix confusão do(a) adptador\n",
      "[[79  2]\n",
      " [ 1 18]] \n",
      "\n",
      "Matrix confusão do(a) bandeja\n",
      "[[74  0]\n",
      " [ 0 26]] \n",
      "\n",
      "Matrix confusão do(a) bateria\n",
      "[[83  0]\n",
      " [ 1 16]] \n",
      "\n",
      "Matrix confusão do(a) cabo\n",
      "[[89  2]\n",
      " [ 1  8]] \n",
      "\n",
      "Matrix confusão do(a) carregador\n",
      "[[84  0]\n",
      " [ 1 15]] \n",
      "\n",
      "Matrix confusão do(a) cartucho\n",
      "[[88  0]\n",
      " [ 2 10]] \n",
      "\n",
      "Matrix confusão do(a) coldre\n",
      "[[95  0]\n",
      " [ 3  2]] \n",
      "\n",
      "Matrix confusão do(a) pendrive\n",
      "[[86  0]\n",
      " [ 9  5]] \n",
      "\n",
      "Matrix confusão do(a) spark\n",
      "[[94  1]\n",
      " [ 0  5]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
    "\n",
    "datagen_test =  ImageDataGenerator(\n",
    "  rescale=1. / 255)\n",
    "\n",
    "img_iter_test = datagen_test.flow_from_dataframe(\n",
    "    data_frame,\n",
    "    directory=path,\n",
    "    x_col='filename',\n",
    "    y_col=columns,\n",
    "    class_mode='other',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=100\n",
    ")\n",
    "def prob_to_binary(predict,threshold):\n",
    "  return (predict >= threshold).astype(int)\n",
    "\n",
    "X_test,y_test=img_iter_test.next()\n",
    "\n",
    "print(X_test.shape,y_test.shape)\n",
    "\n",
    "proba=grid.predict_proba(X_test)\n",
    "t = 0.3 # threshold value\n",
    "print(proba)\n",
    "y_pred_new = prob_to_binary(proba,t)\n",
    "\n",
    "print(len(y_test),len(proba),len(y_pred_new))\n",
    "cm=multilabel_confusion_matrix(y_test,y_pred_new)\n",
    "print(\"O recall é intuitivamente a capacidade do classificador encontrar todas as amostras positivas.\\n\")\n",
    "print(\"A precisão é intuitivamente a capacidade do classificador não rotular como positiva uma amostra negativa.\\n\")\n",
    "print(\"A pontuação F1 pode ser interpretada como uma média ponderada da precisão e recall.\\n\")\n",
    "print(\"Support é a quantidade de ocorrencia da classe.\\n\")\n",
    "print( classification_report(y_test,y_pred_new,target_names=mbl.classes_))\n",
    "\n",
    "for i,label in enumerate(mbl.classes_):\n",
    "  print(\"Matrix confusão do(a) {}\".format(label))\n",
    "  print(cm[i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149401,
     "status": "ok",
     "timestamp": 1582076310950,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "6-b94CXnXbyb",
    "outputId": "1e73ae06-77f7-482c-afe4-58a01385f843"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025555555555555557"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "hamming_loss(y_test,y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257033,
     "status": "ok",
     "timestamp": 1582078452231,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "7a0AEEjl0k3i",
    "outputId": "6378ad2d-b898-49a7-beac-3f8ed4060323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 8s - loss: 3.0233 - acc: 0.7952 - f1_m: 0.1847 - precision_m: 0.2539 - recall_m: 0.1711\n",
      "Epoch 2/500\n",
      " - 0s - loss: 2.0604 - acc: 0.8698 - f1_m: 0.3654 - precision_m: 0.5778 - recall_m: 0.2707\n",
      "Epoch 3/500\n",
      " - 0s - loss: 1.6253 - acc: 0.8884 - f1_m: 0.4733 - precision_m: 0.7030 - recall_m: 0.3663\n",
      "Epoch 4/500\n",
      " - 0s - loss: 1.4378 - acc: 0.9065 - f1_m: 0.6118 - precision_m: 0.7169 - recall_m: 0.5431\n",
      "Epoch 5/500\n",
      " - 1s - loss: 1.2583 - acc: 0.9097 - f1_m: 0.6152 - precision_m: 0.7607 - recall_m: 0.5271\n",
      "Epoch 6/500\n",
      " - 0s - loss: 1.0717 - acc: 0.9176 - f1_m: 0.6800 - precision_m: 0.7471 - recall_m: 0.6367\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.9280 - acc: 0.9345 - f1_m: 0.7417 - precision_m: 0.8231 - recall_m: 0.6892\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.8063 - acc: 0.9403 - f1_m: 0.7739 - precision_m: 0.8179 - recall_m: 0.7430\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.7228 - acc: 0.9440 - f1_m: 0.7934 - precision_m: 0.8368 - recall_m: 0.7625\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.6023 - acc: 0.9551 - f1_m: 0.8303 - precision_m: 0.8759 - recall_m: 0.7978\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.5283 - acc: 0.9635 - f1_m: 0.8688 - precision_m: 0.8956 - recall_m: 0.8463\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.4833 - acc: 0.9638 - f1_m: 0.8650 - precision_m: 0.9093 - recall_m: 0.8317\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.4629 - acc: 0.9679 - f1_m: 0.8827 - precision_m: 0.9048 - recall_m: 0.8681\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.4426 - acc: 0.9717 - f1_m: 0.8927 - precision_m: 0.9103 - recall_m: 0.8787\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.3981 - acc: 0.9737 - f1_m: 0.9042 - precision_m: 0.9267 - recall_m: 0.8862\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.3356 - acc: 0.9775 - f1_m: 0.9162 - precision_m: 0.9448 - recall_m: 0.8915\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.3261 - acc: 0.9761 - f1_m: 0.9060 - precision_m: 0.9225 - recall_m: 0.8942\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.2725 - acc: 0.9836 - f1_m: 0.9422 - precision_m: 0.9599 - recall_m: 0.9271\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.2511 - acc: 0.9860 - f1_m: 0.9496 - precision_m: 0.9742 - recall_m: 0.9277\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.2871 - acc: 0.9792 - f1_m: 0.9215 - precision_m: 0.9272 - recall_m: 0.9181\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.2513 - acc: 0.9831 - f1_m: 0.9369 - precision_m: 0.9470 - recall_m: 0.9284\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.2228 - acc: 0.9853 - f1_m: 0.9448 - precision_m: 0.9539 - recall_m: 0.9378\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.2589 - acc: 0.9807 - f1_m: 0.9292 - precision_m: 0.9444 - recall_m: 0.9154\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.1868 - acc: 0.9894 - f1_m: 0.9632 - precision_m: 0.9656 - recall_m: 0.9617\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.2328 - acc: 0.9848 - f1_m: 0.9440 - precision_m: 0.9585 - recall_m: 0.9327\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.1927 - acc: 0.9899 - f1_m: 0.9651 - precision_m: 0.9753 - recall_m: 0.9560\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.1791 - acc: 0.9865 - f1_m: 0.9499 - precision_m: 0.9599 - recall_m: 0.9413\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.2022 - acc: 0.9848 - f1_m: 0.9407 - precision_m: 0.9494 - recall_m: 0.9331\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.1843 - acc: 0.9886 - f1_m: 0.9559 - precision_m: 0.9624 - recall_m: 0.9501\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.1543 - acc: 0.9891 - f1_m: 0.9609 - precision_m: 0.9668 - recall_m: 0.9568\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.1334 - acc: 0.9920 - f1_m: 0.9704 - precision_m: 0.9722 - recall_m: 0.9692\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.1178 - acc: 0.9920 - f1_m: 0.9711 - precision_m: 0.9830 - recall_m: 0.9604\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.1569 - acc: 0.9901 - f1_m: 0.9636 - precision_m: 0.9714 - recall_m: 0.9573\n",
      "Epoch 34/500\n",
      " - 1s - loss: 0.1125 - acc: 0.9906 - f1_m: 0.9666 - precision_m: 0.9808 - recall_m: 0.9535\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.0919 - acc: 0.9940 - f1_m: 0.9779 - precision_m: 0.9831 - recall_m: 0.9736\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.1325 - acc: 0.9911 - f1_m: 0.9682 - precision_m: 0.9768 - recall_m: 0.9607\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.0960 - acc: 0.9944 - f1_m: 0.9803 - precision_m: 0.9813 - recall_m: 0.9799\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.0929 - acc: 0.9949 - f1_m: 0.9809 - precision_m: 0.9829 - recall_m: 0.9793\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.1267 - acc: 0.9923 - f1_m: 0.9706 - precision_m: 0.9831 - recall_m: 0.9597\n",
      "Epoch 40/500\n",
      " - 1s - loss: 0.0957 - acc: 0.9937 - f1_m: 0.9758 - precision_m: 0.9769 - recall_m: 0.9758\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.1072 - acc: 0.9925 - f1_m: 0.9723 - precision_m: 0.9679 - recall_m: 0.9782\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.1075 - acc: 0.9928 - f1_m: 0.9735 - precision_m: 0.9724 - recall_m: 0.9756\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.1140 - acc: 0.9928 - f1_m: 0.9743 - precision_m: 0.9751 - recall_m: 0.9749\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.1045 - acc: 0.9925 - f1_m: 0.9736 - precision_m: 0.9805 - recall_m: 0.9681\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.1014 - acc: 0.9925 - f1_m: 0.9723 - precision_m: 0.9833 - recall_m: 0.9626\n",
      "Epoch 46/500\n",
      " - 1s - loss: 0.0859 - acc: 0.9937 - f1_m: 0.9765 - precision_m: 0.9771 - recall_m: 0.9763\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.0875 - acc: 0.9925 - f1_m: 0.9725 - precision_m: 0.9746 - recall_m: 0.9714\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.0794 - acc: 0.9954 - f1_m: 0.9849 - precision_m: 0.9870 - recall_m: 0.9836\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.1014 - acc: 0.9928 - f1_m: 0.9759 - precision_m: 0.9769 - recall_m: 0.9750\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.0581 - acc: 0.9969 - f1_m: 0.9882 - precision_m: 0.9930 - recall_m: 0.9836\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.0846 - acc: 0.9940 - f1_m: 0.9808 - precision_m: 0.9804 - recall_m: 0.9815\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.0689 - acc: 0.9952 - f1_m: 0.9837 - precision_m: 0.9880 - recall_m: 0.9799\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.0771 - acc: 0.9947 - f1_m: 0.9803 - precision_m: 0.9843 - recall_m: 0.9773\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.0742 - acc: 0.9947 - f1_m: 0.9797 - precision_m: 0.9870 - recall_m: 0.9729\n",
      "Epoch 55/500\n",
      " - 1s - loss: 0.0617 - acc: 0.9959 - f1_m: 0.9859 - precision_m: 0.9909 - recall_m: 0.9811\n",
      "Epoch 56/500\n",
      " - 1s - loss: 0.0860 - acc: 0.9949 - f1_m: 0.9828 - precision_m: 0.9876 - recall_m: 0.9784\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.0713 - acc: 0.9952 - f1_m: 0.9808 - precision_m: 0.9811 - recall_m: 0.9811\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.0626 - acc: 0.9964 - f1_m: 0.9872 - precision_m: 0.9859 - recall_m: 0.9892\n",
      "Epoch 59/500\n",
      " - 1s - loss: 0.0540 - acc: 0.9969 - f1_m: 0.9896 - precision_m: 0.9921 - recall_m: 0.9876\n",
      "Epoch 60/500\n",
      " - 1s - loss: 0.0819 - acc: 0.9942 - f1_m: 0.9781 - precision_m: 0.9845 - recall_m: 0.9726\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.1006 - acc: 0.9935 - f1_m: 0.9768 - precision_m: 0.9757 - recall_m: 0.9789\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.0827 - acc: 0.9937 - f1_m: 0.9788 - precision_m: 0.9736 - recall_m: 0.9846\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.0843 - acc: 0.9947 - f1_m: 0.9813 - precision_m: 0.9831 - recall_m: 0.9805\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.0740 - acc: 0.9959 - f1_m: 0.9861 - precision_m: 0.9898 - recall_m: 0.9830\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.0727 - acc: 0.9952 - f1_m: 0.9816 - precision_m: 0.9759 - recall_m: 0.9883\n",
      "Epoch 66/500\n",
      " - 1s - loss: 0.0656 - acc: 0.9957 - f1_m: 0.9835 - precision_m: 0.9885 - recall_m: 0.9794\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.0747 - acc: 0.9959 - f1_m: 0.9848 - precision_m: 0.9881 - recall_m: 0.9820\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.0548 - acc: 0.9964 - f1_m: 0.9872 - precision_m: 0.9854 - recall_m: 0.9894\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.0666 - acc: 0.9969 - f1_m: 0.9900 - precision_m: 0.9875 - recall_m: 0.9927\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.0599 - acc: 0.9952 - f1_m: 0.9835 - precision_m: 0.9914 - recall_m: 0.9761\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.0652 - acc: 0.9961 - f1_m: 0.9871 - precision_m: 0.9952 - recall_m: 0.9793\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.0921 - acc: 0.9937 - f1_m: 0.9738 - precision_m: 0.9722 - recall_m: 0.9761\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.0843 - acc: 0.9957 - f1_m: 0.9851 - precision_m: 0.9861 - recall_m: 0.9845\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.0535 - acc: 0.9964 - f1_m: 0.9878 - precision_m: 0.9911 - recall_m: 0.9848\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.0645 - acc: 0.9969 - f1_m: 0.9899 - precision_m: 0.9940 - recall_m: 0.9860\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.0558 - acc: 0.9969 - f1_m: 0.9899 - precision_m: 0.9936 - recall_m: 0.9864\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.0456 - acc: 0.9971 - f1_m: 0.9903 - precision_m: 0.9933 - recall_m: 0.9878\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.0924 - acc: 0.9930 - f1_m: 0.9745 - precision_m: 0.9769 - recall_m: 0.9732\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.0689 - acc: 0.9961 - f1_m: 0.9852 - precision_m: 0.9779 - recall_m: 0.9932\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.0638 - acc: 0.9961 - f1_m: 0.9842 - precision_m: 0.9979 - recall_m: 0.9716\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.0528 - acc: 0.9952 - f1_m: 0.9819 - precision_m: 0.9867 - recall_m: 0.9781\n",
      "Epoch 82/500\n",
      " - 1s - loss: 0.0761 - acc: 0.9954 - f1_m: 0.9836 - precision_m: 0.9816 - recall_m: 0.9862\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.0376 - acc: 0.9978 - f1_m: 0.9908 - precision_m: 0.9948 - recall_m: 0.9872\n",
      "Epoch 84/500\n",
      " - 1s - loss: 0.0656 - acc: 0.9952 - f1_m: 0.9837 - precision_m: 0.9863 - recall_m: 0.9816\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.0480 - acc: 0.9964 - f1_m: 0.9863 - precision_m: 0.9905 - recall_m: 0.9827\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.0449 - acc: 0.9966 - f1_m: 0.9885 - precision_m: 0.9820 - recall_m: 0.9954\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.0640 - acc: 0.9954 - f1_m: 0.9803 - precision_m: 0.9779 - recall_m: 0.9835\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.0386 - acc: 0.9981 - f1_m: 0.9921 - precision_m: 0.9924 - recall_m: 0.9922\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.0624 - acc: 0.9961 - f1_m: 0.9863 - precision_m: 0.9916 - recall_m: 0.9814\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.0387 - acc: 0.9973 - f1_m: 0.9908 - precision_m: 0.9923 - recall_m: 0.9896\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.0477 - acc: 0.9969 - f1_m: 0.9908 - precision_m: 0.9911 - recall_m: 0.9909\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.0427 - acc: 0.9978 - f1_m: 0.9917 - precision_m: 0.9915 - recall_m: 0.9922\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.0361 - acc: 0.9973 - f1_m: 0.9903 - precision_m: 0.9910 - recall_m: 0.9898\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.0370 - acc: 0.9973 - f1_m: 0.9907 - precision_m: 0.9933 - recall_m: 0.9885\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.0344 - acc: 0.9971 - f1_m: 0.9893 - precision_m: 0.9915 - recall_m: 0.9875\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.0259 - acc: 0.9983 - f1_m: 0.9937 - precision_m: 0.9933 - recall_m: 0.9944\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.0425 - acc: 0.9966 - f1_m: 0.9881 - precision_m: 0.9904 - recall_m: 0.9861\n",
      "Epoch 98/500\n",
      " - 1s - loss: 0.0242 - acc: 0.9981 - f1_m: 0.9934 - precision_m: 0.9946 - recall_m: 0.9923\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.0360 - acc: 0.9978 - f1_m: 0.9910 - precision_m: 0.9936 - recall_m: 0.9885\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.0361 - acc: 0.9971 - f1_m: 0.9891 - precision_m: 0.9904 - recall_m: 0.9880\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.0311 - acc: 0.9981 - f1_m: 0.9932 - precision_m: 0.9921 - recall_m: 0.9944\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.0220 - acc: 0.9990 - f1_m: 0.9968 - precision_m: 0.9950 - recall_m: 0.9986\n",
      "Epoch 103/500\n",
      " - 1s - loss: 0.0265 - acc: 0.9983 - f1_m: 0.9934 - precision_m: 0.9922 - recall_m: 0.9948\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.0226 - acc: 0.9981 - f1_m: 0.9932 - precision_m: 0.9942 - recall_m: 0.9922\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.0199 - acc: 0.9990 - f1_m: 0.9971 - precision_m: 0.9956 - recall_m: 0.9986\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.0509 - acc: 0.9969 - f1_m: 0.9886 - precision_m: 0.9952 - recall_m: 0.9826\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.0406 - acc: 0.9976 - f1_m: 0.9901 - precision_m: 0.9911 - recall_m: 0.9895\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.0406 - acc: 0.9973 - f1_m: 0.9914 - precision_m: 0.9929 - recall_m: 0.9903\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.0357 - acc: 0.9978 - f1_m: 0.9922 - precision_m: 0.9916 - recall_m: 0.9929\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.0301 - acc: 0.9976 - f1_m: 0.9911 - precision_m: 0.9867 - recall_m: 0.9958\n",
      "Epoch 111/500\n",
      " - 1s - loss: 0.0263 - acc: 0.9988 - f1_m: 0.9962 - precision_m: 0.9966 - recall_m: 0.9960\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.0357 - acc: 0.9983 - f1_m: 0.9941 - precision_m: 0.9958 - recall_m: 0.9925\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.0311 - acc: 0.9988 - f1_m: 0.9955 - precision_m: 0.9939 - recall_m: 0.9971\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.0372 - acc: 0.9969 - f1_m: 0.9890 - precision_m: 0.9949 - recall_m: 0.9833\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.0269 - acc: 0.9983 - f1_m: 0.9951 - precision_m: 0.9944 - recall_m: 0.9959\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.0510 - acc: 0.9964 - f1_m: 0.9868 - precision_m: 0.9812 - recall_m: 0.9930\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.0324 - acc: 0.9978 - f1_m: 0.9916 - precision_m: 0.9952 - recall_m: 0.9883\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.0425 - acc: 0.9969 - f1_m: 0.9883 - precision_m: 0.9884 - recall_m: 0.9884\n",
      "Epoch 119/500\n",
      " - 1s - loss: 0.0331 - acc: 0.9981 - f1_m: 0.9919 - precision_m: 0.9921 - recall_m: 0.9922\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.0233 - acc: 0.9983 - f1_m: 0.9929 - precision_m: 0.9914 - recall_m: 0.9948\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.0320 - acc: 0.9978 - f1_m: 0.9932 - precision_m: 0.9971 - recall_m: 0.9895\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.0197 - acc: 0.9988 - f1_m: 0.9965 - precision_m: 0.9976 - recall_m: 0.9955\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.0382 - acc: 0.9969 - f1_m: 0.9879 - precision_m: 0.9930 - recall_m: 0.9831\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.0298 - acc: 0.9981 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9934\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.0319 - acc: 0.9973 - f1_m: 0.9896 - precision_m: 0.9948 - recall_m: 0.9847\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.0438 - acc: 0.9966 - f1_m: 0.9879 - precision_m: 0.9854 - recall_m: 0.9907\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.0253 - acc: 0.9981 - f1_m: 0.9944 - precision_m: 0.9934 - recall_m: 0.9956\n",
      "Epoch 128/500\n",
      " - 1s - loss: 0.0431 - acc: 0.9976 - f1_m: 0.9910 - precision_m: 0.9883 - recall_m: 0.9939\n",
      "Epoch 129/500\n",
      " - 1s - loss: 0.0294 - acc: 0.9986 - f1_m: 0.9949 - precision_m: 0.9928 - recall_m: 0.9970\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.0246 - acc: 0.9983 - f1_m: 0.9931 - precision_m: 0.9944 - recall_m: 0.9920\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.0356 - acc: 0.9976 - f1_m: 0.9914 - precision_m: 0.9946 - recall_m: 0.9884\n",
      "Epoch 132/500\n",
      " - 1s - loss: 0.0177 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9941 - recall_m: 0.9983\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.0134 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 1.0000 - recall_m: 0.9970\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.0415 - acc: 0.9969 - f1_m: 0.9877 - precision_m: 0.9918 - recall_m: 0.9840\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.0331 - acc: 0.9976 - f1_m: 0.9908 - precision_m: 0.9893 - recall_m: 0.9927\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.0476 - acc: 0.9971 - f1_m: 0.9879 - precision_m: 0.9937 - recall_m: 0.9828\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.0261 - acc: 0.9988 - f1_m: 0.9954 - precision_m: 0.9937 - recall_m: 0.9972\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.0272 - acc: 0.9983 - f1_m: 0.9943 - precision_m: 0.9936 - recall_m: 0.9950\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.0165 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9982 - recall_m: 0.9942\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.0210 - acc: 0.9986 - f1_m: 0.9946 - precision_m: 0.9955 - recall_m: 0.9939\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.0163 - acc: 0.9986 - f1_m: 0.9946 - precision_m: 0.9940 - recall_m: 0.9953\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.0290 - acc: 0.9978 - f1_m: 0.9919 - precision_m: 0.9929 - recall_m: 0.9910\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.0429 - acc: 0.9978 - f1_m: 0.9929 - precision_m: 0.9976 - recall_m: 0.9885\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.0303 - acc: 0.9978 - f1_m: 0.9920 - precision_m: 0.9870 - recall_m: 0.9972\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.0265 - acc: 0.9983 - f1_m: 0.9932 - precision_m: 0.9964 - recall_m: 0.9901\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.0315 - acc: 0.9976 - f1_m: 0.9909 - precision_m: 0.9920 - recall_m: 0.9900\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.0278 - acc: 0.9971 - f1_m: 0.9887 - precision_m: 0.9934 - recall_m: 0.9844\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.0130 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.0168 - acc: 0.9990 - f1_m: 0.9966 - precision_m: 0.9978 - recall_m: 0.9956\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.0203 - acc: 0.9986 - f1_m: 0.9943 - precision_m: 0.9925 - recall_m: 0.9962\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.0338 - acc: 0.9973 - f1_m: 0.9925 - precision_m: 0.9947 - recall_m: 0.9904\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.0312 - acc: 0.9971 - f1_m: 0.9905 - precision_m: 0.9911 - recall_m: 0.9903\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.0233 - acc: 0.9978 - f1_m: 0.9922 - precision_m: 0.9937 - recall_m: 0.9907\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.0487 - acc: 0.9976 - f1_m: 0.9907 - precision_m: 0.9939 - recall_m: 0.9880\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.0410 - acc: 0.9971 - f1_m: 0.9888 - precision_m: 0.9881 - recall_m: 0.9897\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.0459 - acc: 0.9973 - f1_m: 0.9903 - precision_m: 0.9857 - recall_m: 0.9952\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.0428 - acc: 0.9966 - f1_m: 0.9881 - precision_m: 0.9896 - recall_m: 0.9870\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.0231 - acc: 0.9986 - f1_m: 0.9943 - precision_m: 0.9945 - recall_m: 0.9942\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.0181 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9971 - recall_m: 0.9966\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.0336 - acc: 0.9981 - f1_m: 0.9931 - precision_m: 0.9954 - recall_m: 0.9909\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.0348 - acc: 0.9981 - f1_m: 0.9926 - precision_m: 0.9944 - recall_m: 0.9910\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.0416 - acc: 0.9976 - f1_m: 0.9905 - precision_m: 0.9906 - recall_m: 0.9909\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.0288 - acc: 0.9986 - f1_m: 0.9953 - precision_m: 0.9983 - recall_m: 0.9927\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.0465 - acc: 0.9976 - f1_m: 0.9882 - precision_m: 0.9813 - recall_m: 0.9954\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.0827 - acc: 0.9952 - f1_m: 0.9843 - precision_m: 0.9827 - recall_m: 0.9871\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.0936 - acc: 0.9930 - f1_m: 0.9728 - precision_m: 0.9848 - recall_m: 0.9639\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.0551 - acc: 0.9966 - f1_m: 0.9899 - precision_m: 0.9929 - recall_m: 0.9871\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.0654 - acc: 0.9964 - f1_m: 0.9876 - precision_m: 0.9851 - recall_m: 0.9906\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.0352 - acc: 0.9973 - f1_m: 0.9913 - precision_m: 0.9876 - recall_m: 0.9953\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.0520 - acc: 0.9969 - f1_m: 0.9884 - precision_m: 0.9893 - recall_m: 0.9880\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.0373 - acc: 0.9978 - f1_m: 0.9918 - precision_m: 0.9958 - recall_m: 0.9880\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.0642 - acc: 0.9964 - f1_m: 0.9878 - precision_m: 0.9873 - recall_m: 0.9886\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.0395 - acc: 0.9973 - f1_m: 0.9912 - precision_m: 0.9956 - recall_m: 0.9870\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.0496 - acc: 0.9969 - f1_m: 0.9890 - precision_m: 0.9870 - recall_m: 0.9913\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.0251 - acc: 0.9988 - f1_m: 0.9951 - precision_m: 0.9966 - recall_m: 0.9938\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.0235 - acc: 0.9988 - f1_m: 0.9960 - precision_m: 0.9920 - recall_m: 1.0000\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.0425 - acc: 0.9973 - f1_m: 0.9910 - precision_m: 0.9933 - recall_m: 0.9890\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.0255 - acc: 0.9981 - f1_m: 0.9913 - precision_m: 0.9896 - recall_m: 0.9931\n",
      "Epoch 179/500\n",
      " - 1s - loss: 0.0280 - acc: 0.9983 - f1_m: 0.9937 - precision_m: 0.9960 - recall_m: 0.9918\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.0268 - acc: 0.9986 - f1_m: 0.9941 - precision_m: 0.9963 - recall_m: 0.9921\n",
      "Epoch 181/500\n",
      " - 1s - loss: 0.0159 - acc: 0.9990 - f1_m: 0.9964 - precision_m: 0.9968 - recall_m: 0.9961\n",
      "Epoch 182/500\n",
      " - 1s - loss: 0.0349 - acc: 0.9978 - f1_m: 0.9911 - precision_m: 0.9904 - recall_m: 0.9920\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.0343 - acc: 0.9983 - f1_m: 0.9941 - precision_m: 0.9940 - recall_m: 0.9942\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.0341 - acc: 0.9981 - f1_m: 0.9927 - precision_m: 0.9947 - recall_m: 0.9910\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.0180 - acc: 0.9986 - f1_m: 0.9946 - precision_m: 0.9918 - recall_m: 0.9977\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.0222 - acc: 0.9983 - f1_m: 0.9940 - precision_m: 0.9927 - recall_m: 0.9956\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.0262 - acc: 0.9983 - f1_m: 0.9932 - precision_m: 1.0000 - recall_m: 0.9866\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.0249 - acc: 0.9986 - f1_m: 0.9936 - precision_m: 0.9894 - recall_m: 0.9981\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.0115 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 1.0000 - recall_m: 0.9985\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.0280 - acc: 0.9981 - f1_m: 0.9936 - precision_m: 0.9933 - recall_m: 0.9941\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.0420 - acc: 0.9983 - f1_m: 0.9919 - precision_m: 0.9928 - recall_m: 0.9910\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.0171 - acc: 0.9990 - f1_m: 0.9960 - precision_m: 0.9976 - recall_m: 0.9945\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.0370 - acc: 0.9976 - f1_m: 0.9914 - precision_m: 0.9899 - recall_m: 0.9929\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.0366 - acc: 0.9971 - f1_m: 0.9891 - precision_m: 0.9927 - recall_m: 0.9856\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.0579 - acc: 0.9966 - f1_m: 0.9886 - precision_m: 0.9891 - recall_m: 0.9882\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.0451 - acc: 0.9971 - f1_m: 0.9888 - precision_m: 0.9894 - recall_m: 0.9886\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.0392 - acc: 0.9971 - f1_m: 0.9902 - precision_m: 0.9942 - recall_m: 0.9864\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.0202 - acc: 0.9983 - f1_m: 0.9938 - precision_m: 0.9967 - recall_m: 0.9910\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.0206 - acc: 0.9983 - f1_m: 0.9948 - precision_m: 0.9947 - recall_m: 0.9949\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.0223 - acc: 0.9986 - f1_m: 0.9948 - precision_m: 0.9936 - recall_m: 0.9961\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.0263 - acc: 0.9983 - f1_m: 0.9943 - precision_m: 0.9969 - recall_m: 0.9918\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.0366 - acc: 0.9981 - f1_m: 0.9920 - precision_m: 0.9929 - recall_m: 0.9912\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.0255 - acc: 0.9990 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9959\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.0357 - acc: 0.9976 - f1_m: 0.9915 - precision_m: 0.9925 - recall_m: 0.9908\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.0186 - acc: 0.9983 - f1_m: 0.9933 - precision_m: 0.9938 - recall_m: 0.9931\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.0674 - acc: 0.9966 - f1_m: 0.9884 - precision_m: 0.9863 - recall_m: 0.9908\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.0393 - acc: 0.9973 - f1_m: 0.9905 - precision_m: 0.9880 - recall_m: 0.9935\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.0494 - acc: 0.9976 - f1_m: 0.9914 - precision_m: 0.9918 - recall_m: 0.9912\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.0221 - acc: 0.9986 - f1_m: 0.9954 - precision_m: 0.9956 - recall_m: 0.9953\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.0514 - acc: 0.9981 - f1_m: 0.9929 - precision_m: 0.9920 - recall_m: 0.9941\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.0470 - acc: 0.9971 - f1_m: 0.9902 - precision_m: 0.9917 - recall_m: 0.9890\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.0617 - acc: 0.9959 - f1_m: 0.9847 - precision_m: 0.9929 - recall_m: 0.9773\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.0598 - acc: 0.9964 - f1_m: 0.9856 - precision_m: 0.9769 - recall_m: 0.9950\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.1308 - acc: 0.9964 - f1_m: 0.9856 - precision_m: 0.9907 - recall_m: 0.9811\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.0891 - acc: 0.9935 - f1_m: 0.9748 - precision_m: 0.9696 - recall_m: 0.9820\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.0429 - acc: 0.9966 - f1_m: 0.9877 - precision_m: 0.9918 - recall_m: 0.9844\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.0481 - acc: 0.9978 - f1_m: 0.9902 - precision_m: 0.9831 - recall_m: 0.9978\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.0432 - acc: 0.9973 - f1_m: 0.9906 - precision_m: 0.9920 - recall_m: 0.9893\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.0398 - acc: 0.9973 - f1_m: 0.9910 - precision_m: 0.9893 - recall_m: 0.9929\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.0245 - acc: 0.9988 - f1_m: 0.9952 - precision_m: 0.9918 - recall_m: 0.9987\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.0310 - acc: 0.9969 - f1_m: 0.9882 - precision_m: 0.9933 - recall_m: 0.9835\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.0209 - acc: 0.9978 - f1_m: 0.9918 - precision_m: 0.9938 - recall_m: 0.9900\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.0198 - acc: 0.9981 - f1_m: 0.9930 - precision_m: 0.9921 - recall_m: 0.9941\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.0133 - acc: 0.9988 - f1_m: 0.9960 - precision_m: 0.9984 - recall_m: 0.9936\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.0160 - acc: 0.9988 - f1_m: 0.9967 - precision_m: 0.9972 - recall_m: 0.9962\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.0168 - acc: 0.9995 - f1_m: 0.9982 - precision_m: 0.9982 - recall_m: 0.9982\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.0094 - acc: 0.9990 - f1_m: 0.9960 - precision_m: 0.9920 - recall_m: 1.0000\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.0184 - acc: 0.9988 - f1_m: 0.9968 - precision_m: 0.9989 - recall_m: 0.9947\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.0165 - acc: 0.9986 - f1_m: 0.9962 - precision_m: 0.9950 - recall_m: 0.9974\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.0120 - acc: 0.9990 - f1_m: 0.9968 - precision_m: 0.9973 - recall_m: 0.9963\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.0259 - acc: 0.9983 - f1_m: 0.9940 - precision_m: 0.9972 - recall_m: 0.9909\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.0194 - acc: 0.9990 - f1_m: 0.9965 - precision_m: 0.9949 - recall_m: 0.9981\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.0147 - acc: 0.9988 - f1_m: 0.9943 - precision_m: 0.9923 - recall_m: 0.9966\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.0432 - acc: 0.9969 - f1_m: 0.9907 - precision_m: 0.9875 - recall_m: 0.9943\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.0213 - acc: 0.9983 - f1_m: 0.9938 - precision_m: 0.9963 - recall_m: 0.9914\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.0287 - acc: 0.9978 - f1_m: 0.9931 - precision_m: 0.9963 - recall_m: 0.9901\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.0311 - acc: 0.9981 - f1_m: 0.9932 - precision_m: 0.9953 - recall_m: 0.9913\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.0280 - acc: 0.9978 - f1_m: 0.9936 - precision_m: 0.9943 - recall_m: 0.9928\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.0170 - acc: 0.9988 - f1_m: 0.9946 - precision_m: 0.9951 - recall_m: 0.9943\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.0161 - acc: 0.9995 - f1_m: 0.9982 - precision_m: 1.0000 - recall_m: 0.9964\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.0065 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 1.0000 - recall_m: 0.9987\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.0124 - acc: 0.9988 - f1_m: 0.9958 - precision_m: 0.9951 - recall_m: 0.9967\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.0128 - acc: 0.9988 - f1_m: 0.9950 - precision_m: 0.9938 - recall_m: 0.9963\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.0190 - acc: 0.9990 - f1_m: 0.9961 - precision_m: 0.9938 - recall_m: 0.9986\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.0085 - acc: 0.9995 - f1_m: 0.9983 - precision_m: 0.9967 - recall_m: 1.0000\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.0340 - acc: 0.9983 - f1_m: 0.9931 - precision_m: 0.9962 - recall_m: 0.9900\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.0068 - acc: 0.9995 - f1_m: 0.9986 - precision_m: 0.9973 - recall_m: 1.0000\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.0252 - acc: 0.9988 - f1_m: 0.9959 - precision_m: 0.9969 - recall_m: 0.9949\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.0226 - acc: 0.9983 - f1_m: 0.9953 - precision_m: 0.9963 - recall_m: 0.9943\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.0247 - acc: 0.9986 - f1_m: 0.9951 - precision_m: 0.9932 - recall_m: 0.9972\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.0381 - acc: 0.9973 - f1_m: 0.9873 - precision_m: 0.9910 - recall_m: 0.9842\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.0143 - acc: 0.9990 - f1_m: 0.9968 - precision_m: 0.9937 - recall_m: 1.0000\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.0484 - acc: 0.9969 - f1_m: 0.9887 - precision_m: 0.9931 - recall_m: 0.9848\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.0510 - acc: 0.9966 - f1_m: 0.9875 - precision_m: 0.9872 - recall_m: 0.9881\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.0388 - acc: 0.9976 - f1_m: 0.9926 - precision_m: 0.9965 - recall_m: 0.9889\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.0107 - acc: 0.9990 - f1_m: 0.9965 - precision_m: 0.9949 - recall_m: 0.9981\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.0437 - acc: 0.9983 - f1_m: 0.9945 - precision_m: 0.9967 - recall_m: 0.9925\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.0392 - acc: 0.9986 - f1_m: 0.9942 - precision_m: 0.9945 - recall_m: 0.9940\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.0313 - acc: 0.9973 - f1_m: 0.9901 - precision_m: 0.9901 - recall_m: 0.9904\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.0337 - acc: 0.9978 - f1_m: 0.9912 - precision_m: 0.9854 - recall_m: 0.9973\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.0580 - acc: 0.9973 - f1_m: 0.9913 - precision_m: 0.9908 - recall_m: 0.9921\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.0545 - acc: 0.9973 - f1_m: 0.9903 - precision_m: 0.9861 - recall_m: 0.9949\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.0651 - acc: 0.9969 - f1_m: 0.9883 - precision_m: 0.9854 - recall_m: 0.9916\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.0712 - acc: 0.9964 - f1_m: 0.9866 - precision_m: 0.9901 - recall_m: 0.9838\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.0221 - acc: 0.9983 - f1_m: 0.9946 - precision_m: 0.9925 - recall_m: 0.9969\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.0597 - acc: 0.9978 - f1_m: 0.9920 - precision_m: 0.9937 - recall_m: 0.9906\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.0460 - acc: 0.9971 - f1_m: 0.9859 - precision_m: 0.9963 - recall_m: 0.9764\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.0782 - acc: 0.9959 - f1_m: 0.9849 - precision_m: 0.9822 - recall_m: 0.9882\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.0656 - acc: 0.9949 - f1_m: 0.9818 - precision_m: 0.9792 - recall_m: 0.9848\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.0886 - acc: 0.9952 - f1_m: 0.9815 - precision_m: 0.9836 - recall_m: 0.9807\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.0370 - acc: 0.9978 - f1_m: 0.9925 - precision_m: 0.9906 - recall_m: 0.9946\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.0146 - acc: 0.9988 - f1_m: 0.9952 - precision_m: 0.9986 - recall_m: 0.9921\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.0298 - acc: 0.9988 - f1_m: 0.9953 - precision_m: 0.9961 - recall_m: 0.9946\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.0358 - acc: 0.9978 - f1_m: 0.9922 - precision_m: 0.9910 - recall_m: 0.9937\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.0404 - acc: 0.9978 - f1_m: 0.9923 - precision_m: 0.9901 - recall_m: 0.9947\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.0239 - acc: 0.9978 - f1_m: 0.9908 - precision_m: 0.9900 - recall_m: 0.9920\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.0324 - acc: 0.9976 - f1_m: 0.9909 - precision_m: 0.9946 - recall_m: 0.9876\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.0278 - acc: 0.9986 - f1_m: 0.9943 - precision_m: 0.9900 - recall_m: 0.9988\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.0255 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9987 - recall_m: 0.9983\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.0471 - acc: 0.9983 - f1_m: 0.9936 - precision_m: 0.9949 - recall_m: 0.9924\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.0180 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9970\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.0224 - acc: 0.9990 - f1_m: 0.9963 - precision_m: 0.9948 - recall_m: 0.9978\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.0197 - acc: 0.9990 - f1_m: 0.9954 - precision_m: 0.9927 - recall_m: 0.9983\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.0195 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9985 - recall_m: 0.9938\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.0072 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9982 - recall_m: 0.9988\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.0142 - acc: 0.9993 - f1_m: 0.9971 - precision_m: 0.9959 - recall_m: 0.9985\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.0228 - acc: 0.9981 - f1_m: 0.9933 - precision_m: 1.0000 - recall_m: 0.9868\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.0192 - acc: 0.9988 - f1_m: 0.9953 - precision_m: 0.9966 - recall_m: 0.9940\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.0127 - acc: 0.9993 - f1_m: 0.9975 - precision_m: 0.9950 - recall_m: 1.0000\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.0098 - acc: 0.9995 - f1_m: 0.9980 - precision_m: 0.9980 - recall_m: 0.9981\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.0309 - acc: 0.9978 - f1_m: 0.9914 - precision_m: 0.9910 - recall_m: 0.9919\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.0327 - acc: 0.9976 - f1_m: 0.9906 - precision_m: 0.9885 - recall_m: 0.9932\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.0626 - acc: 0.9973 - f1_m: 0.9892 - precision_m: 0.9927 - recall_m: 0.9861\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.0478 - acc: 0.9969 - f1_m: 0.9889 - precision_m: 0.9865 - recall_m: 0.9916\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.0341 - acc: 0.9973 - f1_m: 0.9904 - precision_m: 0.9920 - recall_m: 0.9892\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.0131 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9985 - recall_m: 0.9967\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.0187 - acc: 0.9988 - f1_m: 0.9946 - precision_m: 0.9961 - recall_m: 0.9933\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.0311 - acc: 0.9986 - f1_m: 0.9951 - precision_m: 0.9969 - recall_m: 0.9934\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.0059 - acc: 0.9998 - f1_m: 0.9985 - precision_m: 1.0000 - recall_m: 0.9971\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0066 - acc: 0.9995 - f1_m: 0.9983 - precision_m: 0.9966 - recall_m: 1.0000\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0214 - acc: 0.9983 - f1_m: 0.9941 - precision_m: 0.9945 - recall_m: 0.9937\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0130 - acc: 0.9993 - f1_m: 0.9974 - precision_m: 0.9981 - recall_m: 0.9968\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0109 - acc: 0.9990 - f1_m: 0.9966 - precision_m: 0.9965 - recall_m: 0.9968\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0057 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9985 - recall_m: 0.9986\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0076 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9986 - recall_m: 0.9984\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0132 - acc: 0.9990 - f1_m: 0.9963 - precision_m: 0.9962 - recall_m: 0.9966\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0145 - acc: 0.9990 - f1_m: 0.9965 - precision_m: 0.9965 - recall_m: 0.9966\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0079 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9972 - recall_m: 0.9970\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0148 - acc: 0.9988 - f1_m: 0.9948 - precision_m: 0.9951 - recall_m: 0.9946\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0112 - acc: 0.9993 - f1_m: 0.9968 - precision_m: 0.9952 - recall_m: 0.9986\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0249 - acc: 0.9983 - f1_m: 0.9940 - precision_m: 0.9963 - recall_m: 0.9919\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0276 - acc: 0.9983 - f1_m: 0.9941 - precision_m: 0.9985 - recall_m: 0.9899\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0305 - acc: 0.9986 - f1_m: 0.9956 - precision_m: 0.9942 - recall_m: 0.9971\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0161 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9964 - recall_m: 0.9988\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0135 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9954 - recall_m: 1.0000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0127 - acc: 0.9993 - f1_m: 0.9972 - precision_m: 0.9982 - recall_m: 0.9962\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0202 - acc: 0.9988 - f1_m: 0.9939 - precision_m: 0.9956 - recall_m: 0.9925\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0276 - acc: 0.9988 - f1_m: 0.9962 - precision_m: 0.9958 - recall_m: 0.9965\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0299 - acc: 0.9986 - f1_m: 0.9959 - precision_m: 0.9961 - recall_m: 0.9958\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0082 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9988 - recall_m: 0.9982\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0225 - acc: 0.9986 - f1_m: 0.9947 - precision_m: 0.9967 - recall_m: 0.9929\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0209 - acc: 0.9986 - f1_m: 0.9952 - precision_m: 0.9963 - recall_m: 0.9942\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0120 - acc: 0.9993 - f1_m: 0.9969 - precision_m: 1.0000 - recall_m: 0.9939\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0100 - acc: 0.9990 - f1_m: 0.9958 - precision_m: 0.9919 - recall_m: 1.0000\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0141 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9940 - recall_m: 1.0000\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0065 - acc: 0.9998 - f1_m: 0.9991 - precision_m: 0.9983 - recall_m: 1.0000\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0164 - acc: 0.9990 - f1_m: 0.9959 - precision_m: 0.9985 - recall_m: 0.9935\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0434 - acc: 0.9981 - f1_m: 0.9935 - precision_m: 0.9940 - recall_m: 0.9931\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0311 - acc: 0.9966 - f1_m: 0.9892 - precision_m: 0.9947 - recall_m: 0.9842\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0476 - acc: 0.9973 - f1_m: 0.9907 - precision_m: 0.9947 - recall_m: 0.9869\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0093 - acc: 0.9995 - f1_m: 0.9984 - precision_m: 0.9981 - recall_m: 0.9987\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0310 - acc: 0.9988 - f1_m: 0.9951 - precision_m: 0.9973 - recall_m: 0.9932\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0315 - acc: 0.9983 - f1_m: 0.9944 - precision_m: 0.9924 - recall_m: 0.9966\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0141 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9952 - recall_m: 0.9989\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0126 - acc: 0.9990 - f1_m: 0.9961 - precision_m: 0.9978 - recall_m: 0.9946\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.0191 - acc: 0.9983 - f1_m: 0.9939 - precision_m: 0.9909 - recall_m: 0.9972\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0161 - acc: 0.9986 - f1_m: 0.9950 - precision_m: 0.9952 - recall_m: 0.9949\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.0146 - acc: 0.9995 - f1_m: 0.9980 - precision_m: 0.9987 - recall_m: 0.9973\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.0129 - acc: 0.9990 - f1_m: 0.9967 - precision_m: 0.9947 - recall_m: 0.9988\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0389 - acc: 0.9983 - f1_m: 0.9949 - precision_m: 0.9987 - recall_m: 0.9912\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0209 - acc: 0.9986 - f1_m: 0.9948 - precision_m: 0.9916 - recall_m: 0.9982\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0244 - acc: 0.9981 - f1_m: 0.9938 - precision_m: 0.9911 - recall_m: 0.9966\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0092 - acc: 0.9988 - f1_m: 0.9954 - precision_m: 0.9983 - recall_m: 0.9926\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0306 - acc: 0.9988 - f1_m: 0.9948 - precision_m: 1.0000 - recall_m: 0.9898\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.0439 - acc: 0.9969 - f1_m: 0.9886 - precision_m: 0.9914 - recall_m: 0.9863\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0113 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9969 - recall_m: 0.9971\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0126 - acc: 0.9988 - f1_m: 0.9962 - precision_m: 0.9964 - recall_m: 0.9961\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0113 - acc: 0.9993 - f1_m: 0.9975 - precision_m: 0.9983 - recall_m: 0.9968\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0205 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9963 - recall_m: 0.9976\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0130 - acc: 0.9990 - f1_m: 0.9963 - precision_m: 0.9945 - recall_m: 0.9981\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0398 - acc: 0.9978 - f1_m: 0.9896 - precision_m: 0.9978 - recall_m: 0.9822\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0193 - acc: 0.9988 - f1_m: 0.9950 - precision_m: 0.9901 - recall_m: 1.0000\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0242 - acc: 0.9983 - f1_m: 0.9944 - precision_m: 0.9957 - recall_m: 0.9932\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0255 - acc: 0.9988 - f1_m: 0.9949 - precision_m: 0.9914 - recall_m: 0.9987\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0141 - acc: 0.9986 - f1_m: 0.9952 - precision_m: 0.9985 - recall_m: 0.9921\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0136 - acc: 0.9995 - f1_m: 0.9982 - precision_m: 1.0000 - recall_m: 0.9964\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0210 - acc: 0.9986 - f1_m: 0.9948 - precision_m: 0.9927 - recall_m: 0.9970\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0212 - acc: 0.9993 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9951\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0160 - acc: 0.9988 - f1_m: 0.9965 - precision_m: 0.9948 - recall_m: 0.9984\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0149 - acc: 0.9990 - f1_m: 0.9962 - precision_m: 0.9954 - recall_m: 0.9972\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0276 - acc: 0.9981 - f1_m: 0.9941 - precision_m: 0.9954 - recall_m: 0.9929\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0052 - acc: 0.9998 - f1_m: 0.9990 - precision_m: 0.9981 - recall_m: 1.0000\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0134 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 1.0000 - recall_m: 0.9971\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0295 - acc: 0.9993 - f1_m: 0.9979 - precision_m: 0.9973 - recall_m: 0.9985\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0038 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 1.0000 - recall_m: 0.9986\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0082 - acc: 0.9995 - f1_m: 0.9971 - precision_m: 0.9943 - recall_m: 1.0000\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0380 - acc: 0.9978 - f1_m: 0.9925 - precision_m: 0.9906 - recall_m: 0.9947\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0300 - acc: 0.9990 - f1_m: 0.9964 - precision_m: 0.9950 - recall_m: 0.9979\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0331 - acc: 0.9973 - f1_m: 0.9914 - precision_m: 0.9901 - recall_m: 0.9929\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0174 - acc: 0.9993 - f1_m: 0.9969 - precision_m: 0.9978 - recall_m: 0.9960\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0162 - acc: 0.9988 - f1_m: 0.9962 - precision_m: 0.9956 - recall_m: 0.9968\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0192 - acc: 0.9988 - f1_m: 0.9956 - precision_m: 0.9948 - recall_m: 0.9964\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0082 - acc: 0.9993 - f1_m: 0.9974 - precision_m: 0.9962 - recall_m: 0.9986\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0084 - acc: 0.9993 - f1_m: 0.9973 - precision_m: 0.9978 - recall_m: 0.9968\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0082 - acc: 0.9993 - f1_m: 0.9972 - precision_m: 1.0000 - recall_m: 0.9945\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0106 - acc: 0.9990 - f1_m: 0.9966 - precision_m: 0.9951 - recall_m: 0.9983\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0064 - acc: 0.9995 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9968\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0109 - acc: 0.9993 - f1_m: 0.9979 - precision_m: 1.0000 - recall_m: 0.9959\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0136 - acc: 0.9990 - f1_m: 0.9972 - precision_m: 0.9972 - recall_m: 0.9974\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0225 - acc: 0.9993 - f1_m: 0.9970 - precision_m: 0.9983 - recall_m: 0.9958\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0254 - acc: 0.9981 - f1_m: 0.9934 - precision_m: 0.9940 - recall_m: 0.9929\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0361 - acc: 0.9969 - f1_m: 0.9888 - precision_m: 0.9847 - recall_m: 0.9932\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0527 - acc: 0.9983 - f1_m: 0.9937 - precision_m: 0.9984 - recall_m: 0.9893\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0240 - acc: 0.9981 - f1_m: 0.9929 - precision_m: 0.9894 - recall_m: 0.9966\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0596 - acc: 0.9969 - f1_m: 0.9894 - precision_m: 0.9894 - recall_m: 0.9896\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0342 - acc: 0.9978 - f1_m: 0.9917 - precision_m: 0.9961 - recall_m: 0.9877\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0150 - acc: 0.9993 - f1_m: 0.9971 - precision_m: 0.9943 - recall_m: 1.0000\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0327 - acc: 0.9988 - f1_m: 0.9957 - precision_m: 1.0000 - recall_m: 0.9916\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0196 - acc: 0.9990 - f1_m: 0.9968 - precision_m: 0.9967 - recall_m: 0.9971\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0258 - acc: 0.9981 - f1_m: 0.9938 - precision_m: 0.9920 - recall_m: 0.9957\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0197 - acc: 0.9983 - f1_m: 0.9938 - precision_m: 0.9951 - recall_m: 0.9928\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0157 - acc: 0.9990 - f1_m: 0.9964 - precision_m: 0.9978 - recall_m: 0.9950\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0109 - acc: 0.9993 - f1_m: 0.9979 - precision_m: 0.9975 - recall_m: 0.9982\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0101 - acc: 0.9988 - f1_m: 0.9959 - precision_m: 0.9956 - recall_m: 0.9964\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0058 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0053 - acc: 0.9995 - f1_m: 0.9983 - precision_m: 0.9983 - recall_m: 0.9983\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0058 - acc: 0.9995 - f1_m: 0.9984 - precision_m: 0.9968 - recall_m: 1.0000\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0200 - acc: 0.9986 - f1_m: 0.9949 - precision_m: 0.9930 - recall_m: 0.9970\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0573 - acc: 0.9990 - f1_m: 0.9967 - precision_m: 1.0000 - recall_m: 0.9935\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0301 - acc: 0.9976 - f1_m: 0.9918 - precision_m: 0.9853 - recall_m: 0.9988\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0466 - acc: 0.9973 - f1_m: 0.9894 - precision_m: 0.9936 - recall_m: 0.9854\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0307 - acc: 0.9976 - f1_m: 0.9910 - precision_m: 0.9867 - recall_m: 0.9957\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0112 - acc: 0.9990 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0095 - acc: 0.9995 - f1_m: 0.9984 - precision_m: 0.9980 - recall_m: 0.9987\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0210 - acc: 0.9986 - f1_m: 0.9949 - precision_m: 0.9935 - recall_m: 0.9964\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0175 - acc: 0.9995 - f1_m: 0.9980 - precision_m: 0.9960 - recall_m: 1.0000\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0097 - acc: 0.9993 - f1_m: 0.9977 - precision_m: 0.9983 - recall_m: 0.9971\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0095 - acc: 0.9993 - f1_m: 0.9974 - precision_m: 0.9986 - recall_m: 0.9963\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0119 - acc: 0.9995 - f1_m: 0.9979 - precision_m: 1.0000 - recall_m: 0.9958\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0068 - acc: 0.9993 - f1_m: 0.9969 - precision_m: 0.9964 - recall_m: 0.9975\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0068 - acc: 0.9995 - f1_m: 0.9984 - precision_m: 0.9983 - recall_m: 0.9986\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0310 - acc: 0.9978 - f1_m: 0.9917 - precision_m: 0.9891 - recall_m: 0.9945\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0107 - acc: 0.9995 - f1_m: 0.9983 - precision_m: 0.9980 - recall_m: 0.9987\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0036 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0353 - acc: 0.9983 - f1_m: 0.9946 - precision_m: 0.9956 - recall_m: 0.9940\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0535 - acc: 0.9973 - f1_m: 0.9913 - precision_m: 0.9934 - recall_m: 0.9895\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0203 - acc: 0.9983 - f1_m: 0.9945 - precision_m: 0.9920 - recall_m: 0.9972\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0341 - acc: 0.9973 - f1_m: 0.9909 - precision_m: 0.9918 - recall_m: 0.9904\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0301 - acc: 0.9983 - f1_m: 0.9929 - precision_m: 0.9939 - recall_m: 0.9919\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0229 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9984 - recall_m: 0.9939\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0120 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9970 - recall_m: 0.9970\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0167 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9967 - recall_m: 0.9955\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0053 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 0.9987 - recall_m: 1.0000\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0094 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9967 - recall_m: 0.9986\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0116 - acc: 0.9986 - f1_m: 0.9941 - precision_m: 0.9966 - recall_m: 0.9917\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0083 - acc: 0.9998 - f1_m: 0.9990 - precision_m: 1.0000 - recall_m: 0.9980\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0086 - acc: 0.9993 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0516 - acc: 0.9961 - f1_m: 0.9869 - precision_m: 0.9806 - recall_m: 0.9939\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0293 - acc: 0.9978 - f1_m: 0.9935 - precision_m: 0.9970 - recall_m: 0.9902\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0203 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9985 - recall_m: 0.9985\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.0198 - acc: 0.9981 - f1_m: 0.9923 - precision_m: 0.9867 - recall_m: 0.9981\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0165 - acc: 0.9986 - f1_m: 0.9941 - precision_m: 0.9942 - recall_m: 0.9941\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0104 - acc: 0.9993 - f1_m: 0.9975 - precision_m: 0.9963 - recall_m: 0.9987\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0185 - acc: 0.9986 - f1_m: 0.9951 - precision_m: 0.9952 - recall_m: 0.9950\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0119 - acc: 0.9993 - f1_m: 0.9958 - precision_m: 0.9934 - recall_m: 0.9983\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0118 - acc: 0.9988 - f1_m: 0.9947 - precision_m: 0.9939 - recall_m: 0.9956\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0144 - acc: 0.9988 - f1_m: 0.9945 - precision_m: 0.9944 - recall_m: 0.9948\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0132 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9985 - recall_m: 0.9968\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0166 - acc: 0.9988 - f1_m: 0.9957 - precision_m: 0.9973 - recall_m: 0.9942\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0204 - acc: 0.9981 - f1_m: 0.9932 - precision_m: 0.9941 - recall_m: 0.9925\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0350 - acc: 0.9986 - f1_m: 0.9950 - precision_m: 0.9944 - recall_m: 0.9957\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0156 - acc: 0.9988 - f1_m: 0.9963 - precision_m: 0.9965 - recall_m: 0.9962\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0067 - acc: 0.9990 - f1_m: 0.9956 - precision_m: 0.9945 - recall_m: 0.9969\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0088 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 0.9986 - recall_m: 1.0000\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0128 - acc: 0.9990 - f1_m: 0.9964 - precision_m: 0.9981 - recall_m: 0.9948\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0193 - acc: 0.9976 - f1_m: 0.9906 - precision_m: 0.9889 - recall_m: 0.9924\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0469 - acc: 0.9978 - f1_m: 0.9932 - precision_m: 0.9956 - recall_m: 0.9908\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0451 - acc: 0.9978 - f1_m: 0.9920 - precision_m: 0.9962 - recall_m: 0.9880\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0229 - acc: 0.9983 - f1_m: 0.9932 - precision_m: 0.9922 - recall_m: 0.9944\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0226 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9972 - recall_m: 0.9968\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0081 - acc: 0.9998 - f1_m: 0.9993 - precision_m: 0.9986 - recall_m: 1.0000\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0238 - acc: 0.9986 - f1_m: 0.9952 - precision_m: 0.9970 - recall_m: 0.9935\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0114 - acc: 0.9990 - f1_m: 0.9965 - precision_m: 0.9949 - recall_m: 0.9982\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0131 - acc: 0.9993 - f1_m: 0.9980 - precision_m: 0.9985 - recall_m: 0.9976\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0115 - acc: 0.9990 - f1_m: 0.9957 - precision_m: 0.9963 - recall_m: 0.9952\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0134 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9980 - recall_m: 0.9973\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0218 - acc: 0.9986 - f1_m: 0.9950 - precision_m: 0.9972 - recall_m: 0.9929\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0134 - acc: 0.9986 - f1_m: 0.9948 - precision_m: 0.9947 - recall_m: 0.9949\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0156 - acc: 0.9986 - f1_m: 0.9951 - precision_m: 0.9935 - recall_m: 0.9969\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0061 - acc: 0.9998 - f1_m: 0.9995 - precision_m: 0.9989 - recall_m: 1.0000\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0120 - acc: 0.9988 - f1_m: 0.9951 - precision_m: 0.9947 - recall_m: 0.9955\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0150 - acc: 0.9986 - f1_m: 0.9936 - precision_m: 0.9909 - recall_m: 0.9966\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0165 - acc: 0.9993 - f1_m: 0.9964 - precision_m: 0.9980 - recall_m: 0.9949\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0096 - acc: 0.9990 - f1_m: 0.9963 - precision_m: 0.9986 - recall_m: 0.9941\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0147 - acc: 0.9988 - f1_m: 0.9963 - precision_m: 0.9927 - recall_m: 1.0000\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0039 - acc: 0.9998 - f1_m: 0.9990 - precision_m: 1.0000 - recall_m: 0.9980\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0083 - acc: 0.9995 - f1_m: 0.9985 - precision_m: 0.9971 - recall_m: 1.0000\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0121 - acc: 0.9990 - f1_m: 0.9968 - precision_m: 0.9979 - recall_m: 0.9959\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0142 - acc: 0.9990 - f1_m: 0.9969 - precision_m: 0.9989 - recall_m: 0.9950\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0570 - acc: 0.9988 - f1_m: 0.9961 - precision_m: 0.9949 - recall_m: 0.9974\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0513 - acc: 0.9971 - f1_m: 0.9889 - precision_m: 0.9927 - recall_m: 0.9855\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0582 - acc: 0.9976 - f1_m: 0.9901 - precision_m: 0.9905 - recall_m: 0.9899\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0085 - acc: 0.9993 - f1_m: 0.9978 - precision_m: 1.0000 - recall_m: 0.9957\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0182 - acc: 0.9988 - f1_m: 0.9947 - precision_m: 0.9983 - recall_m: 0.9913\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0127 - acc: 0.9988 - f1_m: 0.9952 - precision_m: 0.9945 - recall_m: 0.9960\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0099 - acc: 0.9993 - f1_m: 0.9982 - precision_m: 0.9965 - recall_m: 1.0000\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0072 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9983 - recall_m: 0.9969\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0076 - acc: 0.9995 - f1_m: 0.9983 - precision_m: 0.9985 - recall_m: 0.9981\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0294 - acc: 0.9983 - f1_m: 0.9949 - precision_m: 0.9959 - recall_m: 0.9940\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0128 - acc: 0.9990 - f1_m: 0.9960 - precision_m: 0.9920 - recall_m: 1.0000\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0275 - acc: 0.9986 - f1_m: 0.9961 - precision_m: 0.9988 - recall_m: 0.9934\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0252 - acc: 0.9983 - f1_m: 0.9939 - precision_m: 0.9917 - recall_m: 0.9961\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0151 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 1.0000 - recall_m: 0.9953\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0275 - acc: 0.9993 - f1_m: 0.9974 - precision_m: 0.9965 - recall_m: 0.9984\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0127 - acc: 0.9986 - f1_m: 0.9949 - precision_m: 0.9930 - recall_m: 0.9969\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0239 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9949 - recall_m: 0.9991\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0246 - acc: 0.9990 - f1_m: 0.9970 - precision_m: 0.9985 - recall_m: 0.9956\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0137 - acc: 0.9993 - f1_m: 0.9965 - precision_m: 0.9986 - recall_m: 0.9946\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0210 - acc: 0.9988 - f1_m: 0.9956 - precision_m: 0.9986 - recall_m: 0.9926\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0158 - acc: 0.9988 - f1_m: 0.9960 - precision_m: 0.9953 - recall_m: 0.9967\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0189 - acc: 0.9990 - f1_m: 0.9966 - precision_m: 0.9966 - recall_m: 0.9968\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0100 - acc: 0.9990 - f1_m: 0.9972 - precision_m: 0.9989 - recall_m: 0.9956\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0449 - acc: 0.9990 - f1_m: 0.9965 - precision_m: 0.9944 - recall_m: 0.9986\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0241 - acc: 0.9990 - f1_m: 0.9966 - precision_m: 0.9982 - recall_m: 0.9952\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0137 - acc: 0.9988 - f1_m: 0.9953 - precision_m: 0.9987 - recall_m: 0.9921\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0196 - acc: 0.9986 - f1_m: 0.9949 - precision_m: 0.9899 - recall_m: 1.0000\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0415 - acc: 0.9990 - f1_m: 0.9972 - precision_m: 0.9986 - recall_m: 0.9960\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0250 - acc: 0.9981 - f1_m: 0.9930 - precision_m: 0.9877 - recall_m: 0.9986\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0203 - acc: 0.9981 - f1_m: 0.9932 - precision_m: 0.9949 - recall_m: 0.9916\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0093 - acc: 0.9993 - f1_m: 0.9976 - precision_m: 0.9972 - recall_m: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d66141358>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16=create_model_vgg16(num_classe=len(mbl.classes_),units=(128,64),optimizer='adam')\n",
    "model_vgg16.fit(X_train,y_train,epochs=500,class_weight=class_weights,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4744,
     "status": "ok",
     "timestamp": 1582078462168,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "FNgYfocR2lbk",
    "outputId": "5ae557d2-dc04-43f3-bade-b8dbc93dc47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n",
      "O recall é intuitivamente a capacidade do classificador encontrar todas as amostras positivas.\n",
      "\n",
      "A precisão é intuitivamente a capacidade do classificador não rotular como positiva uma amostra negativa.\n",
      "\n",
      "A pontuação F1 pode ser interpretada como uma média ponderada da precisão e recall.\n",
      "\n",
      "Support é a quantidade de ocorrencia da classe.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    adptador       0.95      1.00      0.97        19\n",
      "     bandeja       1.00      1.00      1.00        26\n",
      "     bateria       1.00      1.00      1.00        17\n",
      "        cabo       1.00      0.89      0.94         9\n",
      "  carregador       1.00      0.88      0.93        16\n",
      "    cartucho       0.91      0.83      0.87        12\n",
      "      coldre       0.75      0.60      0.67         5\n",
      "    pendrive       0.92      0.79      0.85        14\n",
      "       spark       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       0.97      0.92      0.94       123\n",
      "   macro avg       0.95      0.89      0.91       123\n",
      "weighted avg       0.96      0.92      0.94       123\n",
      " samples avg       0.45      0.45      0.45       123\n",
      "\n",
      "Matrix confusão do(a) adptador\n",
      "[[80  1]\n",
      " [ 0 19]] \n",
      "\n",
      "Matrix confusão do(a) bandeja\n",
      "[[74  0]\n",
      " [ 0 26]] \n",
      "\n",
      "Matrix confusão do(a) bateria\n",
      "[[83  0]\n",
      " [ 0 17]] \n",
      "\n",
      "Matrix confusão do(a) cabo\n",
      "[[91  0]\n",
      " [ 1  8]] \n",
      "\n",
      "Matrix confusão do(a) carregador\n",
      "[[84  0]\n",
      " [ 2 14]] \n",
      "\n",
      "Matrix confusão do(a) cartucho\n",
      "[[87  1]\n",
      " [ 2 10]] \n",
      "\n",
      "Matrix confusão do(a) coldre\n",
      "[[94  1]\n",
      " [ 2  3]] \n",
      "\n",
      "Matrix confusão do(a) pendrive\n",
      "[[85  1]\n",
      " [ 3 11]] \n",
      "\n",
      "Matrix confusão do(a) spark\n",
      "[[95  0]\n",
      " [ 0  5]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015555555555555555"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba=model_vgg16.predict(X_test)\n",
    "t = 0.37 # threshold value\n",
    "y_pred_new = prob_to_binary(proba,t)\n",
    "\n",
    "print(len(y_test),len(proba),len(y_pred_new))\n",
    "cm=multilabel_confusion_matrix(y_test,y_pred_new)\n",
    "print(\"O recall é intuitivamente a capacidade do classificador encontrar todas as amostras positivas.\\n\")\n",
    "print(\"A precisão é intuitivamente a capacidade do classificador não rotular como positiva uma amostra negativa.\\n\")\n",
    "print(\"A pontuação F1 pode ser interpretada como uma média ponderada da precisão e recall.\\n\")\n",
    "print(\"Support é a quantidade de ocorrencia da classe.\\n\")\n",
    "print( classification_report(y_test,y_pred_new,target_names=mbl.classes_))\n",
    "\n",
    "for i,label in enumerate(mbl.classes_):\n",
    "  print(\"Matrix confusão do(a) {}\".format(label))\n",
    "  print(cm[i],'\\n')\n",
    "\n",
    "hamming_loss(y_test,y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3812,
     "status": "ok",
     "timestamp": 1582077369060,
     "user": {
      "displayName": "wagner luiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU5Ht8-r_-kFet1eZu6CmfQujvNHiCItje2ijFfw=s64",
      "userId": "10379356806221894486"
     },
     "user_tz": 180
    },
    "id": "BtaRFaqLHfiQ",
    "outputId": "9944415f-7d6e-4387-cc56-4fc63bd42dc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/My Drive/dataset/\n",
      "Saved model to disk\n",
      "mbl.classes_  ['adptador' 'bandeja' 'bateria' 'cabo' 'carregador' 'cartucho' 'coldre'\n",
      " 'pendrive' 'spark']\n"
     ]
    }
   ],
   "source": [
    "dataset_path=path_name+'dataset/'\n",
    "print(dataset_path)\n",
    "# serialize model to JSON\n",
    "model_json = model_vgg16.to_json()\n",
    "with open(dataset_path+\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_vgg16.save_weights(dataset_path+\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print('mbl.classes_ ',mbl.classes_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMRGUw4aHnfpmgzTmUsR7sD",
   "collapsed_sections": [],
   "mount_file_id": "1f5W7ykOxIi7QWOm-zB4QzWwFSRTwjodC",
   "name": "condor_keras_with_grid_search.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
